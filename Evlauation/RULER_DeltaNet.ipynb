{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-16T13:16:53.906672Z",
     "start_time": "2025-12-16T13:16:48.812998Z"
    }
   },
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP & ENVIRONMENT\n",
    "# ==============================================================================\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "\n",
    "# --- A. Detect Project Root (Critical for Notebooks) ---\n",
    "# Automatically finds the root 'Babilong_Benchmark' folder\n",
    "current_path = Path(os.getcwd())\n",
    "if (current_path / \"source\").exists():\n",
    "    project_root = current_path\n",
    "elif (current_path.parent / \"source\").exists():\n",
    "    project_root = current_path.parent\n",
    "else:\n",
    "    # Fallback to parent if structure is standard\n",
    "    project_root = current_path.parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "    print(f\"‚úÖ Added Project Root to Path: {project_root}\")\n",
    "\n",
    "# --- B. Windows Compiler Config (DeltaNet Requirement) ---\n",
    "# Locates the Visual Studio C++ compiler for JIT compilation\n",
    "print(\"\\n‚öôÔ∏è Configuring Windows Environment...\")\n",
    "patterns = [\n",
    "    r\"C:\\Program Files\\Microsoft Visual Studio\\**\\Hostx64\\x64\\cl.exe\",\n",
    "    r\"C:\\Program Files (x86)\\Microsoft Visual Studio\\**\\Hostx64\\x64\\cl.exe\"\n",
    "]\n",
    "compiler_path = None\n",
    "for pattern in patterns:\n",
    "    matches = glob.glob(pattern, recursive=True)\n",
    "    if matches:\n",
    "        compiler_path = sorted(matches)[-1]  # Use the newest version\n",
    "        break\n",
    "\n",
    "if compiler_path:\n",
    "    os.environ[\"CC\"] = compiler_path\n",
    "    os.environ[\"CXX\"] = compiler_path\n",
    "    print(f\"‚úÖ Compiler configured: {os.path.basename(compiler_path)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: Visual Studio 'cl.exe' not found. Triton/CUDA kernels may fail.\")\n",
    "\n",
    "# --- C. GPU Patch for FLA Library ---\n",
    "# Monkey-patch 'fla' to force CUDA usage on Windows\n",
    "import fla.utils\n",
    "fla.utils.get_available_device = lru_cache(maxsize=None)(lambda: 'cuda')\n",
    "fla.utils._cpu_device_warning = lambda: None\n",
    "print(\"‚úÖ DeltaNet GPU Lock removed.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è Configuring Windows Environment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Triton version 3.0.0 is below the recommended 3.2.0 version. Errors may occur and these issues will not be fixed. Please consider upgrading Triton.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Compiler configured: cl.exe\n",
      "‚úÖ DeltaNet GPU Lock removed.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T13:19:43.922976Z",
     "start_time": "2025-12-16T13:19:19.740186Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install git+https://github.com/EleutherAI/lm-evaluation-harness.git",
   "id": "de9e6dcf78770ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness.git\n",
      "  Cloning https://github.com/EleutherAI/lm-evaluation-harness.git to c:\\users\\louis\\appdata\\local\\temp\\pip-req-build-utm3yx1v\n",
      "  Resolved https://github.com/EleutherAI/lm-evaluation-harness.git to commit 69ecd0b929701d346c1119d5cd0563ade4ab3536\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: datasets>=2.16.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (4.4.1)\n",
      "Requirement already satisfied: evaluate>=0.4.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (0.4.6)\n",
      "Requirement already satisfied: jinja2 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (3.1.6)\n",
      "Requirement already satisfied: jsonlines in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (4.0.0)\n",
      "Requirement already satisfied: pytablewriter in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (1.2.1)\n",
      "Requirement already satisfied: rouge-score>=0.0.4 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu>=1.5.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (1.8.0)\n",
      "Requirement already satisfied: sqlitedict in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (2.1.0)\n",
      "Requirement already satisfied: zstandard in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (0.25.0)\n",
      "Requirement already satisfied: dill in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (0.3.8)\n",
      "Requirement already satisfied: word2number in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (1.1)\n",
      "Requirement already satisfied: more_itertools in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from lm_eval==0.4.9.2) (10.8.0)\n",
      "Requirement already satisfied: filelock in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (22.0.0)\n",
      "Requirement already satisfied: pandas in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (4.66.4)\n",
      "Requirement already satisfied: xxhash in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (1.1.2)\n",
      "Requirement already satisfied: packaging in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from datasets>=2.16.0->lm_eval==0.4.9.2) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (3.13.2)\n",
      "Requirement already satisfied: anyio in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets>=2.16.0->lm_eval==0.4.9.2) (4.11.0)\n",
      "Requirement already satisfied: certifi in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets>=2.16.0->lm_eval==0.4.9.2) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets>=2.16.0->lm_eval==0.4.9.2) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets>=2.16.0->lm_eval==0.4.9.2) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.16.0->lm_eval==0.4.9.2) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.16.0->lm_eval==0.4.9.2) (1.2.0)\n",
      "Requirement already satisfied: shellingham in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.16.0->lm_eval==0.4.9.2) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.16.0->lm_eval==0.4.9.2) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.16.0->lm_eval==0.4.9.2) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.9.2) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.9.2) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.9.2) (2.5.0)\n",
      "Requirement already satisfied: absl-py in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from rouge-score>=0.0.4->lm_eval==0.4.9.2) (2.3.1)\n",
      "Requirement already satisfied: nltk in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from rouge-score>=0.0.4->lm_eval==0.4.9.2) (3.9.2)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from rouge-score>=0.0.4->lm_eval==0.4.9.2) (1.17.0)\n",
      "Requirement already satisfied: portalocker in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.2) (3.2.0)\n",
      "Requirement already satisfied: regex in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.2) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.2) (0.9.0)\n",
      "Requirement already satisfied: colorama in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.2) (0.4.6)\n",
      "Requirement already satisfied: lxml in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.9.2) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.9.2) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.9.2) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.9.2) (3.6.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets>=2.16.0->lm_eval==0.4.9.2) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from jinja2->lm_eval==0.4.9.2) (3.0.3)\n",
      "Requirement already satisfied: click in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.9.2) (8.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.9.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.9.2) (2025.2)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from portalocker->sacrebleu>=1.5.0->lm_eval==0.4.9.2) (311)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pytablewriter->lm_eval==0.4.9.2) (80.9.0)\n",
      "Requirement already satisfied: DataProperty<2,>=1.1.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pytablewriter->lm_eval==0.4.9.2) (1.1.0)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pytablewriter->lm_eval==0.4.9.2) (1.1.4)\n",
      "Requirement already satisfied: pathvalidate<4,>=2.3.0 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pytablewriter->lm_eval==0.4.9.2) (3.3.1)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.1 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pytablewriter->lm_eval==0.4.9.2) (1.3.4)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from pytablewriter->lm_eval==0.4.9.2) (0.1.7)\n",
      "Requirement already satisfied: typepy<2,>=1.3.2 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.9.2) (1.3.4)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in d:\\users\\louis\\pycharmprojects\\master_thesis\\babilong_benchmark\\.venv\\lib\\site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.9.2) (5.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm-evaluation-harness.git 'C:\\Users\\Louis\\AppData\\Local\\Temp\\pip-req-build-utm3yx1v'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T13:17:49.203939Z",
     "start_time": "2025-12-16T13:17:39.864098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# 2. MODEL LOADING & CONFIGURATION\n",
    "# ==============================================================================\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "from fla.models.delta_net import DeltaNetForCausalLM, DeltaNetConfig\n",
    "\n",
    "# --- Configuration ---\n",
    "USE_ADAPTER = False  # Set to True to load fine-tuned weights\n",
    "BASE_MODEL_ID = \"fla-hub/delta_net-1.3B-100B\"\n",
    "ADAPTER_PATH = Path(\"../babilong_deltanet_finetune\").resolve()\n",
    "\n",
    "# Use bfloat16 for stability with Linear Attention models\n",
    "DTYPE = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "DEVICE_MAP = {\"\": \"cuda\"}\n",
    "\n",
    "# --- A. Register Custom Architecture ---\n",
    "# Registers 'delta_net' so AutoModel and PeftModel can recognize it\n",
    "try:\n",
    "    AutoConfig.register(\"delta_net\", DeltaNetConfig)\n",
    "    AutoModelForCausalLM.register(DeltaNetConfig, DeltaNetForCausalLM)\n",
    "    print(\"‚úÖ DeltaNet architecture registered in Transformers.\")\n",
    "except ValueError:\n",
    "    print(\"‚ÑπÔ∏è  DeltaNet already registered.\")\n",
    "\n",
    "# --- B. Load Base Model ---\n",
    "print(f\"‚è≥ Loading Base Model: {BASE_MODEL_ID}...\")\n",
    "model = DeltaNetForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    "    device_map=DEVICE_MAP,\n",
    "    torch_dtype=DTYPE,\n",
    ")\n",
    "\n",
    "# --- C. Load Tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# --- D. Context Limit Hack (CRITICAL) ---\n",
    "# DeltaNet supports infinite context, but the HF config defaults to 2048.\n",
    "# We must manually override this to allow RULER to test long sequences (4k, 8k+).\n",
    "print(\"üîì Unlocking Model Context Limits to 128k...\")\n",
    "model.config.max_position_embeddings = 131072\n",
    "model.config.max_length = 131072\n",
    "tokenizer.model_max_length = 131072\n",
    "\n",
    "# --- E. Load Adapter (Optional) ---\n",
    "if USE_ADAPTER:\n",
    "    # Logic to find the adapter if it's in a slightly different path\n",
    "    if not (ADAPTER_PATH / \"adapter_config.json\").exists():\n",
    "        fallback = Path(\"../Pretraining/babilong_deltanet_finetune\").resolve()\n",
    "        if (fallback / \"adapter_config.json\").exists():\n",
    "            ADAPTER_PATH = fallback\n",
    "    \n",
    "    if (ADAPTER_PATH / \"adapter_config.json\").exists():\n",
    "        print(f\"üîó Loading LoRA Adapter from: {ADAPTER_PATH}\")\n",
    "        model = PeftModel.from_pretrained(model, str(ADAPTER_PATH))\n",
    "        print(\"‚úÖ Adapter attached successfully.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"‚ùå Adapter not found at: {ADAPTER_PATH}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Running in Baseline Mode (No Adapter).\")\n",
    "\n",
    "model.eval()\n",
    "print(\"‚úÖ Model ready for evaluation.\")"
   ],
   "id": "cb5fa0fe4a769ee0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered DeltaNet architecture in Transformers registry.\n",
      "‚è≥ Loading DeltaNet Base: fla-hub/delta_net-1.3B-100B...\n",
      "‚ÑπÔ∏è  Running in Baseline Mode (No Adapter).\n",
      "‚úÖ Base DeltaNet Loaded Successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaNetForCausalLM(\n",
       "  (model): DeltaNetModel(\n",
       "    (embeddings): Embedding(32000, 2048, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x DeltaNetBlock(\n",
       "        (attn_norm): RMSNorm(2048, eps=1e-06)\n",
       "        (attn): DeltaNet(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (b_proj): Linear(in_features=2048, out_features=16, bias=False)\n",
       "          (q_conv1d): ShortConvolution(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048, bias=False, activation=silu, backend=triton)\n",
       "          (k_conv1d): ShortConvolution(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048, bias=False, activation=silu, backend=triton)\n",
       "          (v_conv1d): ShortConvolution(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048, bias=False, activation=silu, backend=triton)\n",
       "          (o_norm): RMSNorm(128, eps=1e-06)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp_norm): RMSNorm(2048, eps=1e-06)\n",
       "        (mlp): GatedMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (swiglu_linear): SwiGLULinear()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm(2048, eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T19:06:13.045651Z",
     "start_time": "2025-12-16T16:12:02.147810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# 4. RULER EVALUATION HARNESS (Force-Unlocked)\n",
    "# ==============================================================================\n",
    "import lm_eval\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "from lm_eval import simple_evaluate\n",
    "from lm_eval.utils import make_table\n",
    "import json\n",
    "\n",
    "print(\"\\nüîå Plugging DeltaNet into Evaluation Harness...\")\n",
    "\n",
    "# 1. PRE-PATCH THE CONFIG (Just in case)\n",
    "print(\"üîì Unlocking DeltaNet Config Limits...\")\n",
    "# We set every possible attribute name that HF might check\n",
    "model.config.max_position_embeddings = 131072\n",
    "model.config.max_length = 131072\n",
    "model.config.seq_length = 131072  # Sometimes used by custom configs\n",
    "tokenizer.model_max_length = 131072\n",
    "\n",
    "# 2. WRAP THE MODEL\n",
    "lm_obj = HFLM(\n",
    "    pretrained=model,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# --- üõ†Ô∏è STEP 4.5: THE NUCLEAR FIX üõ†Ô∏è ---\n",
    "# We directly overwrite the internal property of the Harness wrapper.\n",
    "# This bypasses any logic it used to \"guess\" the length from the config.\n",
    "lm_obj._max_length = 131072\n",
    "print(f\"‚úÖ Force-set Harness Max Length to: {lm_obj.max_length}\")\n",
    "# ---------------------------------------\n",
    "\n",
    "# 3. DEFINE TASK\n",
    "TASK_NAME = \"niah_single_2\" \n",
    "LENGTHS_TO_TEST = [2048, 4096, 8192] \n",
    "\n",
    "print(f\"üöÄ Starting RULER Evaluation: {TASK_NAME}\")\n",
    "print(f\"üìè Testing Lengths: {LENGTHS_TO_TEST}\")\n",
    "\n",
    "# 4. RUN EVALUATION\n",
    "results = simple_evaluate(\n",
    "    model=lm_obj,\n",
    "    tasks=[TASK_NAME],\n",
    "    device=\"cuda\",\n",
    "    metadata={\n",
    "        \"max_seq_lengths\": LENGTHS_TO_TEST,\n",
    "        \"tokenizer\": BASE_MODEL_ID \n",
    "    }\n",
    ")\n",
    "\n",
    "# 5. PRINT & SAVE\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"üèÜ RESULTS: DeltaNet ({'Fine-Tuned' if USE_ADAPTER else 'Baseline'})\")\n",
    "print(\"=\"*40)\n",
    "print(make_table(results))\n",
    "\n",
    "output_file = f\"results_deltanet_{'finetuned' if USE_ADAPTER else 'baseline'}.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results[\"results\"], f, indent=4)\n",
    "print(f\"\\nüíæ Results saved to {output_file}\")"
   ],
   "id": "aa4693cf6ff4703d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "HF model type is neither marked as CausalLM or Seq2SeqLM.                     This is expected if your model requires `trust_remote_code=True` but may be an error otherwise.Setting backend to causal\n",
      "Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîå Plugging DeltaNet into Evaluation Harness...\n",
      "üîì Unlocking DeltaNet Config Limits...\n",
      "‚úÖ Force-set Harness Max Length to: 131072\n",
      "üöÄ Starting RULER Evaluation: niah_single_2\n",
      "üìè Testing Lengths: [2048, 4096, 8192]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "niah_single_2: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.\n",
      "For example --metadata='{\"max_seq_lengths\":[4096, 8192]}'. For details see task Readme.\n",
      "Generating synthetic samples: essay | 2048: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 590.80it/s]\n",
      "Generating synthetic samples: essay | 4096: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:02<00:00, 208.54it/s]\n",
      "Generating synthetic samples: essay | 8192: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:06<00:00, 73.57it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [00:01<00:00, 1133.40it/s]\n",
      "Running generate_until requests:   0%|          | 0/1500 [00:00<?, ?it/s]D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1776: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "Running generate_until requests: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [2:53:28<00:00,  6.94s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üèÜ RESULTS: DeltaNet (Baseline)\n",
      "========================================\n",
      "|    Tasks    |Version|Filter|n-shot|Metric|   |Value|   |Stderr|\n",
      "|-------------|------:|------|-----:|-----:|---|----:|---|------|\n",
      "|niah_single_2|      1|none  |     0|  2048|   |1.000|¬±  |     0|\n",
      "|             |       |none  |     0|  4096|‚Üë  |0.684|¬±  |   N/A|\n",
      "|             |       |none  |     0|  8192|‚Üë  |0.230|¬±  |   N/A|\n",
      "\n",
      "\n",
      "üíæ Results saved to results_deltanet_baseline.json\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "87ce21a4eb5d560b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
