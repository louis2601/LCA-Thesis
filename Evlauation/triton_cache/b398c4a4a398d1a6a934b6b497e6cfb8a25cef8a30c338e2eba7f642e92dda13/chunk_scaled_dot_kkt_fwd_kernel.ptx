//
// Generated by LLVM NVPTX Back-End
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	chunk_scaled_dot_kkt_fwd_kernel
.extern .shared .align 16 .b8 global_smem[];

.visible .entry chunk_scaled_dot_kkt_fwd_kernel(
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_0,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_1,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_2,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_3,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_4,
	.param .u32 chunk_scaled_dot_kkt_fwd_kernel_param_5
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<86>;
	.reg .b16 	%rs<13>;
	.reg .b32 	%r<335>;
	.reg .f32 	%f<319>;
	.reg .b64 	%rd<109>;
	.loc	1 30 0
$L__func_begin0:
	.loc	1 30 0

	ld.param.u64 	%rd9, [chunk_scaled_dot_kkt_fwd_kernel_param_2];
	ld.param.u64 	%rd22, [chunk_scaled_dot_kkt_fwd_kernel_param_0];
	ld.param.u64 	%rd23, [chunk_scaled_dot_kkt_fwd_kernel_param_1];
$L__tmp0:
	.loc	1 45 30
	// begin inline asm
	mov.u32 %r30, %ctaid.x;
	// end inline asm
	.loc	1 45 48
	// begin inline asm
	mov.u32 %r31, %ctaid.y;
	// end inline asm
	.loc	1 46 33
	shr.s32 	%r48, %r31, 31;
	shr.u32 	%r49, %r48, 28;
	add.s32 	%r50, %r31, %r49;
	and.b32  	%r51, %r50, -16;
	sub.s32 	%r52, %r31, %r51;
	ld.param.u64 	%rd24, [chunk_scaled_dot_kkt_fwd_kernel_param_3];
	.loc	1 48 49
	shl.b32 	%r53, %r30, 1;
	ld.param.u64 	%rd25, [chunk_scaled_dot_kkt_fwd_kernel_param_4];
	.loc	1 48 43
	mul.wide.s32 	%rd26, %r53, 4;
	add.s64 	%rd10, %rd25, %rd26;
	mov.pred 	%p3, -1;
	.loc	1 48 27
	// begin inline asm
	mov.u32 %r32, 0x0;
	@%p3 ld.global.b32 { %r32 }, [ %rd10 + 0 ];
	// end inline asm
	.loc	1 48 100
	add.s64 	%rd11, %rd10, 4;
	.loc	1 48 74
	// begin inline asm
	mov.u32 %r33, 0x0;
	@%p3 ld.global.b32 { %r33 }, [ %rd11 + 0 ];
	// end inline asm
	.loc	1 49 40
	mul.wide.s32 	%rd27, %r32, 4;
	add.s64 	%rd12, %rd24, %rd27;
	.loc	1 49 27
	// begin inline asm
	mov.u32 %r34, 0x0;
	@%p3 ld.global.b32 { %r34 }, [ %rd12 + 0 ];
	// end inline asm
	.loc	1 49 86
	add.s64 	%rd13, %rd12, 4;
	.loc	1 49 67
	// begin inline asm
	mov.u32 %r35, 0x0;
	@%p3 ld.global.b32 { %r35 }, [ %rd13 + 0 ];
	// end inline asm
	.loc	1 50 18
	sub.s32 	%r54, %r35, %r34;
	.loc	1 53 16
	shl.b32 	%r55, %r33, 6;
	.loc	1 53 34
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 31;
	shr.u32 	%r3, %r1, 5;
	shr.u32 	%r4, %r1, 2;
	bfe.u32 	%r56, %r1, 2, 3;
	and.b32  	%r5, %r4, 16;
	and.b32  	%r57, %r4, 24;
	bfe.u32 	%r58, %r1, 2, 5;
	or.b32  	%r59, %r56, 32;
	or.b32  	%r60, %r57, %r59;
	and.b32  	%r6, %r4, 23;
	or.b32  	%r7, %r6, 8;
	or.b32  	%r8, %r59, %r5;
	or.b32  	%r9, %r6, 40;
	.loc	1 56 39
	shl.b32 	%r61, %r34, 4;
	.loc	1 56 35
	mul.wide.s32 	%rd28, %r61, 2;
	add.s64 	%rd29, %rd23, %rd28;
	.loc	1 56 43
	mul.wide.s32 	%rd30, %r52, 2;
	add.s64 	%rd31, %rd29, %rd30;
	.loc	1 56 80
	cvt.s64.s32 	%rd1, %r54;
	cvt.s64.s32 	%rd2, %r55;
	cvt.u64.u32 	%rd32, %r58;
	cvt.u64.u32 	%rd33, %r60;
	cvt.u64.u32 	%rd34, %r6;
	cvt.u64.u32 	%rd35, %r7;
	cvt.u64.u32 	%rd36, %r8;
	cvt.u64.u32 	%rd37, %r9;
	.loc	1 57 18
	or.b64  	%rd38, %rd2, %rd32;
	or.b64  	%rd39, %rd2, %rd33;
	or.b64  	%rd40, %rd2, %rd34;
	or.b64  	%rd41, %rd2, %rd35;
	or.b64  	%rd42, %rd2, %rd36;
	or.b64  	%rd43, %rd2, %rd37;
	shl.b64 	%rd44, %rd40, 5;
	add.s64 	%rd14, %rd31, %rd44;
	shl.b64 	%rd45, %rd41, 5;
	add.s64 	%rd15, %rd31, %rd45;
	shl.b64 	%rd46, %rd42, 5;
	add.s64 	%rd16, %rd31, %rd46;
	shl.b64 	%rd47, %rd43, 5;
	add.s64 	%rd17, %rd31, %rd47;
	setp.gt.s64 	%p15, %rd40, -1;
	setp.gt.s64 	%p16, %rd41, -1;
	setp.gt.s64 	%p17, %rd42, -1;
	setp.gt.s64 	%p18, %rd43, -1;
	setp.lt.s64 	%p19, %rd40, %rd1;
	setp.lt.s64 	%p20, %rd41, %rd1;
	setp.lt.s64 	%p21, %rd42, %rd1;
	setp.lt.s64 	%p22, %rd43, %rd1;
	and.pred  	%p7, %p15, %p19;
	and.pred  	%p8, %p16, %p20;
	and.pred  	%p9, %p17, %p21;
	and.pred  	%p10, %p18, %p22;
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p7 ld.global.b16 { %rs1 }, [ %rd14 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u16 %rs2, 0x0;
	@%p8 ld.global.b16 { %rs2 }, [ %rd15 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u16 %rs3, 0x0;
	@%p9 ld.global.b16 { %rs3 }, [ %rd16 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u16 %rs4, 0x0;
	@%p10 ld.global.b16 { %rs4 }, [ %rd17 + 0 ];
	// end inline asm
	.loc	1 61 45
	add.s32 	%r10, %r61, %r52;
	.loc	1 61 52
	shl.b32 	%r62, %r10, 7;
	.loc	1 61 36
	mul.wide.s32 	%rd48, %r62, 2;
	add.s64 	%rd49, %rd22, %rd48;
	.loc	1 62 22
	shl.b32 	%r63, %r1, 3;
	and.b32  	%r64, %r63, 24;
	setp.gt.s64 	%p23, %rd38, -1;
	setp.gt.s64 	%p24, %rd39, -1;
	setp.lt.s64 	%p25, %rd38, %rd1;
	setp.lt.s64 	%p26, %rd39, %rd1;
	and.pred  	%p1, %p23, %p25;
	and.pred  	%p2, %p24, %p26;
	mul.wide.u32 	%rd50, %r64, 2;
	shl.b64 	%rd51, %rd38, 12;
	or.b64  	%rd52, %rd51, %rd50;
	add.s64 	%rd18, %rd49, %rd52;
	shl.b64 	%rd53, %rd39, 12;
	or.b64  	%rd54, %rd53, %rd50;
	add.s64 	%rd19, %rd49, %rd54;
	shl.b32 	%r65, %r58, 5;
	xor.b32  	%r66, %r1, %r63;
	and.b32  	%r67, %r66, 24;
	or.b32  	%r11, %r65, %r67;
	shl.b32 	%r68, %r11, 1;
	mov.u32 	%r45, global_smem;
	add.s32 	%r36, %r45, %r68;
	shl.b32 	%r69, %r60, 5;
	or.b32  	%r12, %r69, %r67;
	shl.b32 	%r70, %r12, 1;
	add.s32 	%r38, %r45, %r70;
	selp.b32 	%r37, 16, 0, %p1;
	// begin inline asm
	@%p3 cp.async.cg.shared.global [ %r36 + 0 ], [ %rd18 + 0 ], 0x10, %r37;
	// end inline asm
	selp.b32 	%r39, 16, 0, %p2;
	// begin inline asm
	@%p3 cp.async.cg.shared.global [ %r38 + 0 ], [ %rd19 + 0 ], 0x10, %r39;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	add.s64 	%rd20, %rd18, 64;
	add.s64 	%rd21, %rd19, 64;
	bar.sync 	0;
	add.s32 	%r71, %r45, 4096;
	add.s32 	%r40, %r71, %r68;
	add.s32 	%r42, %r71, %r70;
	// begin inline asm
	@%p3 cp.async.cg.shared.global [ %r40 + 0 ], [ %rd20 + 0 ], 0x10, %r37;
	// end inline asm
	// begin inline asm
	@%p3 cp.async.cg.shared.global [ %r42 + 0 ], [ %rd21 + 0 ], 0x10, %r39;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x1;
	// end inline asm
	bar.sync 	0;
	and.b32  	%r72, %r1, 7;
	bfe.u32 	%r73, %r1, 3, 1;
	bfe.u32 	%r13, %r1, 4, 1;
	and.b32  	%r74, %r3, 2;
	or.b32  	%r75, %r74, %r73;
	bfe.u32 	%r76, %r1, 1, 2;
	or.b32  	%r77, %r13, 2;
	and.b32  	%r14, %r4, 8;
	and.b32  	%r78, %r1, 23;
	or.b32  	%r79, %r78, %r14;
	or.b32  	%r80, %r73, 2;
	xor.b32  	%r81, %r13, %r76;
	shl.b32 	%r82, %r75, 8;
	shl.b32 	%r83, %r72, 5;
	or.b32  	%r84, %r82, %r83;
	shl.b32 	%r85, %r81, 3;
	or.b32  	%r15, %r85, %r84;
	xor.b32  	%r86, %r77, %r76;
	shl.b32 	%r87, %r86, 3;
	or.b32  	%r16, %r87, %r84;
	xor.b32  	%r88, %r73, %r76;
	shl.b32 	%r89, %r79, 5;
	shl.b32 	%r90, %r88, 3;
	or.b32  	%r17, %r90, %r89;
	xor.b32  	%r91, %r80, %r76;
	shl.b32 	%r92, %r91, 3;
	or.b32  	%r18, %r92, %r89;
	.loc	1 60 21
	and.b32  	%r93, %r1, 3;
	mul.wide.u32 	%rd55, %r93, 16;
	or.b64  	%rd56, %rd53, %rd55;
	add.s64 	%rd57, %rd56, %rd48;
	add.s64 	%rd58, %rd57, %rd22;
	add.s64 	%rd108, %rd58, 128;
	or.b64  	%rd59, %rd51, %rd55;
	add.s64 	%rd60, %rd59, %rd48;
	add.s64 	%rd61, %rd60, %rd22;
	add.s64 	%rd107, %rd61, 128;
	or.b32  	%r330, %r64, 64;
	mov.f32 	%f287, 0f00000000;
	mov.b32 	%r334, 1;
	mov.b32 	%r333, 0;
	mov.b32 	%r331, -1;
	shl.b32 	%r234, %r15, 1;
	shl.b32 	%r235, %r16, 1;
	shl.b32 	%r236, %r17, 1;
	shl.b32 	%r237, %r18, 1;
	mov.u32 	%r332, %r45;
	mov.f32 	%f288, %f287;
	mov.f32 	%f289, %f287;
	mov.f32 	%f290, %f287;
	mov.f32 	%f291, %f287;
	mov.f32 	%f292, %f287;
	mov.f32 	%f293, %f287;
	mov.f32 	%f294, %f287;
	mov.f32 	%f295, %f287;
	mov.f32 	%f296, %f287;
	mov.f32 	%f297, %f287;
	mov.f32 	%f298, %f287;
	mov.f32 	%f299, %f287;
	mov.f32 	%f300, %f287;
	mov.f32 	%f301, %f287;
	mov.f32 	%f302, %f287;
	mov.f32 	%f303, %f287;
	mov.f32 	%f304, %f287;
	mov.f32 	%f305, %f287;
	mov.f32 	%f306, %f287;
	mov.f32 	%f307, %f287;
	mov.f32 	%f308, %f287;
	mov.f32 	%f309, %f287;
	mov.f32 	%f310, %f287;
	mov.f32 	%f311, %f287;
	mov.f32 	%f312, %f287;
	mov.f32 	%f313, %f287;
	mov.f32 	%f314, %f287;
	mov.f32 	%f315, %f287;
	mov.f32 	%f316, %f287;
	mov.f32 	%f317, %f287;
	mov.f32 	%f318, %f287;
$L__BB0_1:
	add.s32 	%r331, %r331, 1;
	setp.lt.u32 	%p29, %r331, 2;
	.loc	1 62 22
	add.s32 	%r98, %r332, %r234;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r134, %r135, %r136, %r137 }, [ %r98 + 0 ];
	// end inline asm
	add.s32 	%r103, %r332, %r235;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r182, %r183, %r184, %r185 }, [ %r103 + 0 ];
	// end inline asm
	add.s32 	%r108, %r98, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r158, %r159, %r160, %r161 }, [ %r108 + 0 ];
	// end inline asm
	add.s32 	%r113, %r103, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r206, %r207, %r208, %r209 }, [ %r113 + 0 ];
	// end inline asm
	.loc	1 63 36
	add.s32 	%r118, %r332, %r236;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r138, %r139, %r144, %r145 }, [ %r118 + 0 ];
	// end inline asm
	add.s32 	%r123, %r332, %r237;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r186, %r187, %r192, %r193 }, [ %r123 + 0 ];
	// end inline asm
	add.s32 	%r128, %r118, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r150, %r151, %r156, %r157 }, [ %r128 + 0 ];
	// end inline asm
	add.s32 	%r133, %r123, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r198, %r199, %r204, %r205 }, [ %r133 + 0 ];
	// end inline asm
	.loc	1 63 27
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f287, %f288, %f289, %f290 }, { %r134, %r135, %r136, %r137 }, { %r138, %r139 }, { %f287, %f288, %f289, %f290 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f291, %f292, %f293, %f294 }, { %r134, %r135, %r136, %r137 }, { %r144, %r145 }, { %f291, %f292, %f293, %f294 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f295, %f296, %f297, %f298 }, { %r134, %r135, %r136, %r137 }, { %r150, %r151 }, { %f295, %f296, %f297, %f298 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f299, %f300, %f301, %f302 }, { %r134, %r135, %r136, %r137 }, { %r156, %r157 }, { %f299, %f300, %f301, %f302 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f303, %f304, %f305, %f306 }, { %r158, %r159, %r160, %r161 }, { %r138, %r139 }, { %f303, %f304, %f305, %f306 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f307, %f308, %f309, %f310 }, { %r158, %r159, %r160, %r161 }, { %r144, %r145 }, { %f307, %f308, %f309, %f310 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f311, %f312, %f313, %f314 }, { %r158, %r159, %r160, %r161 }, { %r150, %r151 }, { %f311, %f312, %f313, %f314 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f315, %f316, %f317, %f318 }, { %r158, %r159, %r160, %r161 }, { %r156, %r157 }, { %f315, %f316, %f317, %f318 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f287, %f288, %f289, %f290 }, { %r182, %r183, %r184, %r185 }, { %r186, %r187 }, { %f287, %f288, %f289, %f290 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f291, %f292, %f293, %f294 }, { %r182, %r183, %r184, %r185 }, { %r192, %r193 }, { %f291, %f292, %f293, %f294 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f295, %f296, %f297, %f298 }, { %r182, %r183, %r184, %r185 }, { %r198, %r199 }, { %f295, %f296, %f297, %f298 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f299, %f300, %f301, %f302 }, { %r182, %r183, %r184, %r185 }, { %r204, %r205 }, { %f299, %f300, %f301, %f302 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f303, %f304, %f305, %f306 }, { %r206, %r207, %r208, %r209 }, { %r186, %r187 }, { %f303, %f304, %f305, %f306 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f307, %f308, %f309, %f310 }, { %r206, %r207, %r208, %r209 }, { %r192, %r193 }, { %f307, %f308, %f309, %f310 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f311, %f312, %f313, %f314 }, { %r206, %r207, %r208, %r209 }, { %r198, %r199 }, { %f311, %f312, %f313, %f314 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f315, %f316, %f317, %f318 }, { %r206, %r207, %r208, %r209 }, { %r204, %r205 }, { %f315, %f316, %f317, %f318 };
	// end inline asm
	.loc	1 60 21
	add.s32 	%r238, %r334, 1;
	setp.lt.s32 	%p30, %r238, 2;
	selp.b32 	%r334, %r238, 0, %p30;
	.loc	1 62 22
	setp.lt.u32 	%p31, %r330, 128;
	shl.b32 	%r239, %r334, 12;
	add.s32 	%r241, %r45, %r239;
	bar.sync 	0;
	add.s32 	%r230, %r241, %r68;
	add.s32 	%r232, %r241, %r70;
	selp.b32 	%r244, 16, 0, %p31;
	selp.b32 	%r245, %r244, 0, %p1;
	selp.b32 	%r231, %r245, 0, %p29;
	// begin inline asm
	@%p3 cp.async.cg.shared.global [ %r230 + 0 ], [ %rd107 + 0 ], 0x10, %r231;
	// end inline asm
	selp.b32 	%r246, %r244, 0, %p2;
	selp.b32 	%r233, %r246, 0, %p29;
	// begin inline asm
	@%p3 cp.async.cg.shared.global [ %r232 + 0 ], [ %rd108 + 0 ], 0x10, %r233;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 60 21
	add.s32 	%r247, %r333, 1;
	setp.lt.s32 	%p32, %r247, 2;
	selp.b32 	%r333, %r247, 0, %p32;
	.loc	1 62 22
	// begin inline asm
	cp.async.wait_group 0x1;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r248, %r333, 12;
	add.s32 	%r332, %r45, %r248;
	.loc	1 60 21
	add.s64 	%rd108, %rd108, 64;
	add.s64 	%rd107, %rd107, 64;
	add.s32 	%r330, %r330, 32;
	setp.lt.u32 	%p33, %r331, 3;
	@%p33 bra 	$L__BB0_1;
	.loc	1 0 21
	cvt.u32.u64 	%r281, %rd2;
	cvt.u32.u64 	%r282, %rd1;
	.loc	1 53 34
	shl.b32 	%r284, %r1, 2;
	and.b32  	%r285, %r284, 60;
	shl.b32 	%r286, %r1, 1;
	and.b32  	%r287, %r286, 6;
	or.b32  	%r288, %r287, %r14;
	or.b32  	%r289, %r288, 49;
	.loc	1 53 21
	or.b32  	%r290, %r281, %r289;
	.loc	1 54 16
	setp.lt.s32 	%p42, %r290, %r282;
	.loc	1 53 34
	or.b32  	%r291, %r288, 48;
	.loc	1 53 21
	or.b32  	%r292, %r281, %r291;
	.loc	1 54 16
	setp.lt.s32 	%p43, %r292, %r282;
	.loc	1 53 34
	or.b32  	%r293, %r288, 33;
	.loc	1 53 21
	or.b32  	%r294, %r281, %r293;
	.loc	1 54 16
	setp.lt.s32 	%p44, %r294, %r282;
	.loc	1 53 34
	or.b32  	%r295, %r288, 32;
	.loc	1 53 21
	or.b32  	%r296, %r281, %r295;
	.loc	1 54 16
	setp.lt.s32 	%p45, %r296, %r282;
	.loc	1 53 34
	or.b32  	%r297, %r288, 17;
	or.b32  	%r298, %r288, 16;
	or.b32  	%r299, %r288, 1;
	.loc	1 53 21
	or.b32  	%r300, %r281, %r288;
	or.b32  	%r301, %r281, %r6;
	or.b32  	%r302, %r281, %r299;
	or.b32  	%r303, %r281, %r7;
	or.b32  	%r304, %r281, %r298;
	or.b32  	%r305, %r281, %r297;
	or.b32  	%r306, %r281, %r8;
	or.b32  	%r307, %r281, %r9;
	.loc	1 54 16
	setp.lt.s32 	%p46, %r307, %r282;
	setp.lt.s32 	%p47, %r306, %r282;
	setp.lt.s32 	%p48, %r305, %r282;
	setp.lt.s32 	%p49, %r304, %r282;
	setp.lt.s32 	%p50, %r303, %r282;
	setp.lt.s32 	%p51, %r302, %r282;
	setp.lt.s32 	%p52, %r301, %r282;
	setp.lt.s32 	%p53, %r300, %r282;
	.loc	1 60 21
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 70 11
	cvt.f32.f16 	%f194, %rs1;
	cvt.f32.f16 	%f195, %rs2;
	cvt.f32.f16 	%f196, %rs3;
	cvt.f32.f16 	%f197, %rs4;
	mul.f32 	%f198, %f287, %f194;
	mul.f32 	%f199, %f288, %f194;
	mul.f32 	%f200, %f289, %f195;
	mul.f32 	%f201, %f290, %f195;
	mul.f32 	%f202, %f291, %f194;
	mul.f32 	%f203, %f292, %f194;
	mul.f32 	%f204, %f293, %f195;
	mul.f32 	%f205, %f294, %f195;
	mul.f32 	%f206, %f303, %f196;
	mul.f32 	%f207, %f304, %f196;
	mul.f32 	%f208, %f305, %f197;
	mul.f32 	%f209, %f306, %f197;
	mul.f32 	%f210, %f307, %f196;
	mul.f32 	%f211, %f308, %f196;
	mul.f32 	%f212, %f309, %f197;
	mul.f32 	%f213, %f310, %f197;
	mul.f32 	%f214, %f311, %f196;
	mul.f32 	%f215, %f312, %f196;
	mul.f32 	%f216, %f313, %f197;
	mul.f32 	%f217, %f314, %f197;
	mul.f32 	%f218, %f315, %f196;
	mul.f32 	%f219, %f316, %f196;
	mul.f32 	%f220, %f317, %f197;
	mul.f32 	%f221, %f318, %f197;
	.loc	1 72 26
	setp.gt.u32 	%p54, %r6, %r288;
	setp.gt.u32 	%p55, %r6, %r299;
	setp.gt.u32 	%p56, %r7, %r288;
	setp.gt.u32 	%p57, %r7, %r299;
	setp.gt.u32 	%p58, %r6, %r298;
	setp.gt.u32 	%p59, %r6, %r297;
	setp.gt.u32 	%p60, %r7, %r298;
	setp.gt.u32 	%p61, %r7, %r297;
	setp.gt.u32 	%p62, %r8, %r295;
	setp.gt.u32 	%p63, %r8, %r293;
	setp.gt.u32 	%p64, %r9, %r295;
	setp.gt.u32 	%p65, %r9, %r293;
	setp.gt.u32 	%p66, %r8, %r291;
	setp.gt.u32 	%p67, %r8, %r289;
	setp.gt.u32 	%p68, %r9, %r291;
	setp.gt.u32 	%p69, %r9, %r289;
	.loc	1 73 29
	selp.f32 	%f222, %f198, 0f00000000, %p53;
	selp.f32 	%f223, %f222, 0f00000000, %p54;
	selp.f32 	%f224, %f223, 0f00000000, %p52;
	selp.f32 	%f225, %f199, 0f00000000, %p51;
	selp.f32 	%f226, %f225, 0f00000000, %p55;
	selp.f32 	%f227, %f226, 0f00000000, %p52;
	selp.f32 	%f228, %f200, 0f00000000, %p53;
	selp.f32 	%f229, %f228, 0f00000000, %p56;
	selp.f32 	%f230, %f229, 0f00000000, %p50;
	selp.f32 	%f231, %f201, 0f00000000, %p51;
	selp.f32 	%f232, %f231, 0f00000000, %p57;
	selp.f32 	%f233, %f232, 0f00000000, %p50;
	selp.f32 	%f234, %f202, 0f00000000, %p49;
	selp.f32 	%f235, %f234, 0f00000000, %p58;
	selp.f32 	%f236, %f235, 0f00000000, %p52;
	selp.f32 	%f237, %f203, 0f00000000, %p48;
	selp.f32 	%f238, %f237, 0f00000000, %p59;
	selp.f32 	%f239, %f238, 0f00000000, %p52;
	selp.f32 	%f240, %f204, 0f00000000, %p49;
	selp.f32 	%f241, %f240, 0f00000000, %p60;
	selp.f32 	%f242, %f241, 0f00000000, %p50;
	selp.f32 	%f243, %f205, 0f00000000, %p48;
	selp.f32 	%f244, %f243, 0f00000000, %p61;
	selp.f32 	%f245, %f244, 0f00000000, %p50;
	selp.f32 	%f246, %f206, 0f00000000, %p53;
	selp.f32 	%f247, %f246, 0f00000000, %p47;
	selp.f32 	%f248, %f207, 0f00000000, %p51;
	selp.f32 	%f249, %f248, 0f00000000, %p47;
	selp.f32 	%f250, %f208, 0f00000000, %p53;
	selp.f32 	%f251, %f250, 0f00000000, %p46;
	selp.f32 	%f252, %f209, 0f00000000, %p51;
	selp.f32 	%f253, %f252, 0f00000000, %p46;
	selp.f32 	%f254, %f210, 0f00000000, %p49;
	selp.f32 	%f255, %f254, 0f00000000, %p47;
	selp.f32 	%f256, %f211, 0f00000000, %p48;
	selp.f32 	%f257, %f256, 0f00000000, %p47;
	selp.f32 	%f258, %f212, 0f00000000, %p49;
	selp.f32 	%f259, %f258, 0f00000000, %p46;
	selp.f32 	%f260, %f213, 0f00000000, %p48;
	selp.f32 	%f261, %f260, 0f00000000, %p46;
	selp.f32 	%f262, %f214, 0f00000000, %p45;
	selp.f32 	%f263, %f262, 0f00000000, %p62;
	selp.f32 	%f264, %f263, 0f00000000, %p47;
	selp.f32 	%f265, %f215, 0f00000000, %p44;
	selp.f32 	%f266, %f265, 0f00000000, %p63;
	selp.f32 	%f267, %f266, 0f00000000, %p47;
	selp.f32 	%f268, %f216, 0f00000000, %p45;
	selp.f32 	%f269, %f268, 0f00000000, %p64;
	selp.f32 	%f270, %f269, 0f00000000, %p46;
	selp.f32 	%f271, %f217, 0f00000000, %p44;
	selp.f32 	%f272, %f271, 0f00000000, %p65;
	selp.f32 	%f273, %f272, 0f00000000, %p46;
	selp.f32 	%f274, %f218, 0f00000000, %p43;
	selp.f32 	%f275, %f274, 0f00000000, %p66;
	selp.f32 	%f276, %f275, 0f00000000, %p47;
	selp.f32 	%f277, %f219, 0f00000000, %p42;
	selp.f32 	%f278, %f277, 0f00000000, %p67;
	selp.f32 	%f279, %f278, 0f00000000, %p47;
	selp.f32 	%f280, %f220, 0f00000000, %p43;
	selp.f32 	%f281, %f280, 0f00000000, %p68;
	selp.f32 	%f282, %f281, 0f00000000, %p46;
	selp.f32 	%f283, %f221, 0f00000000, %p42;
	selp.f32 	%f284, %f283, 0f00000000, %p69;
	selp.f32 	%f285, %f284, 0f00000000, %p46;
	.loc	1 74 48
	shl.b32 	%r308, %r10, 6;
	.loc	1 74 32
	mul.wide.s32 	%rd72, %r308, 4;
	add.s64 	%rd73, %rd9, %rd72;
	.loc	1 53 34
	bfe.u32 	%r309, %r1, 4, 3;
	or.b32  	%r310, %r309, 56;
	or.b32  	%r311, %r309, 48;
	or.b32  	%r312, %r309, 40;
	or.b32  	%r313, %r309, 32;
	or.b32  	%r314, %r309, 24;
	or.b32  	%r315, %r309, 16;
	or.b32  	%r316, %r309, 8;
	cvt.u64.u32 	%rd74, %r309;
	cvt.u64.u32 	%rd75, %r316;
	cvt.u64.u32 	%rd76, %r315;
	cvt.u64.u32 	%rd77, %r314;
	cvt.u64.u32 	%rd78, %r313;
	cvt.u64.u32 	%rd79, %r312;
	cvt.u64.u32 	%rd80, %r311;
	cvt.u64.u32 	%rd81, %r310;
	.loc	1 57 18
	or.b64  	%rd82, %rd2, %rd81;
	or.b64  	%rd83, %rd2, %rd80;
	or.b64  	%rd84, %rd2, %rd79;
	or.b64  	%rd85, %rd2, %rd78;
	or.b64  	%rd86, %rd2, %rd77;
	or.b64  	%rd87, %rd2, %rd76;
	or.b64  	%rd88, %rd2, %rd75;
	or.b64  	%rd89, %rd2, %rd74;
	.loc	1 75 18
	shl.b64 	%rd90, %rd89, 12;
	mul.wide.u32 	%rd91, %r285, 4;
	or.b64  	%rd92, %rd90, %rd91;
	add.s64 	%rd64, %rd73, %rd92;
	shl.b64 	%rd93, %rd88, 12;
	or.b64  	%rd94, %rd93, %rd91;
	add.s64 	%rd65, %rd73, %rd94;
	shl.b64 	%rd95, %rd87, 12;
	or.b64  	%rd96, %rd95, %rd91;
	add.s64 	%rd66, %rd73, %rd96;
	shl.b64 	%rd97, %rd86, 12;
	or.b64  	%rd98, %rd97, %rd91;
	add.s64 	%rd67, %rd73, %rd98;
	shl.b64 	%rd99, %rd85, 12;
	or.b64  	%rd100, %rd99, %rd91;
	add.s64 	%rd68, %rd73, %rd100;
	shl.b64 	%rd101, %rd84, 12;
	or.b64  	%rd102, %rd101, %rd91;
	add.s64 	%rd69, %rd73, %rd102;
	shl.b64 	%rd103, %rd83, 12;
	or.b64  	%rd104, %rd103, %rd91;
	add.s64 	%rd70, %rd73, %rd104;
	shl.b64 	%rd105, %rd82, 12;
	or.b64  	%rd106, %rd105, %rd91;
	add.s64 	%rd71, %rd73, %rd106;
	setp.gt.s64 	%p70, %rd82, -1;
	setp.gt.s64 	%p71, %rd83, -1;
	setp.gt.s64 	%p72, %rd84, -1;
	setp.gt.s64 	%p73, %rd85, -1;
	setp.gt.s64 	%p74, %rd86, -1;
	setp.gt.s64 	%p75, %rd87, -1;
	setp.gt.s64 	%p76, %rd88, -1;
	setp.gt.s64 	%p77, %rd89, -1;
	setp.lt.s64 	%p78, %rd89, %rd1;
	setp.lt.s64 	%p79, %rd88, %rd1;
	setp.lt.s64 	%p80, %rd87, %rd1;
	setp.lt.s64 	%p81, %rd86, %rd1;
	setp.lt.s64 	%p82, %rd85, %rd1;
	setp.lt.s64 	%p83, %rd84, %rd1;
	setp.lt.s64 	%p84, %rd83, %rd1;
	setp.lt.s64 	%p85, %rd82, %rd1;
	and.pred  	%p34, %p77, %p78;
	and.pred  	%p35, %p76, %p79;
	and.pred  	%p36, %p75, %p80;
	and.pred  	%p37, %p74, %p81;
	and.pred  	%p38, %p73, %p82;
	and.pred  	%p39, %p72, %p83;
	and.pred  	%p40, %p71, %p84;
	and.pred  	%p41, %p70, %p85;
	shr.u32 	%r317, %r2, 2;
	or.b32  	%r318, %r317, %r5;
	or.b32  	%r319, %r14, %r287;
	mad.lo.s32 	%r320, %r318, 68, %r319;
	shl.b32 	%r321, %r320, 2;
	mov.u32 	%r322, global_smem;
	add.s32 	%r323, %r322, %r321;
	st.shared.v2.f32 	[%r323], {%f224, %f227};
	st.shared.v2.f32 	[%r323+2176], {%f230, %f233};
	st.shared.v2.f32 	[%r323+64], {%f236, %f239};
	st.shared.v2.f32 	[%r323+2240], {%f242, %f245};
	mov.f32 	%f286, 0f00000000;
	st.shared.v2.f32 	[%r323+128], {%f286, %f286};
	st.shared.v2.f32 	[%r323+2304], {%f286, %f286};
	st.shared.v2.f32 	[%r323+192], {%f286, %f286};
	st.shared.v2.f32 	[%r323+2368], {%f286, %f286};
	bar.sync 	0;
	shl.b32 	%r324, %r3, 1;
	and.b32  	%r325, %r324, 6;
	or.b32  	%r326, %r325, %r13;
	mad.lo.s32 	%r327, %r326, 68, %r285;
	shl.b32 	%r328, %r327, 2;
	add.s32 	%r329, %r322, %r328;
	ld.shared.v4.u32 	{%r249, %r250, %r251, %r252}, [%r329];
	ld.shared.v4.u32 	{%r253, %r254, %r255, %r256}, [%r329+2176];
	ld.shared.v4.u32 	{%r257, %r258, %r259, %r260}, [%r329+4352];
	ld.shared.v4.u32 	{%r261, %r262, %r263, %r264}, [%r329+6528];
	bar.sync 	0;
	st.shared.v2.f32 	[%r323], {%f247, %f249};
	st.shared.v2.f32 	[%r323+2176], {%f251, %f253};
	st.shared.v2.f32 	[%r323+64], {%f255, %f257};
	st.shared.v2.f32 	[%r323+2240], {%f259, %f261};
	st.shared.v2.f32 	[%r323+128], {%f264, %f267};
	st.shared.v2.f32 	[%r323+2304], {%f270, %f273};
	st.shared.v2.f32 	[%r323+192], {%f276, %f279};
	st.shared.v2.f32 	[%r323+2368], {%f282, %f285};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r265, %r266, %r267, %r268}, [%r329];
	ld.shared.v4.u32 	{%r269, %r270, %r271, %r272}, [%r329+2176];
	ld.shared.v4.u32 	{%r273, %r274, %r275, %r276}, [%r329+4352];
	ld.shared.v4.u32 	{%r277, %r278, %r279, %r280}, [%r329+6528];
	// begin inline asm
	@%p34 st.global.v4.b32 [ %rd64 + 0 ], { %r249, %r250, %r251, %r252 };
	// end inline asm
	// begin inline asm
	@%p35 st.global.v4.b32 [ %rd65 + 0 ], { %r253, %r254, %r255, %r256 };
	// end inline asm
	// begin inline asm
	@%p36 st.global.v4.b32 [ %rd66 + 0 ], { %r257, %r258, %r259, %r260 };
	// end inline asm
	// begin inline asm
	@%p37 st.global.v4.b32 [ %rd67 + 0 ], { %r261, %r262, %r263, %r264 };
	// end inline asm
	// begin inline asm
	@%p38 st.global.v4.b32 [ %rd68 + 0 ], { %r265, %r266, %r267, %r268 };
	// end inline asm
	// begin inline asm
	@%p39 st.global.v4.b32 [ %rd69 + 0 ], { %r269, %r270, %r271, %r272 };
	// end inline asm
	// begin inline asm
	@%p40 st.global.v4.b32 [ %rd70 + 0 ], { %r273, %r274, %r275, %r276 };
	// end inline asm
	// begin inline asm
	@%p41 st.global.v4.b32 [ %rd71 + 0 ], { %r277, %r278, %r279, %r280 };
	// end inline asm
	.loc	1 75 4
	ret;
$L__tmp1:
$L__func_end0:

}
	.file	1 "D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\fla\\ops\\common\\chunk_scaled_dot_kkt.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 0
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 164
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 104
.b8 117
.b8 110
.b8 107
.b8 95
.b8 115
.b8 99
.b8 97
.b8 108
.b8 101
.b8 100
.b8 95
.b8 100
.b8 111
.b8 116
.b8 95
.b8 107
.b8 107
.b8 116
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 68
.b8 58
.b8 92
.b8 85
.b8 115
.b8 101
.b8 114
.b8 115
.b8 92
.b8 76
.b8 111
.b8 117
.b8 105
.b8 115
.b8 92
.b8 80
.b8 121
.b8 99
.b8 104
.b8 97
.b8 114
.b8 109
.b8 80
.b8 114
.b8 111
.b8 106
.b8 101
.b8 99
.b8 116
.b8 115
.b8 92
.b8 77
.b8 97
.b8 115
.b8 116
.b8 101
.b8 114
.b8 95
.b8 116
.b8 104
.b8 101
.b8 115
.b8 105
.b8 115
.b8 92
.b8 66
.b8 97
.b8 98
.b8 105
.b8 108
.b8 111
.b8 110
.b8 103
.b8 95
.b8 66
.b8 101
.b8 110
.b8 99
.b8 104
.b8 109
.b8 97
.b8 114
.b8 107
.b8 92
.b8 46
.b8 118
.b8 101
.b8 110
.b8 118
.b8 92
.b8 76
.b8 105
.b8 98
.b8 92
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 92
.b8 102
.b8 108
.b8 97
.b8 92
.b8 111
.b8 112
.b8 115
.b8 92
.b8 99
.b8 111
.b8 109
.b8 109
.b8 111
.b8 110
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
	}
	.section	.debug_loc	{	}
