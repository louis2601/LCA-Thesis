//
// Generated by LLVM NVPTX Back-End
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	chunk_scaled_dot_kkt_fwd_kernel
.extern .shared .align 16 .b8 global_smem[];

.visible .entry chunk_scaled_dot_kkt_fwd_kernel(
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_0,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_1,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_2,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_3,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_4,
	.param .u32 chunk_scaled_dot_kkt_fwd_kernel_param_5
)
.maxntid 64, 1, 1
{
	.reg .pred 	%p<127>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<534>;
	.reg .f32 	%f<611>;
	.reg .b64 	%rd<164>;
	.loc	1 30 0
$L__func_begin0:
	.loc	1 30 0

	ld.param.u64 	%rd16, [chunk_scaled_dot_kkt_fwd_kernel_param_2];
	ld.param.u64 	%rd30, [chunk_scaled_dot_kkt_fwd_kernel_param_0];
	ld.param.u64 	%rd31, [chunk_scaled_dot_kkt_fwd_kernel_param_1];
$L__tmp0:
	.loc	1 45 30
	// begin inline asm
	mov.u32 %r29, %ctaid.x;
	// end inline asm
	.loc	1 45 48
	// begin inline asm
	mov.u32 %r30, %ctaid.y;
	// end inline asm
	.loc	1 46 33
	shr.s32 	%r55, %r30, 31;
	shr.u32 	%r56, %r55, 28;
	add.s32 	%r57, %r30, %r56;
	and.b32  	%r58, %r57, -16;
	sub.s32 	%r59, %r30, %r58;
	ld.param.u64 	%rd32, [chunk_scaled_dot_kkt_fwd_kernel_param_3];
	.loc	1 48 49
	shl.b32 	%r60, %r29, 1;
	ld.param.u64 	%rd33, [chunk_scaled_dot_kkt_fwd_kernel_param_4];
	.loc	1 48 43
	mul.wide.s32 	%rd34, %r60, 4;
	add.s64 	%rd17, %rd33, %rd34;
	mov.pred 	%p5, -1;
	.loc	1 48 27
	// begin inline asm
	mov.u32 %r31, 0x0;
	@%p5 ld.global.b32 { %r31 }, [ %rd17 + 0 ];
	// end inline asm
	.loc	1 48 100
	add.s64 	%rd18, %rd17, 4;
	.loc	1 48 74
	// begin inline asm
	mov.u32 %r32, 0x0;
	@%p5 ld.global.b32 { %r32 }, [ %rd18 + 0 ];
	// end inline asm
	.loc	1 49 40
	mul.wide.s32 	%rd35, %r31, 4;
	add.s64 	%rd19, %rd32, %rd35;
	.loc	1 49 27
	// begin inline asm
	mov.u32 %r33, 0x0;
	@%p5 ld.global.b32 { %r33 }, [ %rd19 + 0 ];
	// end inline asm
	.loc	1 49 86
	add.s64 	%rd20, %rd19, 4;
	.loc	1 49 67
	// begin inline asm
	mov.u32 %r34, 0x0;
	@%p5 ld.global.b32 { %r34 }, [ %rd20 + 0 ];
	// end inline asm
	.loc	1 50 18
	sub.s32 	%r61, %r34, %r33;
	.loc	1 53 16
	shl.b32 	%r62, %r32, 6;
	.loc	1 53 34
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 31;
	shr.u32 	%r3, %r1, 5;
	bfe.u32 	%r4, %r1, 2, 3;
	and.b32  	%r5, %r1, 32;
	shr.u32 	%r63, %r5, 2;
	or.b32  	%r64, %r4, %r63;
	or.b32  	%r65, %r64, 16;
	or.b32  	%r6, %r4, 32;
	or.b32  	%r66, %r6, %r63;
	or.b32  	%r67, %r64, 48;
	and.b32  	%r7, %r1, 63;
	.loc	1 56 39
	shl.b32 	%r68, %r33, 4;
	.loc	1 56 35
	mul.wide.s32 	%rd36, %r68, 2;
	add.s64 	%rd37, %rd31, %rd36;
	.loc	1 56 43
	mul.wide.s32 	%rd38, %r59, 2;
	add.s64 	%rd39, %rd37, %rd38;
	.loc	1 56 80
	cvt.s64.s32 	%rd1, %r61;
	cvt.s64.s32 	%rd2, %r62;
	cvt.u64.u32 	%rd40, %r64;
	cvt.u64.u32 	%rd41, %r65;
	cvt.u64.u32 	%rd42, %r66;
	cvt.u64.u32 	%rd43, %r67;
	cvt.u64.u32 	%rd44, %r7;
	.loc	1 57 18
	or.b64  	%rd45, %rd2, %rd40;
	or.b64  	%rd46, %rd2, %rd41;
	or.b64  	%rd47, %rd2, %rd42;
	or.b64  	%rd48, %rd2, %rd43;
	or.b64  	%rd49, %rd2, %rd44;
	shl.b64 	%rd50, %rd49, 5;
	add.s64 	%rd21, %rd39, %rd50;
	setp.gt.s64 	%p18, %rd49, -1;
	setp.lt.s64 	%p19, %rd49, %rd1;
	and.pred  	%p9, %p18, %p19;
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p9 ld.global.b16 { %rs1 }, [ %rd21 + 0 ];
	// end inline asm
	.loc	1 61 45
	add.s32 	%r8, %r68, %r59;
	.loc	1 61 52
	shl.b32 	%r69, %r8, 7;
	.loc	1 61 36
	mul.wide.s32 	%rd3, %r69, 2;
	add.s64 	%rd51, %rd30, %rd3;
	.loc	1 62 22
	shl.b32 	%r70, %r1, 3;
	and.b32  	%r71, %r70, 24;
	setp.gt.s64 	%p20, %rd45, -1;
	setp.gt.s64 	%p21, %rd46, -1;
	setp.gt.s64 	%p22, %rd47, -1;
	setp.gt.s64 	%p23, %rd48, -1;
	setp.lt.s64 	%p24, %rd45, %rd1;
	setp.lt.s64 	%p25, %rd46, %rd1;
	setp.lt.s64 	%p26, %rd47, %rd1;
	setp.lt.s64 	%p27, %rd48, %rd1;
	and.pred  	%p1, %p20, %p24;
	and.pred  	%p2, %p21, %p25;
	and.pred  	%p3, %p22, %p26;
	and.pred  	%p4, %p23, %p27;
	mul.wide.u32 	%rd52, %r71, 2;
	shl.b64 	%rd53, %rd45, 12;
	or.b64  	%rd54, %rd53, %rd52;
	add.s64 	%rd22, %rd51, %rd54;
	shl.b64 	%rd55, %rd46, 12;
	or.b64  	%rd56, %rd55, %rd52;
	add.s64 	%rd23, %rd51, %rd56;
	shl.b64 	%rd57, %rd47, 12;
	or.b64  	%rd58, %rd57, %rd52;
	add.s64 	%rd24, %rd51, %rd58;
	shl.b64 	%rd59, %rd48, 12;
	or.b64  	%rd60, %rd59, %rd52;
	add.s64 	%rd25, %rd51, %rd60;
	shl.b32 	%r72, %r64, 5;
	xor.b32  	%r73, %r1, %r70;
	and.b32  	%r74, %r73, 24;
	or.b32  	%r9, %r74, %r72;
	shl.b32 	%r75, %r9, 1;
	mov.u32 	%r52, global_smem;
	add.s32 	%r35, %r52, %r75;
	shl.b32 	%r76, %r65, 5;
	or.b32  	%r10, %r76, %r74;
	shl.b32 	%r77, %r10, 1;
	add.s32 	%r37, %r52, %r77;
	shl.b32 	%r78, %r66, 5;
	or.b32  	%r11, %r78, %r74;
	shl.b32 	%r79, %r11, 1;
	add.s32 	%r39, %r52, %r79;
	shl.b32 	%r80, %r67, 5;
	or.b32  	%r12, %r80, %r74;
	shl.b32 	%r81, %r12, 1;
	add.s32 	%r41, %r52, %r81;
	selp.b32 	%r36, 16, 0, %p1;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r35 + 0 ], [ %rd22 + 0 ], 0x10, %r36;
	// end inline asm
	selp.b32 	%r38, 16, 0, %p2;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r37 + 0 ], [ %rd23 + 0 ], 0x10, %r38;
	// end inline asm
	selp.b32 	%r40, 16, 0, %p3;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r39 + 0 ], [ %rd24 + 0 ], 0x10, %r40;
	// end inline asm
	selp.b32 	%r42, 16, 0, %p4;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r41 + 0 ], [ %rd25 + 0 ], 0x10, %r42;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	add.s64 	%rd26, %rd22, 64;
	add.s64 	%rd27, %rd23, 64;
	add.s64 	%rd28, %rd24, 64;
	add.s64 	%rd29, %rd25, 64;
	bar.sync 	0;
	add.s32 	%r82, %r52, 4096;
	add.s32 	%r43, %r82, %r75;
	add.s32 	%r45, %r82, %r77;
	add.s32 	%r47, %r82, %r79;
	add.s32 	%r49, %r82, %r81;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r43 + 0 ], [ %rd26 + 0 ], 0x10, %r36;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r45 + 0 ], [ %rd27 + 0 ], 0x10, %r38;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r47 + 0 ], [ %rd28 + 0 ], 0x10, %r40;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r49 + 0 ], [ %rd29 + 0 ], 0x10, %r42;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x1;
	// end inline asm
	bar.sync 	0;
	and.b32  	%r83, %r1, 7;
	bfe.u32 	%r84, %r1, 3, 1;
	bfe.u32 	%r13, %r1, 4, 1;
	shr.u32 	%r85, %r1, 4;
	and.b32  	%r86, %r85, 2;
	or.b32  	%r87, %r86, %r84;
	bfe.u32 	%r88, %r1, 1, 2;
	or.b32  	%r89, %r13, 2;
	or.b32  	%r90, %r84, 2;
	xor.b32  	%r91, %r13, %r88;
	shl.b32 	%r92, %r87, 8;
	shl.b32 	%r93, %r83, 5;
	or.b32  	%r94, %r92, %r93;
	shl.b32 	%r95, %r91, 3;
	or.b32  	%r14, %r95, %r94;
	xor.b32  	%r96, %r89, %r88;
	shl.b32 	%r97, %r96, 3;
	or.b32  	%r15, %r97, %r94;
	xor.b32  	%r98, %r84, %r88;
	shl.b32 	%r99, %r13, 8;
	or.b32  	%r100, %r99, %r93;
	shl.b32 	%r101, %r98, 3;
	or.b32  	%r16, %r101, %r100;
	xor.b32  	%r102, %r90, %r88;
	shl.b32 	%r103, %r102, 3;
	or.b32  	%r17, %r103, %r100;
	.loc	1 60 21
	and.b32  	%r104, %r1, 3;
	mul.wide.u32 	%rd61, %r104, 16;
	or.b64  	%rd62, %rd59, %rd61;
	add.s64 	%rd63, %rd62, %rd30;
	add.s64 	%rd163, %rd63, 128;
	or.b32  	%r105, %r64, 32;
	cvt.u64.u32 	%rd64, %r105;
	or.b64  	%rd65, %rd2, %rd64;
	shl.b64 	%rd66, %rd65, 12;
	or.b64  	%rd67, %rd66, %rd61;
	add.s64 	%rd68, %rd67, %rd30;
	add.s64 	%rd162, %rd68, 128;
	or.b64  	%rd69, %rd55, %rd61;
	add.s64 	%rd70, %rd69, %rd30;
	add.s64 	%rd161, %rd70, 128;
	or.b64  	%rd71, %rd53, %rd61;
	add.s64 	%rd72, %rd71, %rd30;
	add.s64 	%rd160, %rd72, 128;
	or.b32  	%r529, %r71, 64;
	mov.f32 	%f547, 0f00000000;
	mov.b32 	%r533, 1;
	mov.b32 	%r532, 0;
	mov.b32 	%r530, -1;
	shl.b32 	%r366, %r14, 1;
	shl.b32 	%r367, %r15, 1;
	shl.b32 	%r368, %r16, 1;
	shl.b32 	%r369, %r17, 1;
	mov.u32 	%r531, %r52;
	mov.f32 	%f548, %f547;
	mov.f32 	%f549, %f547;
	mov.f32 	%f550, %f547;
	mov.f32 	%f551, %f547;
	mov.f32 	%f552, %f547;
	mov.f32 	%f553, %f547;
	mov.f32 	%f554, %f547;
	mov.f32 	%f555, %f547;
	mov.f32 	%f556, %f547;
	mov.f32 	%f557, %f547;
	mov.f32 	%f558, %f547;
	mov.f32 	%f559, %f547;
	mov.f32 	%f560, %f547;
	mov.f32 	%f561, %f547;
	mov.f32 	%f562, %f547;
	mov.f32 	%f563, %f547;
	mov.f32 	%f564, %f547;
	mov.f32 	%f565, %f547;
	mov.f32 	%f566, %f547;
	mov.f32 	%f567, %f547;
	mov.f32 	%f568, %f547;
	mov.f32 	%f569, %f547;
	mov.f32 	%f570, %f547;
	mov.f32 	%f571, %f547;
	mov.f32 	%f572, %f547;
	mov.f32 	%f573, %f547;
	mov.f32 	%f574, %f547;
	mov.f32 	%f575, %f547;
	mov.f32 	%f576, %f547;
	mov.f32 	%f577, %f547;
	mov.f32 	%f578, %f547;
	mov.f32 	%f579, %f547;
	mov.f32 	%f580, %f547;
	mov.f32 	%f581, %f547;
	mov.f32 	%f582, %f547;
	mov.f32 	%f583, %f547;
	mov.f32 	%f584, %f547;
	mov.f32 	%f585, %f547;
	mov.f32 	%f586, %f547;
	mov.f32 	%f587, %f547;
	mov.f32 	%f588, %f547;
	mov.f32 	%f589, %f547;
	mov.f32 	%f590, %f547;
	mov.f32 	%f591, %f547;
	mov.f32 	%f592, %f547;
	mov.f32 	%f593, %f547;
	mov.f32 	%f594, %f547;
	mov.f32 	%f595, %f547;
	mov.f32 	%f596, %f547;
	mov.f32 	%f597, %f547;
	mov.f32 	%f598, %f547;
	mov.f32 	%f599, %f547;
	mov.f32 	%f600, %f547;
	mov.f32 	%f601, %f547;
	mov.f32 	%f602, %f547;
	mov.f32 	%f603, %f547;
	mov.f32 	%f604, %f547;
	mov.f32 	%f605, %f547;
	mov.f32 	%f606, %f547;
	mov.f32 	%f607, %f547;
	mov.f32 	%f608, %f547;
	mov.f32 	%f609, %f547;
	mov.f32 	%f610, %f547;
$L__BB0_1:
	add.s32 	%r530, %r530, 1;
	setp.lt.u32 	%p32, %r530, 2;
	.loc	1 62 22
	add.s32 	%r110, %r531, %r366;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r166, %r167, %r168, %r169 }, [ %r110 + 0 ];
	// end inline asm
	add.s32 	%r115, %r531, %r367;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r262, %r263, %r264, %r265 }, [ %r115 + 0 ];
	// end inline asm
	add.s32 	%r120, %r110, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r214, %r215, %r216, %r217 }, [ %r120 + 0 ];
	// end inline asm
	add.s32 	%r125, %r115, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r310, %r311, %r312, %r313 }, [ %r125 + 0 ];
	// end inline asm
	.loc	1 63 36
	add.s32 	%r130, %r531, %r368;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r170, %r171, %r176, %r177 }, [ %r130 + 0 ];
	// end inline asm
	add.s32 	%r135, %r531, %r369;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r266, %r267, %r272, %r273 }, [ %r135 + 0 ];
	// end inline asm
	add.s32 	%r140, %r130, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r182, %r183, %r188, %r189 }, [ %r140 + 0 ];
	// end inline asm
	add.s32 	%r145, %r135, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r278, %r279, %r284, %r285 }, [ %r145 + 0 ];
	// end inline asm
	add.s32 	%r150, %r130, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r194, %r195, %r200, %r201 }, [ %r150 + 0 ];
	// end inline asm
	add.s32 	%r155, %r135, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r290, %r291, %r296, %r297 }, [ %r155 + 0 ];
	// end inline asm
	add.s32 	%r160, %r130, 3072;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r206, %r207, %r212, %r213 }, [ %r160 + 0 ];
	// end inline asm
	add.s32 	%r165, %r135, 3072;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r302, %r303, %r308, %r309 }, [ %r165 + 0 ];
	// end inline asm
	.loc	1 63 27
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f547, %f548, %f549, %f550 }, { %r166, %r167, %r168, %r169 }, { %r170, %r171 }, { %f547, %f548, %f549, %f550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f551, %f552, %f553, %f554 }, { %r166, %r167, %r168, %r169 }, { %r176, %r177 }, { %f551, %f552, %f553, %f554 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f555, %f556, %f557, %f558 }, { %r166, %r167, %r168, %r169 }, { %r182, %r183 }, { %f555, %f556, %f557, %f558 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f559, %f560, %f561, %f562 }, { %r166, %r167, %r168, %r169 }, { %r188, %r189 }, { %f559, %f560, %f561, %f562 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f563, %f564, %f565, %f566 }, { %r166, %r167, %r168, %r169 }, { %r194, %r195 }, { %f563, %f564, %f565, %f566 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f567, %f568, %f569, %f570 }, { %r166, %r167, %r168, %r169 }, { %r200, %r201 }, { %f567, %f568, %f569, %f570 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f571, %f572, %f573, %f574 }, { %r166, %r167, %r168, %r169 }, { %r206, %r207 }, { %f571, %f572, %f573, %f574 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f575, %f576, %f577, %f578 }, { %r166, %r167, %r168, %r169 }, { %r212, %r213 }, { %f575, %f576, %f577, %f578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f579, %f580, %f581, %f582 }, { %r214, %r215, %r216, %r217 }, { %r170, %r171 }, { %f579, %f580, %f581, %f582 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f583, %f584, %f585, %f586 }, { %r214, %r215, %r216, %r217 }, { %r176, %r177 }, { %f583, %f584, %f585, %f586 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f587, %f588, %f589, %f590 }, { %r214, %r215, %r216, %r217 }, { %r182, %r183 }, { %f587, %f588, %f589, %f590 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f591, %f592, %f593, %f594 }, { %r214, %r215, %r216, %r217 }, { %r188, %r189 }, { %f591, %f592, %f593, %f594 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f595, %f596, %f597, %f598 }, { %r214, %r215, %r216, %r217 }, { %r194, %r195 }, { %f595, %f596, %f597, %f598 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f599, %f600, %f601, %f602 }, { %r214, %r215, %r216, %r217 }, { %r200, %r201 }, { %f599, %f600, %f601, %f602 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f603, %f604, %f605, %f606 }, { %r214, %r215, %r216, %r217 }, { %r206, %r207 }, { %f603, %f604, %f605, %f606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f607, %f608, %f609, %f610 }, { %r214, %r215, %r216, %r217 }, { %r212, %r213 }, { %f607, %f608, %f609, %f610 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f547, %f548, %f549, %f550 }, { %r262, %r263, %r264, %r265 }, { %r266, %r267 }, { %f547, %f548, %f549, %f550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f551, %f552, %f553, %f554 }, { %r262, %r263, %r264, %r265 }, { %r272, %r273 }, { %f551, %f552, %f553, %f554 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f555, %f556, %f557, %f558 }, { %r262, %r263, %r264, %r265 }, { %r278, %r279 }, { %f555, %f556, %f557, %f558 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f559, %f560, %f561, %f562 }, { %r262, %r263, %r264, %r265 }, { %r284, %r285 }, { %f559, %f560, %f561, %f562 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f563, %f564, %f565, %f566 }, { %r262, %r263, %r264, %r265 }, { %r290, %r291 }, { %f563, %f564, %f565, %f566 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f567, %f568, %f569, %f570 }, { %r262, %r263, %r264, %r265 }, { %r296, %r297 }, { %f567, %f568, %f569, %f570 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f571, %f572, %f573, %f574 }, { %r262, %r263, %r264, %r265 }, { %r302, %r303 }, { %f571, %f572, %f573, %f574 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f575, %f576, %f577, %f578 }, { %r262, %r263, %r264, %r265 }, { %r308, %r309 }, { %f575, %f576, %f577, %f578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f579, %f580, %f581, %f582 }, { %r310, %r311, %r312, %r313 }, { %r266, %r267 }, { %f579, %f580, %f581, %f582 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f583, %f584, %f585, %f586 }, { %r310, %r311, %r312, %r313 }, { %r272, %r273 }, { %f583, %f584, %f585, %f586 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f587, %f588, %f589, %f590 }, { %r310, %r311, %r312, %r313 }, { %r278, %r279 }, { %f587, %f588, %f589, %f590 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f591, %f592, %f593, %f594 }, { %r310, %r311, %r312, %r313 }, { %r284, %r285 }, { %f591, %f592, %f593, %f594 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f595, %f596, %f597, %f598 }, { %r310, %r311, %r312, %r313 }, { %r290, %r291 }, { %f595, %f596, %f597, %f598 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f599, %f600, %f601, %f602 }, { %r310, %r311, %r312, %r313 }, { %r296, %r297 }, { %f599, %f600, %f601, %f602 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f603, %f604, %f605, %f606 }, { %r310, %r311, %r312, %r313 }, { %r302, %r303 }, { %f603, %f604, %f605, %f606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f607, %f608, %f609, %f610 }, { %r310, %r311, %r312, %r313 }, { %r308, %r309 }, { %f607, %f608, %f609, %f610 };
	// end inline asm
	.loc	1 60 21
	add.s32 	%r370, %r533, 1;
	setp.lt.s32 	%p33, %r370, 2;
	selp.b32 	%r533, %r370, 0, %p33;
	add.s64 	%rd73, %rd160, %rd3;
	add.s64 	%rd74, %rd161, %rd3;
	add.s64 	%rd75, %rd162, %rd3;
	.loc	1 62 22
	add.s64 	%rd76, %rd163, %rd3;
	setp.lt.u32 	%p34, %r529, 128;
	shl.b32 	%r371, %r533, 12;
	add.s32 	%r373, %r52, %r371;
	bar.sync 	0;
	add.s32 	%r358, %r373, %r75;
	add.s32 	%r360, %r373, %r77;
	add.s32 	%r362, %r373, %r79;
	add.s32 	%r364, %r373, %r81;
	selp.b32 	%r378, 16, 0, %p34;
	selp.b32 	%r379, %r378, 0, %p1;
	selp.b32 	%r359, %r379, 0, %p32;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r358 + 0 ], [ %rd73 + 0 ], 0x10, %r359;
	// end inline asm
	selp.b32 	%r380, %r378, 0, %p2;
	selp.b32 	%r361, %r380, 0, %p32;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r360 + 0 ], [ %rd74 + 0 ], 0x10, %r361;
	// end inline asm
	selp.b32 	%r381, %r378, 0, %p3;
	selp.b32 	%r363, %r381, 0, %p32;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r362 + 0 ], [ %rd75 + 0 ], 0x10, %r363;
	// end inline asm
	selp.b32 	%r382, %r378, 0, %p4;
	selp.b32 	%r365, %r382, 0, %p32;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r364 + 0 ], [ %rd76 + 0 ], 0x10, %r365;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 60 21
	add.s32 	%r383, %r532, 1;
	setp.lt.s32 	%p35, %r383, 2;
	selp.b32 	%r532, %r383, 0, %p35;
	.loc	1 62 22
	// begin inline asm
	cp.async.wait_group 0x1;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r384, %r532, 12;
	add.s32 	%r531, %r52, %r384;
	.loc	1 60 21
	add.s64 	%rd163, %rd163, 64;
	add.s64 	%rd162, %rd162, 64;
	add.s64 	%rd161, %rd161, 64;
	add.s64 	%rd160, %rd160, 64;
	add.s32 	%r529, %r529, 32;
	setp.lt.u32 	%p36, %r530, 3;
	@%p36 bra 	$L__BB0_1;
	.loc	1 0 21
	cvt.u32.u64 	%r449, %rd2;
	cvt.u32.u64 	%r450, %rd1;
	.loc	1 53 34
	shl.b32 	%r451, %r1, 2;
	and.b32  	%r452, %r451, 60;
	shl.b32 	%r453, %r1, 1;
	shr.u32 	%r454, %r5, 1;
	and.b32  	%r455, %r453, 6;
	or.b32  	%r456, %r455, 57;
	.loc	1 53 21
	or.b32  	%r457, %r449, %r456;
	.loc	1 54 16
	setp.lt.s32 	%p53, %r457, %r450;
	.loc	1 53 34
	or.b32  	%r458, %r455, 56;
	.loc	1 53 21
	or.b32  	%r459, %r449, %r458;
	.loc	1 54 16
	setp.lt.s32 	%p54, %r459, %r450;
	.loc	1 53 34
	or.b32  	%r460, %r455, 49;
	.loc	1 53 21
	or.b32  	%r461, %r449, %r460;
	.loc	1 54 16
	setp.lt.s32 	%p55, %r461, %r450;
	.loc	1 53 34
	or.b32  	%r462, %r455, 48;
	.loc	1 53 21
	or.b32  	%r463, %r449, %r462;
	.loc	1 54 16
	setp.lt.s32 	%p56, %r463, %r450;
	.loc	1 53 34
	or.b32  	%r464, %r455, 41;
	or.b32  	%r465, %r455, 40;
	or.b32  	%r466, %r455, 33;
	or.b32  	%r467, %r455, 32;
	or.b32  	%r468, %r455, 25;
	or.b32  	%r469, %r455, 24;
	or.b32  	%r470, %r455, 17;
	or.b32  	%r471, %r455, 16;
	or.b32  	%r472, %r455, 9;
	or.b32  	%r473, %r455, 8;
	or.b32  	%r474, %r455, 1;
	or.b32  	%r475, %r4, %r454;
	or.b32  	%r476, %r475, 40;
	or.b32  	%r477, %r6, %r454;
	or.b32  	%r478, %r475, 8;
	.loc	1 53 21
	or.b32  	%r479, %r449, %r455;
	or.b32  	%r480, %r449, %r475;
	or.b32  	%r481, %r449, %r474;
	or.b32  	%r482, %r449, %r478;
	or.b32  	%r483, %r449, %r473;
	or.b32  	%r484, %r449, %r472;
	or.b32  	%r485, %r449, %r471;
	or.b32  	%r486, %r449, %r470;
	or.b32  	%r487, %r449, %r469;
	or.b32  	%r488, %r449, %r468;
	or.b32  	%r489, %r449, %r477;
	or.b32  	%r490, %r449, %r476;
	or.b32  	%r491, %r449, %r467;
	or.b32  	%r492, %r449, %r466;
	or.b32  	%r493, %r449, %r465;
	or.b32  	%r494, %r449, %r464;
	.loc	1 54 16
	setp.lt.s32 	%p57, %r494, %r450;
	setp.lt.s32 	%p58, %r493, %r450;
	setp.lt.s32 	%p59, %r492, %r450;
	setp.lt.s32 	%p60, %r491, %r450;
	setp.lt.s32 	%p61, %r490, %r450;
	setp.lt.s32 	%p62, %r489, %r450;
	setp.lt.s32 	%p63, %r488, %r450;
	setp.lt.s32 	%p64, %r487, %r450;
	setp.lt.s32 	%p65, %r486, %r450;
	setp.lt.s32 	%p66, %r485, %r450;
	setp.lt.s32 	%p67, %r484, %r450;
	setp.lt.s32 	%p68, %r483, %r450;
	setp.lt.s32 	%p69, %r482, %r450;
	setp.lt.s32 	%p70, %r481, %r450;
	setp.lt.s32 	%p71, %r480, %r450;
	setp.lt.s32 	%p72, %r479, %r450;
	.loc	1 60 21
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 70 15
	and.b32  	%r495, %r3, 1;
	shl.b32 	%r496, %r7, 1;
	mov.u32 	%r497, global_smem;
	add.s32 	%r498, %r497, %r496;
	st.shared.u16 	[%r498], %rs1;
	bar.sync 	0;
	shr.u32 	%r499, %r2, 2;
	shl.b32 	%r500, %r495, 4;
	or.b32  	%r501, %r500, %r499;
	shl.b32 	%r502, %r501, 1;
	add.s32 	%r503, %r497, %r502;
	ld.shared.b16 	%rs3, [%r503];
	ld.shared.b16 	%rs4, [%r503+16];
	ld.shared.b16 	%rs5, [%r503+64];
	ld.shared.b16 	%rs6, [%r503+80];
	.loc	1 70 11
	cvt.f32.f16 	%f386, %rs3;
	cvt.f32.f16 	%f387, %rs4;
	cvt.f32.f16 	%f388, %rs5;
	cvt.f32.f16 	%f389, %rs6;
	mul.f32 	%f390, %f547, %f386;
	mul.f32 	%f391, %f548, %f386;
	mul.f32 	%f392, %f549, %f387;
	mul.f32 	%f393, %f550, %f387;
	mul.f32 	%f394, %f551, %f386;
	mul.f32 	%f395, %f552, %f386;
	mul.f32 	%f396, %f553, %f387;
	mul.f32 	%f397, %f554, %f387;
	mul.f32 	%f398, %f555, %f386;
	mul.f32 	%f399, %f556, %f386;
	mul.f32 	%f400, %f557, %f387;
	mul.f32 	%f401, %f558, %f387;
	mul.f32 	%f402, %f561, %f387;
	mul.f32 	%f403, %f562, %f387;
	mul.f32 	%f404, %f579, %f388;
	mul.f32 	%f405, %f580, %f388;
	mul.f32 	%f406, %f581, %f389;
	mul.f32 	%f407, %f582, %f389;
	mul.f32 	%f408, %f583, %f388;
	mul.f32 	%f409, %f584, %f388;
	mul.f32 	%f410, %f585, %f389;
	mul.f32 	%f411, %f586, %f389;
	mul.f32 	%f412, %f587, %f388;
	mul.f32 	%f413, %f588, %f388;
	mul.f32 	%f414, %f589, %f389;
	mul.f32 	%f415, %f590, %f389;
	mul.f32 	%f416, %f591, %f388;
	mul.f32 	%f417, %f592, %f388;
	mul.f32 	%f418, %f593, %f389;
	mul.f32 	%f419, %f594, %f389;
	mul.f32 	%f420, %f595, %f388;
	mul.f32 	%f421, %f596, %f388;
	mul.f32 	%f422, %f597, %f389;
	mul.f32 	%f423, %f598, %f389;
	mul.f32 	%f424, %f599, %f388;
	mul.f32 	%f425, %f600, %f388;
	mul.f32 	%f426, %f601, %f389;
	mul.f32 	%f427, %f602, %f389;
	mul.f32 	%f428, %f603, %f388;
	mul.f32 	%f429, %f604, %f388;
	mul.f32 	%f430, %f605, %f389;
	mul.f32 	%f431, %f606, %f389;
	mul.f32 	%f432, %f609, %f389;
	mul.f32 	%f433, %f610, %f389;
	.loc	1 72 26
	setp.gt.u32 	%p73, %r475, %r455;
	setp.gt.u32 	%p74, %r475, %r474;
	setp.gt.u32 	%p75, %r475, %r473;
	setp.gt.u32 	%p76, %r475, %r472;
	setp.gt.u32 	%p77, %r478, %r472;
	setp.gt.u32 	%p78, %r475, %r471;
	setp.gt.u32 	%p79, %r475, %r470;
	setp.gt.u32 	%p80, %r478, %r471;
	setp.gt.u32 	%p81, %r478, %r470;
	setp.gt.u32 	%p82, %r478, %r469;
	setp.gt.u32 	%p83, %r478, %r468;
	setp.gt.u32 	%p84, %r477, %r467;
	setp.gt.u32 	%p85, %r477, %r466;
	setp.gt.u32 	%p86, %r477, %r465;
	setp.gt.u32 	%p87, %r477, %r464;
	setp.gt.u32 	%p88, %r476, %r464;
	setp.gt.u32 	%p89, %r477, %r462;
	setp.gt.u32 	%p90, %r477, %r460;
	setp.gt.u32 	%p91, %r476, %r462;
	setp.gt.u32 	%p92, %r476, %r460;
	setp.gt.u32 	%p93, %r476, %r458;
	setp.gt.u32 	%p94, %r476, %r456;
	.loc	1 73 29
	selp.f32 	%f434, %f390, 0f00000000, %p72;
	selp.f32 	%f435, %f434, 0f00000000, %p73;
	selp.f32 	%f436, %f435, 0f00000000, %p71;
	selp.f32 	%f437, %f391, 0f00000000, %p70;
	selp.f32 	%f438, %f437, 0f00000000, %p74;
	selp.f32 	%f439, %f438, 0f00000000, %p71;
	selp.f32 	%f440, %f392, 0f00000000, %p72;
	selp.f32 	%f441, %f440, 0f00000000, %p69;
	selp.f32 	%f442, %f393, 0f00000000, %p70;
	selp.f32 	%f443, %f442, 0f00000000, %p69;
	selp.f32 	%f444, %f394, 0f00000000, %p68;
	selp.f32 	%f445, %f444, 0f00000000, %p75;
	selp.f32 	%f446, %f445, 0f00000000, %p71;
	selp.f32 	%f447, %f395, 0f00000000, %p67;
	selp.f32 	%f448, %f447, 0f00000000, %p76;
	selp.f32 	%f449, %f448, 0f00000000, %p71;
	selp.f32 	%f450, %f396, 0f00000000, %p68;
	selp.f32 	%f451, %f450, 0f00000000, %p73;
	selp.f32 	%f452, %f451, 0f00000000, %p69;
	selp.f32 	%f453, %f397, 0f00000000, %p67;
	selp.f32 	%f454, %f453, 0f00000000, %p77;
	selp.f32 	%f455, %f454, 0f00000000, %p69;
	selp.f32 	%f456, %f398, 0f00000000, %p66;
	selp.f32 	%f457, %f456, 0f00000000, %p78;
	selp.f32 	%f458, %f457, 0f00000000, %p71;
	selp.f32 	%f459, %f399, 0f00000000, %p65;
	selp.f32 	%f460, %f459, 0f00000000, %p79;
	selp.f32 	%f461, %f460, 0f00000000, %p71;
	selp.f32 	%f462, %f400, 0f00000000, %p66;
	selp.f32 	%f463, %f462, 0f00000000, %p80;
	selp.f32 	%f464, %f463, 0f00000000, %p69;
	selp.f32 	%f465, %f401, 0f00000000, %p65;
	selp.f32 	%f466, %f465, 0f00000000, %p81;
	selp.f32 	%f467, %f466, 0f00000000, %p69;
	selp.f32 	%f468, %f402, 0f00000000, %p64;
	selp.f32 	%f469, %f468, 0f00000000, %p82;
	selp.f32 	%f470, %f469, 0f00000000, %p69;
	selp.f32 	%f471, %f403, 0f00000000, %p63;
	selp.f32 	%f472, %f471, 0f00000000, %p83;
	selp.f32 	%f473, %f472, 0f00000000, %p69;
	selp.f32 	%f474, %f404, 0f00000000, %p72;
	selp.f32 	%f475, %f474, 0f00000000, %p62;
	selp.f32 	%f476, %f405, 0f00000000, %p70;
	selp.f32 	%f477, %f476, 0f00000000, %p62;
	selp.f32 	%f478, %f406, 0f00000000, %p72;
	selp.f32 	%f479, %f478, 0f00000000, %p61;
	selp.f32 	%f480, %f407, 0f00000000, %p70;
	selp.f32 	%f481, %f480, 0f00000000, %p61;
	selp.f32 	%f482, %f408, 0f00000000, %p68;
	selp.f32 	%f483, %f482, 0f00000000, %p62;
	selp.f32 	%f484, %f409, 0f00000000, %p67;
	selp.f32 	%f485, %f484, 0f00000000, %p62;
	selp.f32 	%f486, %f410, 0f00000000, %p68;
	selp.f32 	%f487, %f486, 0f00000000, %p61;
	selp.f32 	%f488, %f411, 0f00000000, %p67;
	selp.f32 	%f489, %f488, 0f00000000, %p61;
	selp.f32 	%f490, %f412, 0f00000000, %p66;
	selp.f32 	%f491, %f490, 0f00000000, %p62;
	selp.f32 	%f492, %f413, 0f00000000, %p65;
	selp.f32 	%f493, %f492, 0f00000000, %p62;
	selp.f32 	%f494, %f414, 0f00000000, %p66;
	selp.f32 	%f495, %f494, 0f00000000, %p61;
	selp.f32 	%f496, %f415, 0f00000000, %p65;
	selp.f32 	%f497, %f496, 0f00000000, %p61;
	selp.f32 	%f498, %f416, 0f00000000, %p64;
	selp.f32 	%f499, %f498, 0f00000000, %p62;
	selp.f32 	%f500, %f417, 0f00000000, %p63;
	selp.f32 	%f501, %f500, 0f00000000, %p62;
	selp.f32 	%f502, %f418, 0f00000000, %p64;
	selp.f32 	%f503, %f502, 0f00000000, %p61;
	selp.f32 	%f504, %f419, 0f00000000, %p63;
	selp.f32 	%f505, %f504, 0f00000000, %p61;
	selp.f32 	%f506, %f420, 0f00000000, %p60;
	selp.f32 	%f507, %f506, 0f00000000, %p84;
	selp.f32 	%f508, %f507, 0f00000000, %p62;
	selp.f32 	%f509, %f421, 0f00000000, %p59;
	selp.f32 	%f510, %f509, 0f00000000, %p85;
	selp.f32 	%f511, %f510, 0f00000000, %p62;
	selp.f32 	%f512, %f422, 0f00000000, %p60;
	selp.f32 	%f513, %f512, 0f00000000, %p61;
	selp.f32 	%f514, %f423, 0f00000000, %p59;
	selp.f32 	%f515, %f514, 0f00000000, %p61;
	selp.f32 	%f516, %f424, 0f00000000, %p58;
	selp.f32 	%f517, %f516, 0f00000000, %p86;
	selp.f32 	%f518, %f517, 0f00000000, %p62;
	selp.f32 	%f519, %f425, 0f00000000, %p57;
	selp.f32 	%f520, %f519, 0f00000000, %p87;
	selp.f32 	%f521, %f520, 0f00000000, %p62;
	selp.f32 	%f522, %f426, 0f00000000, %p58;
	selp.f32 	%f523, %f522, 0f00000000, %p73;
	selp.f32 	%f524, %f523, 0f00000000, %p61;
	selp.f32 	%f525, %f427, 0f00000000, %p57;
	selp.f32 	%f526, %f525, 0f00000000, %p88;
	selp.f32 	%f527, %f526, 0f00000000, %p61;
	selp.f32 	%f528, %f428, 0f00000000, %p56;
	selp.f32 	%f529, %f528, 0f00000000, %p89;
	selp.f32 	%f530, %f529, 0f00000000, %p62;
	selp.f32 	%f531, %f429, 0f00000000, %p55;
	selp.f32 	%f532, %f531, 0f00000000, %p90;
	selp.f32 	%f533, %f532, 0f00000000, %p62;
	selp.f32 	%f534, %f430, 0f00000000, %p56;
	selp.f32 	%f535, %f534, 0f00000000, %p91;
	selp.f32 	%f536, %f535, 0f00000000, %p61;
	selp.f32 	%f537, %f431, 0f00000000, %p55;
	selp.f32 	%f538, %f537, 0f00000000, %p92;
	selp.f32 	%f539, %f538, 0f00000000, %p61;
	selp.f32 	%f540, %f432, 0f00000000, %p54;
	selp.f32 	%f541, %f540, 0f00000000, %p93;
	selp.f32 	%f542, %f541, 0f00000000, %p61;
	selp.f32 	%f543, %f433, 0f00000000, %p53;
	selp.f32 	%f544, %f543, 0f00000000, %p94;
	selp.f32 	%f545, %f544, 0f00000000, %p61;
	.loc	1 74 48
	shl.b32 	%r504, %r8, 6;
	.loc	1 74 32
	mul.wide.s32 	%rd93, %r504, 4;
	add.s64 	%rd94, %rd16, %rd93;
	.loc	1 53 34
	bfe.u32 	%r505, %r1, 4, 2;
	or.b32  	%r506, %r505, 60;
	or.b32  	%r507, %r505, 56;
	or.b32  	%r508, %r505, 52;
	or.b32  	%r509, %r505, 48;
	or.b32  	%r510, %r505, 44;
	or.b32  	%r511, %r505, 40;
	or.b32  	%r512, %r505, 36;
	or.b32  	%r513, %r505, 32;
	or.b32  	%r514, %r505, 28;
	or.b32  	%r515, %r505, 24;
	or.b32  	%r516, %r505, 20;
	or.b32  	%r517, %r505, 16;
	or.b32  	%r518, %r505, 12;
	or.b32  	%r519, %r505, 8;
	or.b32  	%r520, %r505, 4;
	cvt.u64.u32 	%rd95, %r505;
	cvt.u64.u32 	%rd96, %r520;
	cvt.u64.u32 	%rd97, %r519;
	cvt.u64.u32 	%rd98, %r518;
	cvt.u64.u32 	%rd99, %r517;
	cvt.u64.u32 	%rd100, %r516;
	cvt.u64.u32 	%rd101, %r515;
	cvt.u64.u32 	%rd102, %r514;
	cvt.u64.u32 	%rd103, %r513;
	cvt.u64.u32 	%rd104, %r512;
	cvt.u64.u32 	%rd105, %r511;
	cvt.u64.u32 	%rd106, %r510;
	cvt.u64.u32 	%rd107, %r509;
	cvt.u64.u32 	%rd108, %r508;
	cvt.u64.u32 	%rd109, %r507;
	cvt.u64.u32 	%rd110, %r506;
	.loc	1 57 18
	or.b64  	%rd111, %rd2, %rd110;
	or.b64  	%rd112, %rd2, %rd109;
	or.b64  	%rd113, %rd2, %rd108;
	or.b64  	%rd114, %rd2, %rd107;
	or.b64  	%rd115, %rd2, %rd106;
	or.b64  	%rd116, %rd2, %rd105;
	or.b64  	%rd117, %rd2, %rd104;
	or.b64  	%rd118, %rd2, %rd103;
	or.b64  	%rd119, %rd2, %rd102;
	or.b64  	%rd120, %rd2, %rd101;
	or.b64  	%rd121, %rd2, %rd100;
	or.b64  	%rd122, %rd2, %rd99;
	or.b64  	%rd123, %rd2, %rd98;
	or.b64  	%rd124, %rd2, %rd97;
	or.b64  	%rd125, %rd2, %rd96;
	or.b64  	%rd126, %rd2, %rd95;
	.loc	1 75 18
	shl.b64 	%rd127, %rd126, 12;
	mul.wide.u32 	%rd128, %r452, 4;
	or.b64  	%rd129, %rd127, %rd128;
	add.s64 	%rd77, %rd94, %rd129;
	shl.b64 	%rd130, %rd125, 12;
	or.b64  	%rd131, %rd130, %rd128;
	add.s64 	%rd78, %rd94, %rd131;
	shl.b64 	%rd132, %rd124, 12;
	or.b64  	%rd133, %rd132, %rd128;
	add.s64 	%rd79, %rd94, %rd133;
	shl.b64 	%rd134, %rd123, 12;
	or.b64  	%rd135, %rd134, %rd128;
	add.s64 	%rd80, %rd94, %rd135;
	shl.b64 	%rd136, %rd122, 12;
	or.b64  	%rd137, %rd136, %rd128;
	add.s64 	%rd81, %rd94, %rd137;
	shl.b64 	%rd138, %rd121, 12;
	or.b64  	%rd139, %rd138, %rd128;
	add.s64 	%rd82, %rd94, %rd139;
	shl.b64 	%rd140, %rd120, 12;
	or.b64  	%rd141, %rd140, %rd128;
	add.s64 	%rd83, %rd94, %rd141;
	shl.b64 	%rd142, %rd119, 12;
	or.b64  	%rd143, %rd142, %rd128;
	add.s64 	%rd84, %rd94, %rd143;
	shl.b64 	%rd144, %rd118, 12;
	or.b64  	%rd145, %rd144, %rd128;
	add.s64 	%rd85, %rd94, %rd145;
	shl.b64 	%rd146, %rd117, 12;
	or.b64  	%rd147, %rd146, %rd128;
	add.s64 	%rd86, %rd94, %rd147;
	shl.b64 	%rd148, %rd116, 12;
	or.b64  	%rd149, %rd148, %rd128;
	add.s64 	%rd87, %rd94, %rd149;
	shl.b64 	%rd150, %rd115, 12;
	or.b64  	%rd151, %rd150, %rd128;
	add.s64 	%rd88, %rd94, %rd151;
	shl.b64 	%rd152, %rd114, 12;
	or.b64  	%rd153, %rd152, %rd128;
	add.s64 	%rd89, %rd94, %rd153;
	shl.b64 	%rd154, %rd113, 12;
	or.b64  	%rd155, %rd154, %rd128;
	add.s64 	%rd90, %rd94, %rd155;
	shl.b64 	%rd156, %rd112, 12;
	or.b64  	%rd157, %rd156, %rd128;
	add.s64 	%rd91, %rd94, %rd157;
	shl.b64 	%rd158, %rd111, 12;
	or.b64  	%rd159, %rd158, %rd128;
	add.s64 	%rd92, %rd94, %rd159;
	setp.gt.s64 	%p95, %rd111, -1;
	setp.gt.s64 	%p96, %rd112, -1;
	setp.gt.s64 	%p97, %rd113, -1;
	setp.gt.s64 	%p98, %rd114, -1;
	setp.gt.s64 	%p99, %rd115, -1;
	setp.gt.s64 	%p100, %rd116, -1;
	setp.gt.s64 	%p101, %rd117, -1;
	setp.gt.s64 	%p102, %rd118, -1;
	setp.gt.s64 	%p103, %rd119, -1;
	setp.gt.s64 	%p104, %rd120, -1;
	setp.gt.s64 	%p105, %rd121, -1;
	setp.gt.s64 	%p106, %rd122, -1;
	setp.gt.s64 	%p107, %rd123, -1;
	setp.gt.s64 	%p108, %rd124, -1;
	setp.gt.s64 	%p109, %rd125, -1;
	setp.gt.s64 	%p110, %rd126, -1;
	setp.lt.s64 	%p111, %rd126, %rd1;
	setp.lt.s64 	%p112, %rd125, %rd1;
	setp.lt.s64 	%p113, %rd124, %rd1;
	setp.lt.s64 	%p114, %rd123, %rd1;
	setp.lt.s64 	%p115, %rd122, %rd1;
	setp.lt.s64 	%p116, %rd121, %rd1;
	setp.lt.s64 	%p117, %rd120, %rd1;
	setp.lt.s64 	%p118, %rd119, %rd1;
	setp.lt.s64 	%p119, %rd118, %rd1;
	setp.lt.s64 	%p120, %rd117, %rd1;
	setp.lt.s64 	%p121, %rd116, %rd1;
	setp.lt.s64 	%p122, %rd115, %rd1;
	setp.lt.s64 	%p123, %rd114, %rd1;
	setp.lt.s64 	%p124, %rd113, %rd1;
	setp.lt.s64 	%p125, %rd112, %rd1;
	setp.lt.s64 	%p126, %rd111, %rd1;
	and.pred  	%p37, %p110, %p111;
	and.pred  	%p38, %p109, %p112;
	and.pred  	%p39, %p108, %p113;
	and.pred  	%p40, %p107, %p114;
	and.pred  	%p41, %p106, %p115;
	and.pred  	%p42, %p105, %p116;
	and.pred  	%p43, %p104, %p117;
	and.pred  	%p44, %p103, %p118;
	and.pred  	%p45, %p102, %p119;
	and.pred  	%p46, %p101, %p120;
	and.pred  	%p47, %p100, %p121;
	and.pred  	%p48, %p99, %p122;
	and.pred  	%p49, %p98, %p123;
	and.pred  	%p50, %p97, %p124;
	and.pred  	%p51, %p96, %p125;
	and.pred  	%p52, %p95, %p126;
	bar.sync 	0;
	mad.lo.s32 	%r521, %r501, 68, %r455;
	shl.b32 	%r522, %r521, 2;
	add.s32 	%r523, %r497, %r522;
	st.shared.v2.f32 	[%r523], {%f436, %f439};
	st.shared.v2.f32 	[%r523+2176], {%f441, %f443};
	st.shared.v2.f32 	[%r523+32], {%f446, %f449};
	st.shared.v2.f32 	[%r523+2208], {%f452, %f455};
	st.shared.v2.f32 	[%r523+64], {%f458, %f461};
	st.shared.v2.f32 	[%r523+2240], {%f464, %f467};
	mov.f32 	%f546, 0f00000000;
	st.shared.v2.f32 	[%r523+96], {%f546, %f546};
	st.shared.v2.f32 	[%r523+2272], {%f470, %f473};
	st.shared.v2.f32 	[%r523+128], {%f546, %f546};
	st.shared.v2.f32 	[%r523+2304], {%f546, %f546};
	st.shared.v2.f32 	[%r523+160], {%f546, %f546};
	st.shared.v2.f32 	[%r523+2336], {%f546, %f546};
	st.shared.v2.f32 	[%r523+192], {%f546, %f546};
	st.shared.v2.f32 	[%r523+2368], {%f546, %f546};
	st.shared.v2.f32 	[%r523+224], {%f546, %f546};
	st.shared.v2.f32 	[%r523+2400], {%f546, %f546};
	bar.sync 	0;
	shl.b32 	%r524, %r495, 1;
	or.b32  	%r525, %r524, %r13;
	mad.lo.s32 	%r526, %r525, 68, %r452;
	shl.b32 	%r527, %r526, 2;
	add.s32 	%r528, %r497, %r527;
	ld.shared.v4.u32 	{%r385, %r386, %r387, %r388}, [%r528];
	ld.shared.v4.u32 	{%r389, %r390, %r391, %r392}, [%r528+1088];
	ld.shared.v4.u32 	{%r393, %r394, %r395, %r396}, [%r528+2176];
	ld.shared.v4.u32 	{%r397, %r398, %r399, %r400}, [%r528+3264];
	ld.shared.v4.u32 	{%r401, %r402, %r403, %r404}, [%r528+4352];
	ld.shared.v4.u32 	{%r405, %r406, %r407, %r408}, [%r528+5440];
	ld.shared.v4.u32 	{%r409, %r410, %r411, %r412}, [%r528+6528];
	ld.shared.v4.u32 	{%r413, %r414, %r415, %r416}, [%r528+7616];
	bar.sync 	0;
	st.shared.v2.f32 	[%r523], {%f475, %f477};
	st.shared.v2.f32 	[%r523+2176], {%f479, %f481};
	st.shared.v2.f32 	[%r523+32], {%f483, %f485};
	st.shared.v2.f32 	[%r523+2208], {%f487, %f489};
	st.shared.v2.f32 	[%r523+64], {%f491, %f493};
	st.shared.v2.f32 	[%r523+2240], {%f495, %f497};
	st.shared.v2.f32 	[%r523+96], {%f499, %f501};
	st.shared.v2.f32 	[%r523+2272], {%f503, %f505};
	st.shared.v2.f32 	[%r523+128], {%f508, %f511};
	st.shared.v2.f32 	[%r523+2304], {%f513, %f515};
	st.shared.v2.f32 	[%r523+160], {%f518, %f521};
	st.shared.v2.f32 	[%r523+2336], {%f524, %f527};
	st.shared.v2.f32 	[%r523+192], {%f530, %f533};
	st.shared.v2.f32 	[%r523+2368], {%f536, %f539};
	st.shared.v2.f32 	[%r523+224], {%f546, %f546};
	st.shared.v2.f32 	[%r523+2400], {%f542, %f545};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r417, %r418, %r419, %r420}, [%r528];
	ld.shared.v4.u32 	{%r421, %r422, %r423, %r424}, [%r528+1088];
	ld.shared.v4.u32 	{%r425, %r426, %r427, %r428}, [%r528+2176];
	ld.shared.v4.u32 	{%r429, %r430, %r431, %r432}, [%r528+3264];
	ld.shared.v4.u32 	{%r433, %r434, %r435, %r436}, [%r528+4352];
	ld.shared.v4.u32 	{%r437, %r438, %r439, %r440}, [%r528+5440];
	ld.shared.v4.u32 	{%r441, %r442, %r443, %r444}, [%r528+6528];
	ld.shared.v4.u32 	{%r445, %r446, %r447, %r448}, [%r528+7616];
	// begin inline asm
	@%p37 st.global.v4.b32 [ %rd77 + 0 ], { %r385, %r386, %r387, %r388 };
	// end inline asm
	// begin inline asm
	@%p38 st.global.v4.b32 [ %rd78 + 0 ], { %r389, %r390, %r391, %r392 };
	// end inline asm
	// begin inline asm
	@%p39 st.global.v4.b32 [ %rd79 + 0 ], { %r393, %r394, %r395, %r396 };
	// end inline asm
	// begin inline asm
	@%p40 st.global.v4.b32 [ %rd80 + 0 ], { %r397, %r398, %r399, %r400 };
	// end inline asm
	// begin inline asm
	@%p41 st.global.v4.b32 [ %rd81 + 0 ], { %r401, %r402, %r403, %r404 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd82 + 0 ], { %r405, %r406, %r407, %r408 };
	// end inline asm
	// begin inline asm
	@%p43 st.global.v4.b32 [ %rd83 + 0 ], { %r409, %r410, %r411, %r412 };
	// end inline asm
	// begin inline asm
	@%p44 st.global.v4.b32 [ %rd84 + 0 ], { %r413, %r414, %r415, %r416 };
	// end inline asm
	// begin inline asm
	@%p45 st.global.v4.b32 [ %rd85 + 0 ], { %r417, %r418, %r419, %r420 };
	// end inline asm
	// begin inline asm
	@%p46 st.global.v4.b32 [ %rd86 + 0 ], { %r421, %r422, %r423, %r424 };
	// end inline asm
	// begin inline asm
	@%p47 st.global.v4.b32 [ %rd87 + 0 ], { %r425, %r426, %r427, %r428 };
	// end inline asm
	// begin inline asm
	@%p48 st.global.v4.b32 [ %rd88 + 0 ], { %r429, %r430, %r431, %r432 };
	// end inline asm
	// begin inline asm
	@%p49 st.global.v4.b32 [ %rd89 + 0 ], { %r433, %r434, %r435, %r436 };
	// end inline asm
	// begin inline asm
	@%p50 st.global.v4.b32 [ %rd90 + 0 ], { %r437, %r438, %r439, %r440 };
	// end inline asm
	// begin inline asm
	@%p51 st.global.v4.b32 [ %rd91 + 0 ], { %r441, %r442, %r443, %r444 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v4.b32 [ %rd92 + 0 ], { %r445, %r446, %r447, %r448 };
	// end inline asm
	.loc	1 75 4
	ret;
$L__tmp1:
$L__func_end0:

}
	.file	1 "D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\fla\\ops\\common\\chunk_scaled_dot_kkt.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 0
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 164
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 104
.b8 117
.b8 110
.b8 107
.b8 95
.b8 115
.b8 99
.b8 97
.b8 108
.b8 101
.b8 100
.b8 95
.b8 100
.b8 111
.b8 116
.b8 95
.b8 107
.b8 107
.b8 116
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 68
.b8 58
.b8 92
.b8 85
.b8 115
.b8 101
.b8 114
.b8 115
.b8 92
.b8 76
.b8 111
.b8 117
.b8 105
.b8 115
.b8 92
.b8 80
.b8 121
.b8 99
.b8 104
.b8 97
.b8 114
.b8 109
.b8 80
.b8 114
.b8 111
.b8 106
.b8 101
.b8 99
.b8 116
.b8 115
.b8 92
.b8 77
.b8 97
.b8 115
.b8 116
.b8 101
.b8 114
.b8 95
.b8 116
.b8 104
.b8 101
.b8 115
.b8 105
.b8 115
.b8 92
.b8 66
.b8 97
.b8 98
.b8 105
.b8 108
.b8 111
.b8 110
.b8 103
.b8 95
.b8 66
.b8 101
.b8 110
.b8 99
.b8 104
.b8 109
.b8 97
.b8 114
.b8 107
.b8 92
.b8 46
.b8 118
.b8 101
.b8 110
.b8 118
.b8 92
.b8 76
.b8 105
.b8 98
.b8 92
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 92
.b8 102
.b8 108
.b8 97
.b8 92
.b8 111
.b8 112
.b8 115
.b8 92
.b8 99
.b8 111
.b8 109
.b8 109
.b8 111
.b8 110
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
	}
	.section	.debug_loc	{	}
