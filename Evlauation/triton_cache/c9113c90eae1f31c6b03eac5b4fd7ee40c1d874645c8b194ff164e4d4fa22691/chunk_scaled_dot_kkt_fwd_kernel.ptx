//
// Generated by LLVM NVPTX Back-End
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	chunk_scaled_dot_kkt_fwd_kernel
.extern .shared .align 16 .b8 global_smem[];

.visible .entry chunk_scaled_dot_kkt_fwd_kernel(
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_0,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_1,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_2,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_3,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_4,
	.param .u32 chunk_scaled_dot_kkt_fwd_kernel_param_5
)
.maxntid 64, 1, 1
{
	.reg .pred 	%p<131>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<544>;
	.reg .f32 	%f<611>;
	.reg .b64 	%rd<164>;
	.loc	1 30 0
$L__func_begin0:
	.loc	1 30 0

	ld.param.u64 	%rd9, [chunk_scaled_dot_kkt_fwd_kernel_param_2];
	ld.param.u64 	%rd28, [chunk_scaled_dot_kkt_fwd_kernel_param_0];
	ld.param.u64 	%rd29, [chunk_scaled_dot_kkt_fwd_kernel_param_1];
$L__tmp0:
	.loc	1 45 30
	// begin inline asm
	mov.u32 %r29, %ctaid.x;
	// end inline asm
	.loc	1 45 48
	// begin inline asm
	mov.u32 %r30, %ctaid.y;
	// end inline asm
	.loc	1 46 33
	shr.s32 	%r63, %r30, 31;
	shr.u32 	%r64, %r63, 28;
	add.s32 	%r65, %r30, %r64;
	and.b32  	%r66, %r65, -16;
	sub.s32 	%r67, %r30, %r66;
	ld.param.u64 	%rd30, [chunk_scaled_dot_kkt_fwd_kernel_param_3];
	.loc	1 48 49
	shl.b32 	%r68, %r29, 1;
	ld.param.u64 	%rd31, [chunk_scaled_dot_kkt_fwd_kernel_param_4];
	.loc	1 48 43
	mul.wide.s32 	%rd32, %r68, 4;
	add.s64 	%rd10, %rd31, %rd32;
	mov.pred 	%p5, -1;
	.loc	1 48 27
	// begin inline asm
	mov.u32 %r31, 0x0;
	@%p5 ld.global.b32 { %r31 }, [ %rd10 + 0 ];
	// end inline asm
	.loc	1 48 100
	add.s64 	%rd11, %rd10, 4;
	.loc	1 48 74
	// begin inline asm
	mov.u32 %r32, 0x0;
	@%p5 ld.global.b32 { %r32 }, [ %rd11 + 0 ];
	// end inline asm
	.loc	1 49 40
	mul.wide.s32 	%rd33, %r31, 4;
	add.s64 	%rd12, %rd30, %rd33;
	.loc	1 49 27
	// begin inline asm
	mov.u32 %r33, 0x0;
	@%p5 ld.global.b32 { %r33 }, [ %rd12 + 0 ];
	// end inline asm
	.loc	1 49 86
	add.s64 	%rd13, %rd12, 4;
	.loc	1 49 67
	// begin inline asm
	mov.u32 %r34, 0x0;
	@%p5 ld.global.b32 { %r34 }, [ %rd13 + 0 ];
	// end inline asm
	.loc	1 50 18
	sub.s32 	%r69, %r34, %r33;
	.loc	1 53 16
	shl.b32 	%r70, %r32, 6;
	.loc	1 53 34
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 31;
	shr.u32 	%r3, %r1, 5;
	bfe.u32 	%r4, %r1, 2, 3;
	and.b32  	%r5, %r1, 32;
	shr.u32 	%r71, %r5, 2;
	or.b32  	%r72, %r4, %r71;
	or.b32  	%r73, %r72, 16;
	or.b32  	%r6, %r4, 32;
	or.b32  	%r74, %r6, %r71;
	or.b32  	%r75, %r72, 48;
	and.b32  	%r7, %r1, 63;
	.loc	1 56 39
	shl.b32 	%r76, %r33, 4;
	.loc	1 56 35
	mul.wide.s32 	%rd34, %r76, 2;
	add.s64 	%rd35, %rd29, %rd34;
	.loc	1 56 43
	mul.wide.s32 	%rd36, %r67, 2;
	add.s64 	%rd37, %rd35, %rd36;
	.loc	1 56 80
	cvt.s64.s32 	%rd1, %r69;
	cvt.s64.s32 	%rd2, %r70;
	cvt.u64.u32 	%rd38, %r72;
	cvt.u64.u32 	%rd39, %r73;
	cvt.u64.u32 	%rd40, %r74;
	cvt.u64.u32 	%rd41, %r75;
	cvt.u64.u32 	%rd42, %r7;
	.loc	1 57 18
	or.b64  	%rd43, %rd2, %rd38;
	or.b64  	%rd44, %rd2, %rd39;
	or.b64  	%rd45, %rd2, %rd40;
	or.b64  	%rd46, %rd2, %rd41;
	or.b64  	%rd47, %rd2, %rd42;
	shl.b64 	%rd48, %rd47, 5;
	add.s64 	%rd14, %rd37, %rd48;
	setp.gt.s64 	%p22, %rd47, -1;
	setp.lt.s64 	%p23, %rd47, %rd1;
	and.pred  	%p9, %p22, %p23;
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p9 ld.global.b16 { %rs1 }, [ %rd14 + 0 ];
	// end inline asm
	.loc	1 61 45
	add.s32 	%r8, %r76, %r67;
	.loc	1 61 52
	shl.b32 	%r77, %r8, 7;
	.loc	1 61 36
	mul.wide.s32 	%rd49, %r77, 2;
	add.s64 	%rd50, %rd28, %rd49;
	.loc	1 62 22
	shl.b32 	%r78, %r1, 3;
	and.b32  	%r79, %r78, 24;
	setp.gt.s64 	%p24, %rd43, -1;
	setp.gt.s64 	%p25, %rd44, -1;
	setp.gt.s64 	%p26, %rd45, -1;
	setp.gt.s64 	%p27, %rd46, -1;
	setp.lt.s64 	%p28, %rd43, %rd1;
	setp.lt.s64 	%p29, %rd44, %rd1;
	setp.lt.s64 	%p30, %rd45, %rd1;
	setp.lt.s64 	%p31, %rd46, %rd1;
	and.pred  	%p1, %p24, %p28;
	and.pred  	%p2, %p25, %p29;
	and.pred  	%p3, %p26, %p30;
	and.pred  	%p4, %p27, %p31;
	mul.wide.u32 	%rd51, %r79, 2;
	shl.b64 	%rd52, %rd43, 12;
	or.b64  	%rd53, %rd52, %rd51;
	add.s64 	%rd15, %rd50, %rd53;
	shl.b64 	%rd54, %rd44, 12;
	or.b64  	%rd55, %rd54, %rd51;
	add.s64 	%rd16, %rd50, %rd55;
	shl.b64 	%rd56, %rd45, 12;
	or.b64  	%rd57, %rd56, %rd51;
	add.s64 	%rd17, %rd50, %rd57;
	shl.b64 	%rd58, %rd46, 12;
	or.b64  	%rd59, %rd58, %rd51;
	add.s64 	%rd18, %rd50, %rd59;
	shl.b32 	%r80, %r72, 5;
	xor.b32  	%r81, %r1, %r78;
	and.b32  	%r82, %r81, 24;
	or.b32  	%r9, %r82, %r80;
	shl.b32 	%r83, %r9, 1;
	mov.u32 	%r60, global_smem;
	add.s32 	%r35, %r60, %r83;
	shl.b32 	%r84, %r73, 5;
	or.b32  	%r10, %r84, %r82;
	shl.b32 	%r85, %r10, 1;
	add.s32 	%r37, %r60, %r85;
	shl.b32 	%r86, %r74, 5;
	or.b32  	%r11, %r86, %r82;
	shl.b32 	%r87, %r11, 1;
	add.s32 	%r39, %r60, %r87;
	shl.b32 	%r88, %r75, 5;
	or.b32  	%r12, %r88, %r82;
	shl.b32 	%r89, %r12, 1;
	add.s32 	%r41, %r60, %r89;
	selp.b32 	%r36, 16, 0, %p1;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r35 + 0 ], [ %rd15 + 0 ], 0x10, %r36;
	// end inline asm
	selp.b32 	%r38, 16, 0, %p2;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r37 + 0 ], [ %rd16 + 0 ], 0x10, %r38;
	// end inline asm
	selp.b32 	%r40, 16, 0, %p3;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r39 + 0 ], [ %rd17 + 0 ], 0x10, %r40;
	// end inline asm
	selp.b32 	%r42, 16, 0, %p4;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r41 + 0 ], [ %rd18 + 0 ], 0x10, %r42;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	add.s64 	%rd19, %rd15, 64;
	add.s64 	%rd20, %rd16, 64;
	add.s64 	%rd21, %rd17, 64;
	add.s64 	%rd22, %rd18, 64;
	bar.sync 	0;
	add.s32 	%r90, %r60, 4096;
	add.s32 	%r43, %r90, %r83;
	add.s32 	%r45, %r90, %r85;
	add.s32 	%r47, %r90, %r87;
	add.s32 	%r49, %r90, %r89;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r43 + 0 ], [ %rd19 + 0 ], 0x10, %r36;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r45 + 0 ], [ %rd20 + 0 ], 0x10, %r38;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r47 + 0 ], [ %rd21 + 0 ], 0x10, %r40;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r49 + 0 ], [ %rd22 + 0 ], 0x10, %r42;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	add.s64 	%rd23, %rd15, 128;
	add.s64 	%rd24, %rd16, 128;
	add.s64 	%rd25, %rd17, 128;
	add.s64 	%rd26, %rd18, 128;
	bar.sync 	0;
	add.s32 	%r91, %r60, 8192;
	add.s32 	%r51, %r91, %r83;
	add.s32 	%r53, %r91, %r85;
	add.s32 	%r55, %r91, %r87;
	add.s32 	%r57, %r91, %r89;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r51 + 0 ], [ %rd23 + 0 ], 0x10, %r36;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r53 + 0 ], [ %rd24 + 0 ], 0x10, %r38;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r55 + 0 ], [ %rd25 + 0 ], 0x10, %r40;
	// end inline asm
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r57 + 0 ], [ %rd26 + 0 ], 0x10, %r42;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x2;
	// end inline asm
	bar.sync 	0;
	and.b32  	%r92, %r1, 7;
	bfe.u32 	%r93, %r1, 3, 1;
	bfe.u32 	%r13, %r1, 4, 1;
	shr.u32 	%r94, %r1, 4;
	and.b32  	%r95, %r94, 2;
	or.b32  	%r96, %r95, %r93;
	bfe.u32 	%r97, %r1, 1, 2;
	or.b32  	%r98, %r13, 2;
	or.b32  	%r99, %r93, 2;
	xor.b32  	%r100, %r13, %r97;
	shl.b32 	%r101, %r96, 8;
	shl.b32 	%r102, %r92, 5;
	or.b32  	%r103, %r101, %r102;
	shl.b32 	%r104, %r100, 3;
	or.b32  	%r14, %r104, %r103;
	xor.b32  	%r105, %r98, %r97;
	shl.b32 	%r106, %r105, 3;
	or.b32  	%r15, %r106, %r103;
	xor.b32  	%r107, %r93, %r97;
	shl.b32 	%r108, %r13, 8;
	or.b32  	%r109, %r108, %r102;
	shl.b32 	%r110, %r107, 3;
	or.b32  	%r16, %r110, %r109;
	xor.b32  	%r111, %r99, %r97;
	shl.b32 	%r112, %r111, 3;
	or.b32  	%r17, %r112, %r109;
	.loc	1 60 21
	and.b32  	%r113, %r1, 3;
	mul.wide.u32 	%rd60, %r113, 16;
	or.b64  	%rd61, %rd58, %rd60;
	add.s64 	%rd62, %rd61, %rd49;
	add.s64 	%rd63, %rd62, %rd28;
	add.s64 	%rd3, %rd63, 192;
	or.b32  	%r114, %r72, 32;
	cvt.u64.u32 	%rd64, %r114;
	or.b64  	%rd65, %rd2, %rd64;
	shl.b64 	%rd66, %rd65, 12;
	or.b64  	%rd67, %rd66, %rd60;
	add.s64 	%rd68, %rd67, %rd49;
	add.s64 	%rd69, %rd68, %rd28;
	add.s64 	%rd4, %rd69, 192;
	or.b64  	%rd70, %rd54, %rd60;
	add.s64 	%rd71, %rd70, %rd49;
	add.s64 	%rd72, %rd71, %rd28;
	add.s64 	%rd5, %rd72, 192;
	or.b64  	%rd73, %rd52, %rd60;
	add.s64 	%rd74, %rd73, %rd49;
	add.s64 	%rd75, %rd74, %rd28;
	add.s64 	%rd6, %rd75, 192;
	or.b32  	%r539, %r79, 96;
	mov.f32 	%f547, 0f00000000;
	mov.b32 	%r543, 2;
	mov.b32 	%r542, 0;
	mov.b32 	%r540, -1;
	mov.u64 	%rd163, 0;
	shl.b32 	%r376, %r14, 1;
	shl.b32 	%r377, %r15, 1;
	shl.b32 	%r378, %r16, 1;
	shl.b32 	%r379, %r17, 1;
	mov.u32 	%r541, %r60;
	mov.f32 	%f548, %f547;
	mov.f32 	%f549, %f547;
	mov.f32 	%f550, %f547;
	mov.f32 	%f551, %f547;
	mov.f32 	%f552, %f547;
	mov.f32 	%f553, %f547;
	mov.f32 	%f554, %f547;
	mov.f32 	%f555, %f547;
	mov.f32 	%f556, %f547;
	mov.f32 	%f557, %f547;
	mov.f32 	%f558, %f547;
	mov.f32 	%f559, %f547;
	mov.f32 	%f560, %f547;
	mov.f32 	%f561, %f547;
	mov.f32 	%f562, %f547;
	mov.f32 	%f563, %f547;
	mov.f32 	%f564, %f547;
	mov.f32 	%f565, %f547;
	mov.f32 	%f566, %f547;
	mov.f32 	%f567, %f547;
	mov.f32 	%f568, %f547;
	mov.f32 	%f569, %f547;
	mov.f32 	%f570, %f547;
	mov.f32 	%f571, %f547;
	mov.f32 	%f572, %f547;
	mov.f32 	%f573, %f547;
	mov.f32 	%f574, %f547;
	mov.f32 	%f575, %f547;
	mov.f32 	%f576, %f547;
	mov.f32 	%f577, %f547;
	mov.f32 	%f578, %f547;
	mov.f32 	%f579, %f547;
	mov.f32 	%f580, %f547;
	mov.f32 	%f581, %f547;
	mov.f32 	%f582, %f547;
	mov.f32 	%f583, %f547;
	mov.f32 	%f584, %f547;
	mov.f32 	%f585, %f547;
	mov.f32 	%f586, %f547;
	mov.f32 	%f587, %f547;
	mov.f32 	%f588, %f547;
	mov.f32 	%f589, %f547;
	mov.f32 	%f590, %f547;
	mov.f32 	%f591, %f547;
	mov.f32 	%f592, %f547;
	mov.f32 	%f593, %f547;
	mov.f32 	%f594, %f547;
	mov.f32 	%f595, %f547;
	mov.f32 	%f596, %f547;
	mov.f32 	%f597, %f547;
	mov.f32 	%f598, %f547;
	mov.f32 	%f599, %f547;
	mov.f32 	%f600, %f547;
	mov.f32 	%f601, %f547;
	mov.f32 	%f602, %f547;
	mov.f32 	%f603, %f547;
	mov.f32 	%f604, %f547;
	mov.f32 	%f605, %f547;
	mov.f32 	%f606, %f547;
	mov.f32 	%f607, %f547;
	mov.f32 	%f608, %f547;
	mov.f32 	%f609, %f547;
	mov.f32 	%f610, %f547;
$L__BB0_1:
	.loc	1 0 21
	cvt.u32.u64 	%r375, %rd163;
	.loc	1 60 21
	setp.eq.s32 	%p36, %r375, 0;
	.loc	1 62 22
	add.s32 	%r119, %r541, %r376;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r175, %r176, %r177, %r178 }, [ %r119 + 0 ];
	// end inline asm
	add.s32 	%r124, %r541, %r377;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r271, %r272, %r273, %r274 }, [ %r124 + 0 ];
	// end inline asm
	add.s32 	%r129, %r119, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r223, %r224, %r225, %r226 }, [ %r129 + 0 ];
	// end inline asm
	add.s32 	%r134, %r124, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r319, %r320, %r321, %r322 }, [ %r134 + 0 ];
	// end inline asm
	.loc	1 63 36
	add.s32 	%r139, %r541, %r378;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r179, %r180, %r185, %r186 }, [ %r139 + 0 ];
	// end inline asm
	add.s32 	%r144, %r541, %r379;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r275, %r276, %r281, %r282 }, [ %r144 + 0 ];
	// end inline asm
	add.s32 	%r149, %r139, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r191, %r192, %r197, %r198 }, [ %r149 + 0 ];
	// end inline asm
	add.s32 	%r154, %r144, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r287, %r288, %r293, %r294 }, [ %r154 + 0 ];
	// end inline asm
	add.s32 	%r159, %r139, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r203, %r204, %r209, %r210 }, [ %r159 + 0 ];
	// end inline asm
	add.s32 	%r164, %r144, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r299, %r300, %r305, %r306 }, [ %r164 + 0 ];
	// end inline asm
	add.s32 	%r169, %r139, 3072;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r215, %r216, %r221, %r222 }, [ %r169 + 0 ];
	// end inline asm
	add.s32 	%r174, %r144, 3072;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r311, %r312, %r317, %r318 }, [ %r174 + 0 ];
	// end inline asm
	.loc	1 63 27
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f547, %f548, %f549, %f550 }, { %r175, %r176, %r177, %r178 }, { %r179, %r180 }, { %f547, %f548, %f549, %f550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f551, %f552, %f553, %f554 }, { %r175, %r176, %r177, %r178 }, { %r185, %r186 }, { %f551, %f552, %f553, %f554 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f555, %f556, %f557, %f558 }, { %r175, %r176, %r177, %r178 }, { %r191, %r192 }, { %f555, %f556, %f557, %f558 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f559, %f560, %f561, %f562 }, { %r175, %r176, %r177, %r178 }, { %r197, %r198 }, { %f559, %f560, %f561, %f562 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f563, %f564, %f565, %f566 }, { %r175, %r176, %r177, %r178 }, { %r203, %r204 }, { %f563, %f564, %f565, %f566 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f567, %f568, %f569, %f570 }, { %r175, %r176, %r177, %r178 }, { %r209, %r210 }, { %f567, %f568, %f569, %f570 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f571, %f572, %f573, %f574 }, { %r175, %r176, %r177, %r178 }, { %r215, %r216 }, { %f571, %f572, %f573, %f574 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f575, %f576, %f577, %f578 }, { %r175, %r176, %r177, %r178 }, { %r221, %r222 }, { %f575, %f576, %f577, %f578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f579, %f580, %f581, %f582 }, { %r223, %r224, %r225, %r226 }, { %r179, %r180 }, { %f579, %f580, %f581, %f582 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f583, %f584, %f585, %f586 }, { %r223, %r224, %r225, %r226 }, { %r185, %r186 }, { %f583, %f584, %f585, %f586 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f587, %f588, %f589, %f590 }, { %r223, %r224, %r225, %r226 }, { %r191, %r192 }, { %f587, %f588, %f589, %f590 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f591, %f592, %f593, %f594 }, { %r223, %r224, %r225, %r226 }, { %r197, %r198 }, { %f591, %f592, %f593, %f594 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f595, %f596, %f597, %f598 }, { %r223, %r224, %r225, %r226 }, { %r203, %r204 }, { %f595, %f596, %f597, %f598 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f599, %f600, %f601, %f602 }, { %r223, %r224, %r225, %r226 }, { %r209, %r210 }, { %f599, %f600, %f601, %f602 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f603, %f604, %f605, %f606 }, { %r223, %r224, %r225, %r226 }, { %r215, %r216 }, { %f603, %f604, %f605, %f606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f607, %f608, %f609, %f610 }, { %r223, %r224, %r225, %r226 }, { %r221, %r222 }, { %f607, %f608, %f609, %f610 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f547, %f548, %f549, %f550 }, { %r271, %r272, %r273, %r274 }, { %r275, %r276 }, { %f547, %f548, %f549, %f550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f551, %f552, %f553, %f554 }, { %r271, %r272, %r273, %r274 }, { %r281, %r282 }, { %f551, %f552, %f553, %f554 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f555, %f556, %f557, %f558 }, { %r271, %r272, %r273, %r274 }, { %r287, %r288 }, { %f555, %f556, %f557, %f558 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f559, %f560, %f561, %f562 }, { %r271, %r272, %r273, %r274 }, { %r293, %r294 }, { %f559, %f560, %f561, %f562 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f563, %f564, %f565, %f566 }, { %r271, %r272, %r273, %r274 }, { %r299, %r300 }, { %f563, %f564, %f565, %f566 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f567, %f568, %f569, %f570 }, { %r271, %r272, %r273, %r274 }, { %r305, %r306 }, { %f567, %f568, %f569, %f570 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f571, %f572, %f573, %f574 }, { %r271, %r272, %r273, %r274 }, { %r311, %r312 }, { %f571, %f572, %f573, %f574 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f575, %f576, %f577, %f578 }, { %r271, %r272, %r273, %r274 }, { %r317, %r318 }, { %f575, %f576, %f577, %f578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f579, %f580, %f581, %f582 }, { %r319, %r320, %r321, %r322 }, { %r275, %r276 }, { %f579, %f580, %f581, %f582 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f583, %f584, %f585, %f586 }, { %r319, %r320, %r321, %r322 }, { %r281, %r282 }, { %f583, %f584, %f585, %f586 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f587, %f588, %f589, %f590 }, { %r319, %r320, %r321, %r322 }, { %r287, %r288 }, { %f587, %f588, %f589, %f590 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f591, %f592, %f593, %f594 }, { %r319, %r320, %r321, %r322 }, { %r293, %r294 }, { %f591, %f592, %f593, %f594 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f595, %f596, %f597, %f598 }, { %r319, %r320, %r321, %r322 }, { %r299, %r300 }, { %f595, %f596, %f597, %f598 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f599, %f600, %f601, %f602 }, { %r319, %r320, %r321, %r322 }, { %r305, %r306 }, { %f599, %f600, %f601, %f602 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f603, %f604, %f605, %f606 }, { %r319, %r320, %r321, %r322 }, { %r311, %r312 }, { %f603, %f604, %f605, %f606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f607, %f608, %f609, %f610 }, { %r319, %r320, %r321, %r322 }, { %r317, %r318 }, { %f607, %f608, %f609, %f610 };
	// end inline asm
	.loc	1 60 21
	add.s32 	%r380, %r543, 1;
	setp.lt.s32 	%p37, %r380, 3;
	selp.b32 	%r543, %r380, 0, %p37;
	add.s64 	%rd76, %rd6, %rd163;
	add.s64 	%rd77, %rd5, %rd163;
	add.s64 	%rd78, %rd4, %rd163;
	.loc	1 62 22
	add.s64 	%rd79, %rd3, %rd163;
	setp.lt.u32 	%p38, %r539, 128;
	shl.b32 	%r381, %r543, 12;
	add.s32 	%r383, %r60, %r381;
	bar.sync 	0;
	add.s32 	%r367, %r383, %r83;
	add.s32 	%r369, %r383, %r85;
	add.s32 	%r371, %r383, %r87;
	add.s32 	%r373, %r383, %r89;
	selp.b32 	%r388, 16, 0, %p38;
	selp.b32 	%r389, %r388, 0, %p1;
	selp.b32 	%r368, %r389, 0, %p36;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r367 + 0 ], [ %rd76 + 0 ], 0x10, %r368;
	// end inline asm
	selp.b32 	%r390, %r388, 0, %p2;
	selp.b32 	%r370, %r390, 0, %p36;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r369 + 0 ], [ %rd77 + 0 ], 0x10, %r370;
	// end inline asm
	selp.b32 	%r391, %r388, 0, %p3;
	selp.b32 	%r372, %r391, 0, %p36;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r371 + 0 ], [ %rd78 + 0 ], 0x10, %r372;
	// end inline asm
	selp.b32 	%r392, %r388, 0, %p4;
	selp.b32 	%r374, %r392, 0, %p36;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r373 + 0 ], [ %rd79 + 0 ], 0x10, %r374;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 60 21
	add.s32 	%r393, %r542, 1;
	setp.lt.s32 	%p39, %r393, 3;
	selp.b32 	%r542, %r393, 0, %p39;
	.loc	1 62 22
	// begin inline asm
	cp.async.wait_group 0x2;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r394, %r542, 12;
	add.s32 	%r541, %r60, %r394;
	.loc	1 60 21
	add.s32 	%r540, %r540, 1;
	add.s64 	%rd163, %rd163, 64;
	add.s32 	%r539, %r539, 32;
	setp.lt.u32 	%p40, %r540, 3;
	@%p40 bra 	$L__BB0_1;
	.loc	1 0 21
	cvt.u32.u64 	%r459, %rd2;
	cvt.u32.u64 	%r460, %rd1;
	.loc	1 53 34
	shl.b32 	%r461, %r1, 2;
	and.b32  	%r462, %r461, 60;
	shl.b32 	%r463, %r1, 1;
	shr.u32 	%r464, %r5, 1;
	and.b32  	%r465, %r463, 6;
	or.b32  	%r466, %r465, 57;
	.loc	1 53 21
	or.b32  	%r467, %r459, %r466;
	.loc	1 54 16
	setp.lt.s32 	%p57, %r467, %r460;
	.loc	1 53 34
	or.b32  	%r468, %r465, 56;
	.loc	1 53 21
	or.b32  	%r469, %r459, %r468;
	.loc	1 54 16
	setp.lt.s32 	%p58, %r469, %r460;
	.loc	1 53 34
	or.b32  	%r470, %r465, 49;
	.loc	1 53 21
	or.b32  	%r471, %r459, %r470;
	.loc	1 54 16
	setp.lt.s32 	%p59, %r471, %r460;
	.loc	1 53 34
	or.b32  	%r472, %r465, 48;
	.loc	1 53 21
	or.b32  	%r473, %r459, %r472;
	.loc	1 54 16
	setp.lt.s32 	%p60, %r473, %r460;
	.loc	1 53 34
	or.b32  	%r474, %r465, 41;
	or.b32  	%r475, %r465, 40;
	or.b32  	%r476, %r465, 33;
	or.b32  	%r477, %r465, 32;
	or.b32  	%r478, %r465, 25;
	or.b32  	%r479, %r465, 24;
	or.b32  	%r480, %r465, 17;
	or.b32  	%r481, %r465, 16;
	or.b32  	%r482, %r465, 9;
	or.b32  	%r483, %r465, 8;
	or.b32  	%r484, %r465, 1;
	or.b32  	%r485, %r4, %r464;
	or.b32  	%r486, %r485, 40;
	or.b32  	%r487, %r6, %r464;
	or.b32  	%r488, %r485, 8;
	.loc	1 53 21
	or.b32  	%r489, %r459, %r465;
	or.b32  	%r490, %r459, %r485;
	or.b32  	%r491, %r459, %r484;
	or.b32  	%r492, %r459, %r488;
	or.b32  	%r493, %r459, %r483;
	or.b32  	%r494, %r459, %r482;
	or.b32  	%r495, %r459, %r481;
	or.b32  	%r496, %r459, %r480;
	or.b32  	%r497, %r459, %r479;
	or.b32  	%r498, %r459, %r478;
	or.b32  	%r499, %r459, %r487;
	or.b32  	%r500, %r459, %r486;
	or.b32  	%r501, %r459, %r477;
	or.b32  	%r502, %r459, %r476;
	or.b32  	%r503, %r459, %r475;
	or.b32  	%r504, %r459, %r474;
	.loc	1 54 16
	setp.lt.s32 	%p61, %r504, %r460;
	setp.lt.s32 	%p62, %r503, %r460;
	setp.lt.s32 	%p63, %r502, %r460;
	setp.lt.s32 	%p64, %r501, %r460;
	setp.lt.s32 	%p65, %r500, %r460;
	setp.lt.s32 	%p66, %r499, %r460;
	setp.lt.s32 	%p67, %r498, %r460;
	setp.lt.s32 	%p68, %r497, %r460;
	setp.lt.s32 	%p69, %r496, %r460;
	setp.lt.s32 	%p70, %r495, %r460;
	setp.lt.s32 	%p71, %r494, %r460;
	setp.lt.s32 	%p72, %r493, %r460;
	setp.lt.s32 	%p73, %r492, %r460;
	setp.lt.s32 	%p74, %r491, %r460;
	setp.lt.s32 	%p75, %r490, %r460;
	setp.lt.s32 	%p76, %r489, %r460;
	.loc	1 60 21
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 70 15
	and.b32  	%r505, %r3, 1;
	shl.b32 	%r506, %r7, 1;
	mov.u32 	%r507, global_smem;
	add.s32 	%r508, %r507, %r506;
	st.shared.u16 	[%r508], %rs1;
	bar.sync 	0;
	shr.u32 	%r509, %r2, 2;
	shl.b32 	%r510, %r505, 4;
	or.b32  	%r511, %r510, %r509;
	shl.b32 	%r512, %r511, 1;
	add.s32 	%r513, %r507, %r512;
	ld.shared.b16 	%rs3, [%r513];
	ld.shared.b16 	%rs4, [%r513+16];
	ld.shared.b16 	%rs5, [%r513+64];
	ld.shared.b16 	%rs6, [%r513+80];
	.loc	1 70 11
	cvt.f32.f16 	%f386, %rs3;
	cvt.f32.f16 	%f387, %rs4;
	cvt.f32.f16 	%f388, %rs5;
	cvt.f32.f16 	%f389, %rs6;
	mul.f32 	%f390, %f547, %f386;
	mul.f32 	%f391, %f548, %f386;
	mul.f32 	%f392, %f549, %f387;
	mul.f32 	%f393, %f550, %f387;
	mul.f32 	%f394, %f551, %f386;
	mul.f32 	%f395, %f552, %f386;
	mul.f32 	%f396, %f553, %f387;
	mul.f32 	%f397, %f554, %f387;
	mul.f32 	%f398, %f555, %f386;
	mul.f32 	%f399, %f556, %f386;
	mul.f32 	%f400, %f557, %f387;
	mul.f32 	%f401, %f558, %f387;
	mul.f32 	%f402, %f561, %f387;
	mul.f32 	%f403, %f562, %f387;
	mul.f32 	%f404, %f579, %f388;
	mul.f32 	%f405, %f580, %f388;
	mul.f32 	%f406, %f581, %f389;
	mul.f32 	%f407, %f582, %f389;
	mul.f32 	%f408, %f583, %f388;
	mul.f32 	%f409, %f584, %f388;
	mul.f32 	%f410, %f585, %f389;
	mul.f32 	%f411, %f586, %f389;
	mul.f32 	%f412, %f587, %f388;
	mul.f32 	%f413, %f588, %f388;
	mul.f32 	%f414, %f589, %f389;
	mul.f32 	%f415, %f590, %f389;
	mul.f32 	%f416, %f591, %f388;
	mul.f32 	%f417, %f592, %f388;
	mul.f32 	%f418, %f593, %f389;
	mul.f32 	%f419, %f594, %f389;
	mul.f32 	%f420, %f595, %f388;
	mul.f32 	%f421, %f596, %f388;
	mul.f32 	%f422, %f597, %f389;
	mul.f32 	%f423, %f598, %f389;
	mul.f32 	%f424, %f599, %f388;
	mul.f32 	%f425, %f600, %f388;
	mul.f32 	%f426, %f601, %f389;
	mul.f32 	%f427, %f602, %f389;
	mul.f32 	%f428, %f603, %f388;
	mul.f32 	%f429, %f604, %f388;
	mul.f32 	%f430, %f605, %f389;
	mul.f32 	%f431, %f606, %f389;
	mul.f32 	%f432, %f609, %f389;
	mul.f32 	%f433, %f610, %f389;
	.loc	1 72 26
	setp.gt.u32 	%p77, %r485, %r465;
	setp.gt.u32 	%p78, %r485, %r484;
	setp.gt.u32 	%p79, %r485, %r483;
	setp.gt.u32 	%p80, %r485, %r482;
	setp.gt.u32 	%p81, %r488, %r482;
	setp.gt.u32 	%p82, %r485, %r481;
	setp.gt.u32 	%p83, %r485, %r480;
	setp.gt.u32 	%p84, %r488, %r481;
	setp.gt.u32 	%p85, %r488, %r480;
	setp.gt.u32 	%p86, %r488, %r479;
	setp.gt.u32 	%p87, %r488, %r478;
	setp.gt.u32 	%p88, %r487, %r477;
	setp.gt.u32 	%p89, %r487, %r476;
	setp.gt.u32 	%p90, %r487, %r475;
	setp.gt.u32 	%p91, %r487, %r474;
	setp.gt.u32 	%p92, %r486, %r474;
	setp.gt.u32 	%p93, %r487, %r472;
	setp.gt.u32 	%p94, %r487, %r470;
	setp.gt.u32 	%p95, %r486, %r472;
	setp.gt.u32 	%p96, %r486, %r470;
	setp.gt.u32 	%p97, %r486, %r468;
	setp.gt.u32 	%p98, %r486, %r466;
	.loc	1 73 29
	selp.f32 	%f434, %f390, 0f00000000, %p76;
	selp.f32 	%f435, %f434, 0f00000000, %p77;
	selp.f32 	%f436, %f435, 0f00000000, %p75;
	selp.f32 	%f437, %f391, 0f00000000, %p74;
	selp.f32 	%f438, %f437, 0f00000000, %p78;
	selp.f32 	%f439, %f438, 0f00000000, %p75;
	selp.f32 	%f440, %f392, 0f00000000, %p76;
	selp.f32 	%f441, %f440, 0f00000000, %p73;
	selp.f32 	%f442, %f393, 0f00000000, %p74;
	selp.f32 	%f443, %f442, 0f00000000, %p73;
	selp.f32 	%f444, %f394, 0f00000000, %p72;
	selp.f32 	%f445, %f444, 0f00000000, %p79;
	selp.f32 	%f446, %f445, 0f00000000, %p75;
	selp.f32 	%f447, %f395, 0f00000000, %p71;
	selp.f32 	%f448, %f447, 0f00000000, %p80;
	selp.f32 	%f449, %f448, 0f00000000, %p75;
	selp.f32 	%f450, %f396, 0f00000000, %p72;
	selp.f32 	%f451, %f450, 0f00000000, %p77;
	selp.f32 	%f452, %f451, 0f00000000, %p73;
	selp.f32 	%f453, %f397, 0f00000000, %p71;
	selp.f32 	%f454, %f453, 0f00000000, %p81;
	selp.f32 	%f455, %f454, 0f00000000, %p73;
	selp.f32 	%f456, %f398, 0f00000000, %p70;
	selp.f32 	%f457, %f456, 0f00000000, %p82;
	selp.f32 	%f458, %f457, 0f00000000, %p75;
	selp.f32 	%f459, %f399, 0f00000000, %p69;
	selp.f32 	%f460, %f459, 0f00000000, %p83;
	selp.f32 	%f461, %f460, 0f00000000, %p75;
	selp.f32 	%f462, %f400, 0f00000000, %p70;
	selp.f32 	%f463, %f462, 0f00000000, %p84;
	selp.f32 	%f464, %f463, 0f00000000, %p73;
	selp.f32 	%f465, %f401, 0f00000000, %p69;
	selp.f32 	%f466, %f465, 0f00000000, %p85;
	selp.f32 	%f467, %f466, 0f00000000, %p73;
	selp.f32 	%f468, %f402, 0f00000000, %p68;
	selp.f32 	%f469, %f468, 0f00000000, %p86;
	selp.f32 	%f470, %f469, 0f00000000, %p73;
	selp.f32 	%f471, %f403, 0f00000000, %p67;
	selp.f32 	%f472, %f471, 0f00000000, %p87;
	selp.f32 	%f473, %f472, 0f00000000, %p73;
	selp.f32 	%f474, %f404, 0f00000000, %p76;
	selp.f32 	%f475, %f474, 0f00000000, %p66;
	selp.f32 	%f476, %f405, 0f00000000, %p74;
	selp.f32 	%f477, %f476, 0f00000000, %p66;
	selp.f32 	%f478, %f406, 0f00000000, %p76;
	selp.f32 	%f479, %f478, 0f00000000, %p65;
	selp.f32 	%f480, %f407, 0f00000000, %p74;
	selp.f32 	%f481, %f480, 0f00000000, %p65;
	selp.f32 	%f482, %f408, 0f00000000, %p72;
	selp.f32 	%f483, %f482, 0f00000000, %p66;
	selp.f32 	%f484, %f409, 0f00000000, %p71;
	selp.f32 	%f485, %f484, 0f00000000, %p66;
	selp.f32 	%f486, %f410, 0f00000000, %p72;
	selp.f32 	%f487, %f486, 0f00000000, %p65;
	selp.f32 	%f488, %f411, 0f00000000, %p71;
	selp.f32 	%f489, %f488, 0f00000000, %p65;
	selp.f32 	%f490, %f412, 0f00000000, %p70;
	selp.f32 	%f491, %f490, 0f00000000, %p66;
	selp.f32 	%f492, %f413, 0f00000000, %p69;
	selp.f32 	%f493, %f492, 0f00000000, %p66;
	selp.f32 	%f494, %f414, 0f00000000, %p70;
	selp.f32 	%f495, %f494, 0f00000000, %p65;
	selp.f32 	%f496, %f415, 0f00000000, %p69;
	selp.f32 	%f497, %f496, 0f00000000, %p65;
	selp.f32 	%f498, %f416, 0f00000000, %p68;
	selp.f32 	%f499, %f498, 0f00000000, %p66;
	selp.f32 	%f500, %f417, 0f00000000, %p67;
	selp.f32 	%f501, %f500, 0f00000000, %p66;
	selp.f32 	%f502, %f418, 0f00000000, %p68;
	selp.f32 	%f503, %f502, 0f00000000, %p65;
	selp.f32 	%f504, %f419, 0f00000000, %p67;
	selp.f32 	%f505, %f504, 0f00000000, %p65;
	selp.f32 	%f506, %f420, 0f00000000, %p64;
	selp.f32 	%f507, %f506, 0f00000000, %p88;
	selp.f32 	%f508, %f507, 0f00000000, %p66;
	selp.f32 	%f509, %f421, 0f00000000, %p63;
	selp.f32 	%f510, %f509, 0f00000000, %p89;
	selp.f32 	%f511, %f510, 0f00000000, %p66;
	selp.f32 	%f512, %f422, 0f00000000, %p64;
	selp.f32 	%f513, %f512, 0f00000000, %p65;
	selp.f32 	%f514, %f423, 0f00000000, %p63;
	selp.f32 	%f515, %f514, 0f00000000, %p65;
	selp.f32 	%f516, %f424, 0f00000000, %p62;
	selp.f32 	%f517, %f516, 0f00000000, %p90;
	selp.f32 	%f518, %f517, 0f00000000, %p66;
	selp.f32 	%f519, %f425, 0f00000000, %p61;
	selp.f32 	%f520, %f519, 0f00000000, %p91;
	selp.f32 	%f521, %f520, 0f00000000, %p66;
	selp.f32 	%f522, %f426, 0f00000000, %p62;
	selp.f32 	%f523, %f522, 0f00000000, %p77;
	selp.f32 	%f524, %f523, 0f00000000, %p65;
	selp.f32 	%f525, %f427, 0f00000000, %p61;
	selp.f32 	%f526, %f525, 0f00000000, %p92;
	selp.f32 	%f527, %f526, 0f00000000, %p65;
	selp.f32 	%f528, %f428, 0f00000000, %p60;
	selp.f32 	%f529, %f528, 0f00000000, %p93;
	selp.f32 	%f530, %f529, 0f00000000, %p66;
	selp.f32 	%f531, %f429, 0f00000000, %p59;
	selp.f32 	%f532, %f531, 0f00000000, %p94;
	selp.f32 	%f533, %f532, 0f00000000, %p66;
	selp.f32 	%f534, %f430, 0f00000000, %p60;
	selp.f32 	%f535, %f534, 0f00000000, %p95;
	selp.f32 	%f536, %f535, 0f00000000, %p65;
	selp.f32 	%f537, %f431, 0f00000000, %p59;
	selp.f32 	%f538, %f537, 0f00000000, %p96;
	selp.f32 	%f539, %f538, 0f00000000, %p65;
	selp.f32 	%f540, %f432, 0f00000000, %p58;
	selp.f32 	%f541, %f540, 0f00000000, %p97;
	selp.f32 	%f542, %f541, 0f00000000, %p65;
	selp.f32 	%f543, %f433, 0f00000000, %p57;
	selp.f32 	%f544, %f543, 0f00000000, %p98;
	selp.f32 	%f545, %f544, 0f00000000, %p65;
	.loc	1 74 48
	shl.b32 	%r514, %r8, 6;
	.loc	1 74 32
	mul.wide.s32 	%rd96, %r514, 4;
	add.s64 	%rd97, %rd9, %rd96;
	.loc	1 53 34
	bfe.u32 	%r515, %r1, 4, 2;
	or.b32  	%r516, %r515, 60;
	or.b32  	%r517, %r515, 56;
	or.b32  	%r518, %r515, 52;
	or.b32  	%r519, %r515, 48;
	or.b32  	%r520, %r515, 44;
	or.b32  	%r521, %r515, 40;
	or.b32  	%r522, %r515, 36;
	or.b32  	%r523, %r515, 32;
	or.b32  	%r524, %r515, 28;
	or.b32  	%r525, %r515, 24;
	or.b32  	%r526, %r515, 20;
	or.b32  	%r527, %r515, 16;
	or.b32  	%r528, %r515, 12;
	or.b32  	%r529, %r515, 8;
	or.b32  	%r530, %r515, 4;
	cvt.u64.u32 	%rd98, %r515;
	cvt.u64.u32 	%rd99, %r530;
	cvt.u64.u32 	%rd100, %r529;
	cvt.u64.u32 	%rd101, %r528;
	cvt.u64.u32 	%rd102, %r527;
	cvt.u64.u32 	%rd103, %r526;
	cvt.u64.u32 	%rd104, %r525;
	cvt.u64.u32 	%rd105, %r524;
	cvt.u64.u32 	%rd106, %r523;
	cvt.u64.u32 	%rd107, %r522;
	cvt.u64.u32 	%rd108, %r521;
	cvt.u64.u32 	%rd109, %r520;
	cvt.u64.u32 	%rd110, %r519;
	cvt.u64.u32 	%rd111, %r518;
	cvt.u64.u32 	%rd112, %r517;
	cvt.u64.u32 	%rd113, %r516;
	.loc	1 57 18
	or.b64  	%rd114, %rd2, %rd113;
	or.b64  	%rd115, %rd2, %rd112;
	or.b64  	%rd116, %rd2, %rd111;
	or.b64  	%rd117, %rd2, %rd110;
	or.b64  	%rd118, %rd2, %rd109;
	or.b64  	%rd119, %rd2, %rd108;
	or.b64  	%rd120, %rd2, %rd107;
	or.b64  	%rd121, %rd2, %rd106;
	or.b64  	%rd122, %rd2, %rd105;
	or.b64  	%rd123, %rd2, %rd104;
	or.b64  	%rd124, %rd2, %rd103;
	or.b64  	%rd125, %rd2, %rd102;
	or.b64  	%rd126, %rd2, %rd101;
	or.b64  	%rd127, %rd2, %rd100;
	or.b64  	%rd128, %rd2, %rd99;
	or.b64  	%rd129, %rd2, %rd98;
	.loc	1 75 18
	shl.b64 	%rd130, %rd129, 12;
	mul.wide.u32 	%rd131, %r462, 4;
	or.b64  	%rd132, %rd130, %rd131;
	add.s64 	%rd80, %rd97, %rd132;
	shl.b64 	%rd133, %rd128, 12;
	or.b64  	%rd134, %rd133, %rd131;
	add.s64 	%rd81, %rd97, %rd134;
	shl.b64 	%rd135, %rd127, 12;
	or.b64  	%rd136, %rd135, %rd131;
	add.s64 	%rd82, %rd97, %rd136;
	shl.b64 	%rd137, %rd126, 12;
	or.b64  	%rd138, %rd137, %rd131;
	add.s64 	%rd83, %rd97, %rd138;
	shl.b64 	%rd139, %rd125, 12;
	or.b64  	%rd140, %rd139, %rd131;
	add.s64 	%rd84, %rd97, %rd140;
	shl.b64 	%rd141, %rd124, 12;
	or.b64  	%rd142, %rd141, %rd131;
	add.s64 	%rd85, %rd97, %rd142;
	shl.b64 	%rd143, %rd123, 12;
	or.b64  	%rd144, %rd143, %rd131;
	add.s64 	%rd86, %rd97, %rd144;
	shl.b64 	%rd145, %rd122, 12;
	or.b64  	%rd146, %rd145, %rd131;
	add.s64 	%rd87, %rd97, %rd146;
	shl.b64 	%rd147, %rd121, 12;
	or.b64  	%rd148, %rd147, %rd131;
	add.s64 	%rd88, %rd97, %rd148;
	shl.b64 	%rd149, %rd120, 12;
	or.b64  	%rd150, %rd149, %rd131;
	add.s64 	%rd89, %rd97, %rd150;
	shl.b64 	%rd151, %rd119, 12;
	or.b64  	%rd152, %rd151, %rd131;
	add.s64 	%rd90, %rd97, %rd152;
	shl.b64 	%rd153, %rd118, 12;
	or.b64  	%rd154, %rd153, %rd131;
	add.s64 	%rd91, %rd97, %rd154;
	shl.b64 	%rd155, %rd117, 12;
	or.b64  	%rd156, %rd155, %rd131;
	add.s64 	%rd92, %rd97, %rd156;
	shl.b64 	%rd157, %rd116, 12;
	or.b64  	%rd158, %rd157, %rd131;
	add.s64 	%rd93, %rd97, %rd158;
	shl.b64 	%rd159, %rd115, 12;
	or.b64  	%rd160, %rd159, %rd131;
	add.s64 	%rd94, %rd97, %rd160;
	shl.b64 	%rd161, %rd114, 12;
	or.b64  	%rd162, %rd161, %rd131;
	add.s64 	%rd95, %rd97, %rd162;
	setp.gt.s64 	%p99, %rd114, -1;
	setp.gt.s64 	%p100, %rd115, -1;
	setp.gt.s64 	%p101, %rd116, -1;
	setp.gt.s64 	%p102, %rd117, -1;
	setp.gt.s64 	%p103, %rd118, -1;
	setp.gt.s64 	%p104, %rd119, -1;
	setp.gt.s64 	%p105, %rd120, -1;
	setp.gt.s64 	%p106, %rd121, -1;
	setp.gt.s64 	%p107, %rd122, -1;
	setp.gt.s64 	%p108, %rd123, -1;
	setp.gt.s64 	%p109, %rd124, -1;
	setp.gt.s64 	%p110, %rd125, -1;
	setp.gt.s64 	%p111, %rd126, -1;
	setp.gt.s64 	%p112, %rd127, -1;
	setp.gt.s64 	%p113, %rd128, -1;
	setp.gt.s64 	%p114, %rd129, -1;
	setp.lt.s64 	%p115, %rd129, %rd1;
	setp.lt.s64 	%p116, %rd128, %rd1;
	setp.lt.s64 	%p117, %rd127, %rd1;
	setp.lt.s64 	%p118, %rd126, %rd1;
	setp.lt.s64 	%p119, %rd125, %rd1;
	setp.lt.s64 	%p120, %rd124, %rd1;
	setp.lt.s64 	%p121, %rd123, %rd1;
	setp.lt.s64 	%p122, %rd122, %rd1;
	setp.lt.s64 	%p123, %rd121, %rd1;
	setp.lt.s64 	%p124, %rd120, %rd1;
	setp.lt.s64 	%p125, %rd119, %rd1;
	setp.lt.s64 	%p126, %rd118, %rd1;
	setp.lt.s64 	%p127, %rd117, %rd1;
	setp.lt.s64 	%p128, %rd116, %rd1;
	setp.lt.s64 	%p129, %rd115, %rd1;
	setp.lt.s64 	%p130, %rd114, %rd1;
	and.pred  	%p41, %p114, %p115;
	and.pred  	%p42, %p113, %p116;
	and.pred  	%p43, %p112, %p117;
	and.pred  	%p44, %p111, %p118;
	and.pred  	%p45, %p110, %p119;
	and.pred  	%p46, %p109, %p120;
	and.pred  	%p47, %p108, %p121;
	and.pred  	%p48, %p107, %p122;
	and.pred  	%p49, %p106, %p123;
	and.pred  	%p50, %p105, %p124;
	and.pred  	%p51, %p104, %p125;
	and.pred  	%p52, %p103, %p126;
	and.pred  	%p53, %p102, %p127;
	and.pred  	%p54, %p101, %p128;
	and.pred  	%p55, %p100, %p129;
	and.pred  	%p56, %p99, %p130;
	bar.sync 	0;
	mad.lo.s32 	%r531, %r511, 68, %r465;
	shl.b32 	%r532, %r531, 2;
	add.s32 	%r533, %r507, %r532;
	st.shared.v2.f32 	[%r533], {%f436, %f439};
	st.shared.v2.f32 	[%r533+2176], {%f441, %f443};
	st.shared.v2.f32 	[%r533+32], {%f446, %f449};
	st.shared.v2.f32 	[%r533+2208], {%f452, %f455};
	st.shared.v2.f32 	[%r533+64], {%f458, %f461};
	st.shared.v2.f32 	[%r533+2240], {%f464, %f467};
	mov.f32 	%f546, 0f00000000;
	st.shared.v2.f32 	[%r533+96], {%f546, %f546};
	st.shared.v2.f32 	[%r533+2272], {%f470, %f473};
	st.shared.v2.f32 	[%r533+128], {%f546, %f546};
	st.shared.v2.f32 	[%r533+2304], {%f546, %f546};
	st.shared.v2.f32 	[%r533+160], {%f546, %f546};
	st.shared.v2.f32 	[%r533+2336], {%f546, %f546};
	st.shared.v2.f32 	[%r533+192], {%f546, %f546};
	st.shared.v2.f32 	[%r533+2368], {%f546, %f546};
	st.shared.v2.f32 	[%r533+224], {%f546, %f546};
	st.shared.v2.f32 	[%r533+2400], {%f546, %f546};
	bar.sync 	0;
	shl.b32 	%r534, %r505, 1;
	or.b32  	%r535, %r534, %r13;
	mad.lo.s32 	%r536, %r535, 68, %r462;
	shl.b32 	%r537, %r536, 2;
	add.s32 	%r538, %r507, %r537;
	ld.shared.v4.u32 	{%r395, %r396, %r397, %r398}, [%r538];
	ld.shared.v4.u32 	{%r399, %r400, %r401, %r402}, [%r538+1088];
	ld.shared.v4.u32 	{%r403, %r404, %r405, %r406}, [%r538+2176];
	ld.shared.v4.u32 	{%r407, %r408, %r409, %r410}, [%r538+3264];
	ld.shared.v4.u32 	{%r411, %r412, %r413, %r414}, [%r538+4352];
	ld.shared.v4.u32 	{%r415, %r416, %r417, %r418}, [%r538+5440];
	ld.shared.v4.u32 	{%r419, %r420, %r421, %r422}, [%r538+6528];
	ld.shared.v4.u32 	{%r423, %r424, %r425, %r426}, [%r538+7616];
	bar.sync 	0;
	st.shared.v2.f32 	[%r533], {%f475, %f477};
	st.shared.v2.f32 	[%r533+2176], {%f479, %f481};
	st.shared.v2.f32 	[%r533+32], {%f483, %f485};
	st.shared.v2.f32 	[%r533+2208], {%f487, %f489};
	st.shared.v2.f32 	[%r533+64], {%f491, %f493};
	st.shared.v2.f32 	[%r533+2240], {%f495, %f497};
	st.shared.v2.f32 	[%r533+96], {%f499, %f501};
	st.shared.v2.f32 	[%r533+2272], {%f503, %f505};
	st.shared.v2.f32 	[%r533+128], {%f508, %f511};
	st.shared.v2.f32 	[%r533+2304], {%f513, %f515};
	st.shared.v2.f32 	[%r533+160], {%f518, %f521};
	st.shared.v2.f32 	[%r533+2336], {%f524, %f527};
	st.shared.v2.f32 	[%r533+192], {%f530, %f533};
	st.shared.v2.f32 	[%r533+2368], {%f536, %f539};
	st.shared.v2.f32 	[%r533+224], {%f546, %f546};
	st.shared.v2.f32 	[%r533+2400], {%f542, %f545};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r427, %r428, %r429, %r430}, [%r538];
	ld.shared.v4.u32 	{%r431, %r432, %r433, %r434}, [%r538+1088];
	ld.shared.v4.u32 	{%r435, %r436, %r437, %r438}, [%r538+2176];
	ld.shared.v4.u32 	{%r439, %r440, %r441, %r442}, [%r538+3264];
	ld.shared.v4.u32 	{%r443, %r444, %r445, %r446}, [%r538+4352];
	ld.shared.v4.u32 	{%r447, %r448, %r449, %r450}, [%r538+5440];
	ld.shared.v4.u32 	{%r451, %r452, %r453, %r454}, [%r538+6528];
	ld.shared.v4.u32 	{%r455, %r456, %r457, %r458}, [%r538+7616];
	// begin inline asm
	@%p41 st.global.v4.b32 [ %rd80 + 0 ], { %r395, %r396, %r397, %r398 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd81 + 0 ], { %r399, %r400, %r401, %r402 };
	// end inline asm
	// begin inline asm
	@%p43 st.global.v4.b32 [ %rd82 + 0 ], { %r403, %r404, %r405, %r406 };
	// end inline asm
	// begin inline asm
	@%p44 st.global.v4.b32 [ %rd83 + 0 ], { %r407, %r408, %r409, %r410 };
	// end inline asm
	// begin inline asm
	@%p45 st.global.v4.b32 [ %rd84 + 0 ], { %r411, %r412, %r413, %r414 };
	// end inline asm
	// begin inline asm
	@%p46 st.global.v4.b32 [ %rd85 + 0 ], { %r415, %r416, %r417, %r418 };
	// end inline asm
	// begin inline asm
	@%p47 st.global.v4.b32 [ %rd86 + 0 ], { %r419, %r420, %r421, %r422 };
	// end inline asm
	// begin inline asm
	@%p48 st.global.v4.b32 [ %rd87 + 0 ], { %r423, %r424, %r425, %r426 };
	// end inline asm
	// begin inline asm
	@%p49 st.global.v4.b32 [ %rd88 + 0 ], { %r427, %r428, %r429, %r430 };
	// end inline asm
	// begin inline asm
	@%p50 st.global.v4.b32 [ %rd89 + 0 ], { %r431, %r432, %r433, %r434 };
	// end inline asm
	// begin inline asm
	@%p51 st.global.v4.b32 [ %rd90 + 0 ], { %r435, %r436, %r437, %r438 };
	// end inline asm
	// begin inline asm
	@%p52 st.global.v4.b32 [ %rd91 + 0 ], { %r439, %r440, %r441, %r442 };
	// end inline asm
	// begin inline asm
	@%p53 st.global.v4.b32 [ %rd92 + 0 ], { %r443, %r444, %r445, %r446 };
	// end inline asm
	// begin inline asm
	@%p54 st.global.v4.b32 [ %rd93 + 0 ], { %r447, %r448, %r449, %r450 };
	// end inline asm
	// begin inline asm
	@%p55 st.global.v4.b32 [ %rd94 + 0 ], { %r451, %r452, %r453, %r454 };
	// end inline asm
	// begin inline asm
	@%p56 st.global.v4.b32 [ %rd95 + 0 ], { %r455, %r456, %r457, %r458 };
	// end inline asm
	.loc	1 75 4
	ret;
$L__tmp1:
$L__func_end0:

}
	.file	1 "D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\fla\\ops\\common\\chunk_scaled_dot_kkt.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 0
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 164
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 104
.b8 117
.b8 110
.b8 107
.b8 95
.b8 115
.b8 99
.b8 97
.b8 108
.b8 101
.b8 100
.b8 95
.b8 100
.b8 111
.b8 116
.b8 95
.b8 107
.b8 107
.b8 116
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 68
.b8 58
.b8 92
.b8 85
.b8 115
.b8 101
.b8 114
.b8 115
.b8 92
.b8 76
.b8 111
.b8 117
.b8 105
.b8 115
.b8 92
.b8 80
.b8 121
.b8 99
.b8 104
.b8 97
.b8 114
.b8 109
.b8 80
.b8 114
.b8 111
.b8 106
.b8 101
.b8 99
.b8 116
.b8 115
.b8 92
.b8 77
.b8 97
.b8 115
.b8 116
.b8 101
.b8 114
.b8 95
.b8 116
.b8 104
.b8 101
.b8 115
.b8 105
.b8 115
.b8 92
.b8 66
.b8 97
.b8 98
.b8 105
.b8 108
.b8 111
.b8 110
.b8 103
.b8 95
.b8 66
.b8 101
.b8 110
.b8 99
.b8 104
.b8 109
.b8 97
.b8 114
.b8 107
.b8 92
.b8 46
.b8 118
.b8 101
.b8 110
.b8 118
.b8 92
.b8 76
.b8 105
.b8 98
.b8 92
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 92
.b8 102
.b8 108
.b8 97
.b8 92
.b8 111
.b8 112
.b8 115
.b8 92
.b8 99
.b8 111
.b8 109
.b8 109
.b8 111
.b8 110
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
	}
	.section	.debug_loc	{	}
