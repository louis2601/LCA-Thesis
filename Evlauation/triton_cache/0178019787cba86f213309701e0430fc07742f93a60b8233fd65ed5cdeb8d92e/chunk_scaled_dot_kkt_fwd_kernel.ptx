//
// Generated by LLVM NVPTX Back-End
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	chunk_scaled_dot_kkt_fwd_kernel
.extern .shared .align 16 .b8 global_smem[];

.visible .entry chunk_scaled_dot_kkt_fwd_kernel(
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_0,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_1,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_2,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_3,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_4,
	.param .u32 chunk_scaled_dot_kkt_fwd_kernel_param_5
)
.maxntid 64, 1, 1
{
	.reg .pred 	%p<121>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<514>;
	.reg .f32 	%f<611>;
	.reg .b64 	%rd<156>;
	.loc	1 30 0
$L__func_begin0:
	.loc	1 30 0

	ld.param.u64 	%rd9, [chunk_scaled_dot_kkt_fwd_kernel_param_2];
	ld.param.u64 	%rd20, [chunk_scaled_dot_kkt_fwd_kernel_param_0];
	ld.param.u64 	%rd21, [chunk_scaled_dot_kkt_fwd_kernel_param_1];
$L__tmp0:
	.loc	1 45 30
	// begin inline asm
	mov.u32 %r31, %ctaid.x;
	// end inline asm
	.loc	1 45 48
	// begin inline asm
	mov.u32 %r32, %ctaid.y;
	// end inline asm
	.loc	1 46 33
	shr.s32 	%r46, %r32, 31;
	shr.u32 	%r47, %r46, 28;
	add.s32 	%r48, %r32, %r47;
	and.b32  	%r49, %r48, -16;
	sub.s32 	%r50, %r32, %r49;
	ld.param.u64 	%rd22, [chunk_scaled_dot_kkt_fwd_kernel_param_3];
	.loc	1 48 49
	shl.b32 	%r51, %r31, 1;
	ld.param.u64 	%rd23, [chunk_scaled_dot_kkt_fwd_kernel_param_4];
	.loc	1 48 43
	mul.wide.s32 	%rd24, %r51, 4;
	add.s64 	%rd10, %rd23, %rd24;
	mov.pred 	%p5, -1;
	.loc	1 48 27
	// begin inline asm
	mov.u32 %r33, 0x0;
	@%p5 ld.global.b32 { %r33 }, [ %rd10 + 0 ];
	// end inline asm
	.loc	1 48 100
	add.s64 	%rd11, %rd10, 4;
	.loc	1 48 74
	// begin inline asm
	mov.u32 %r34, 0x0;
	@%p5 ld.global.b32 { %r34 }, [ %rd11 + 0 ];
	// end inline asm
	.loc	1 49 40
	mul.wide.s32 	%rd25, %r33, 4;
	add.s64 	%rd12, %rd22, %rd25;
	.loc	1 49 27
	// begin inline asm
	mov.u32 %r35, 0x0;
	@%p5 ld.global.b32 { %r35 }, [ %rd12 + 0 ];
	// end inline asm
	.loc	1 49 86
	add.s64 	%rd13, %rd12, 4;
	.loc	1 49 67
	// begin inline asm
	mov.u32 %r36, 0x0;
	@%p5 ld.global.b32 { %r36 }, [ %rd13 + 0 ];
	// end inline asm
	.loc	1 50 18
	sub.s32 	%r52, %r36, %r35;
	.loc	1 53 16
	shl.b32 	%r53, %r34, 6;
	.loc	1 53 34
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 31;
	shr.u32 	%r3, %r1, 5;
	bfe.u32 	%r4, %r1, 2, 3;
	and.b32  	%r5, %r1, 32;
	shr.u32 	%r54, %r5, 2;
	or.b32  	%r55, %r4, %r54;
	or.b32  	%r56, %r55, 16;
	or.b32  	%r6, %r4, 32;
	or.b32  	%r57, %r6, %r54;
	or.b32  	%r58, %r55, 48;
	and.b32  	%r7, %r1, 63;
	.loc	1 56 39
	shl.b32 	%r59, %r35, 4;
	.loc	1 56 35
	mul.wide.s32 	%rd26, %r59, 2;
	add.s64 	%rd27, %rd21, %rd26;
	.loc	1 56 43
	mul.wide.s32 	%rd28, %r50, 2;
	add.s64 	%rd29, %rd27, %rd28;
	.loc	1 56 80
	cvt.s64.s32 	%rd1, %r52;
	cvt.s64.s32 	%rd2, %r53;
	cvt.u64.u32 	%rd30, %r55;
	cvt.u64.u32 	%rd31, %r56;
	cvt.u64.u32 	%rd32, %r57;
	cvt.u64.u32 	%rd33, %r58;
	cvt.u64.u32 	%rd34, %r7;
	.loc	1 57 18
	or.b64  	%rd35, %rd2, %rd30;
	or.b64  	%rd36, %rd2, %rd31;
	or.b64  	%rd37, %rd2, %rd32;
	or.b64  	%rd38, %rd2, %rd33;
	or.b64  	%rd39, %rd2, %rd34;
	shl.b64 	%rd40, %rd39, 5;
	add.s64 	%rd14, %rd29, %rd40;
	setp.gt.s64 	%p14, %rd39, -1;
	setp.lt.s64 	%p15, %rd39, %rd1;
	and.pred  	%p9, %p14, %p15;
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p9 ld.global.b16 { %rs1 }, [ %rd14 + 0 ];
	// end inline asm
	.loc	1 61 45
	add.s32 	%r8, %r59, %r50;
	.loc	1 61 52
	shl.b32 	%r60, %r8, 7;
	.loc	1 61 36
	mul.wide.s32 	%rd41, %r60, 2;
	add.s64 	%rd42, %rd20, %rd41;
	.loc	1 62 22
	shl.b32 	%r61, %r1, 3;
	and.b32  	%r62, %r61, 24;
	setp.gt.s64 	%p16, %rd35, -1;
	setp.gt.s64 	%p17, %rd36, -1;
	setp.gt.s64 	%p18, %rd37, -1;
	setp.gt.s64 	%p19, %rd38, -1;
	setp.lt.s64 	%p20, %rd35, %rd1;
	setp.lt.s64 	%p21, %rd36, %rd1;
	setp.lt.s64 	%p22, %rd37, %rd1;
	setp.lt.s64 	%p23, %rd38, %rd1;
	and.pred  	%p1, %p16, %p20;
	and.pred  	%p2, %p17, %p21;
	and.pred  	%p3, %p18, %p22;
	and.pred  	%p4, %p19, %p23;
	mul.wide.u32 	%rd43, %r62, 2;
	shl.b64 	%rd44, %rd35, 12;
	or.b64  	%rd45, %rd44, %rd43;
	add.s64 	%rd15, %rd42, %rd45;
	shl.b64 	%rd46, %rd36, 12;
	or.b64  	%rd47, %rd46, %rd43;
	add.s64 	%rd16, %rd42, %rd47;
	shl.b64 	%rd48, %rd37, 12;
	or.b64  	%rd49, %rd48, %rd43;
	add.s64 	%rd17, %rd42, %rd49;
	shl.b64 	%rd50, %rd38, 12;
	or.b64  	%rd51, %rd50, %rd43;
	add.s64 	%rd18, %rd42, %rd51;
	xor.b32  	%r63, %r1, %r61;
	and.b32  	%r64, %r63, 24;
	shl.b32 	%r65, %r55, 6;
	shl.b32 	%r66, %r64, 1;
	or.b32  	%r67, %r65, %r66;
	mov.u32 	%r68, global_smem;
	add.s32 	%r354, %r68, %r67;
	shl.b32 	%r69, %r56, 6;
	or.b32  	%r70, %r69, %r66;
	add.s32 	%r356, %r68, %r70;
	shl.b32 	%r71, %r57, 6;
	or.b32  	%r72, %r71, %r66;
	add.s32 	%r358, %r68, %r72;
	shl.b32 	%r73, %r58, 6;
	or.b32  	%r74, %r73, %r66;
	add.s32 	%r360, %r68, %r74;
	selp.b32 	%r38, 16, 0, %p1;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r354 + 0 ], [ %rd15 + 0 ], 0x10, %r38;
	// end inline asm
	selp.b32 	%r40, 16, 0, %p2;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r356 + 0 ], [ %rd16 + 0 ], 0x10, %r40;
	// end inline asm
	selp.b32 	%r42, 16, 0, %p3;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r358 + 0 ], [ %rd17 + 0 ], 0x10, %r42;
	// end inline asm
	selp.b32 	%r44, 16, 0, %p4;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r360 + 0 ], [ %rd18 + 0 ], 0x10, %r44;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	and.b32  	%r75, %r1, 7;
	bfe.u32 	%r76, %r1, 3, 1;
	bfe.u32 	%r13, %r1, 4, 1;
	shr.u32 	%r77, %r1, 4;
	and.b32  	%r78, %r77, 2;
	or.b32  	%r79, %r78, %r76;
	bfe.u32 	%r80, %r1, 1, 2;
	xor.b32  	%r81, %r13, %r80;
	shl.b32 	%r82, %r81, 4;
	shl.b32 	%r83, %r79, 9;
	shl.b32 	%r84, %r75, 6;
	or.b32  	%r85, %r83, %r84;
	or.b32  	%r86, %r82, %r85;
	add.s32 	%r106, %r68, %r86;
	or.b32  	%r87, %r13, 2;
	xor.b32  	%r88, %r87, %r80;
	shl.b32 	%r89, %r88, 4;
	or.b32  	%r90, %r89, %r85;
	add.s32 	%r111, %r68, %r90;
	add.s32 	%r116, %r106, 2048;
	add.s32 	%r121, %r111, 2048;
	xor.b32  	%r91, %r76, %r80;
	shl.b32 	%r92, %r91, 4;
	shl.b32 	%r93, %r13, 9;
	or.b32  	%r94, %r93, %r84;
	or.b32  	%r95, %r92, %r94;
	add.s32 	%r126, %r68, %r95;
	or.b32  	%r96, %r76, 2;
	xor.b32  	%r97, %r96, %r80;
	shl.b32 	%r98, %r97, 4;
	or.b32  	%r99, %r98, %r94;
	add.s32 	%r131, %r68, %r99;
	add.s32 	%r136, %r126, 1024;
	add.s32 	%r141, %r131, 1024;
	add.s32 	%r146, %r126, 2048;
	add.s32 	%r151, %r131, 2048;
	add.s32 	%r156, %r126, 3072;
	add.s32 	%r161, %r131, 3072;
	.loc	1 60 21
	or.b32  	%r512, %r62, 32;
	and.b32  	%r100, %r1, 3;
	mul.wide.u32 	%rd52, %r100, 16;
	or.b64  	%rd53, %rd50, %rd52;
	add.s64 	%rd54, %rd53, %rd41;
	add.s64 	%rd55, %rd54, %rd20;
	add.s64 	%rd3, %rd55, 64;
	or.b32  	%r101, %r55, 32;
	cvt.u64.u32 	%rd56, %r101;
	or.b64  	%rd57, %rd2, %rd56;
	shl.b64 	%rd58, %rd57, 12;
	or.b64  	%rd59, %rd58, %rd52;
	add.s64 	%rd60, %rd59, %rd41;
	add.s64 	%rd61, %rd60, %rd20;
	add.s64 	%rd4, %rd61, 64;
	or.b64  	%rd62, %rd46, %rd52;
	add.s64 	%rd63, %rd62, %rd41;
	add.s64 	%rd64, %rd63, %rd20;
	add.s64 	%rd5, %rd64, 64;
	or.b64  	%rd65, %rd44, %rd52;
	add.s64 	%rd66, %rd65, %rd41;
	add.s64 	%rd67, %rd66, %rd20;
	add.s64 	%rd6, %rd67, 64;
	mov.f32 	%f547, 0f00000000;
	mov.b32 	%r513, -1;
	mov.u64 	%rd155, 0;
	mov.f32 	%f548, %f547;
	mov.f32 	%f549, %f547;
	mov.f32 	%f550, %f547;
	mov.f32 	%f551, %f547;
	mov.f32 	%f552, %f547;
	mov.f32 	%f553, %f547;
	mov.f32 	%f554, %f547;
	mov.f32 	%f555, %f547;
	mov.f32 	%f556, %f547;
	mov.f32 	%f557, %f547;
	mov.f32 	%f558, %f547;
	mov.f32 	%f559, %f547;
	mov.f32 	%f560, %f547;
	mov.f32 	%f561, %f547;
	mov.f32 	%f562, %f547;
	mov.f32 	%f563, %f547;
	mov.f32 	%f564, %f547;
	mov.f32 	%f565, %f547;
	mov.f32 	%f566, %f547;
	mov.f32 	%f567, %f547;
	mov.f32 	%f568, %f547;
	mov.f32 	%f569, %f547;
	mov.f32 	%f570, %f547;
	mov.f32 	%f571, %f547;
	mov.f32 	%f572, %f547;
	mov.f32 	%f573, %f547;
	mov.f32 	%f574, %f547;
	mov.f32 	%f575, %f547;
	mov.f32 	%f576, %f547;
	mov.f32 	%f577, %f547;
	mov.f32 	%f578, %f547;
	mov.f32 	%f579, %f547;
	mov.f32 	%f580, %f547;
	mov.f32 	%f581, %f547;
	mov.f32 	%f582, %f547;
	mov.f32 	%f583, %f547;
	mov.f32 	%f584, %f547;
	mov.f32 	%f585, %f547;
	mov.f32 	%f586, %f547;
	mov.f32 	%f587, %f547;
	mov.f32 	%f588, %f547;
	mov.f32 	%f589, %f547;
	mov.f32 	%f590, %f547;
	mov.f32 	%f591, %f547;
	mov.f32 	%f592, %f547;
	mov.f32 	%f593, %f547;
	mov.f32 	%f594, %f547;
	mov.f32 	%f595, %f547;
	mov.f32 	%f596, %f547;
	mov.f32 	%f597, %f547;
	mov.f32 	%f598, %f547;
	mov.f32 	%f599, %f547;
	mov.f32 	%f600, %f547;
	mov.f32 	%f601, %f547;
	mov.f32 	%f602, %f547;
	mov.f32 	%f603, %f547;
	mov.f32 	%f604, %f547;
	mov.f32 	%f605, %f547;
	mov.f32 	%f606, %f547;
	mov.f32 	%f607, %f547;
	mov.f32 	%f608, %f547;
	mov.f32 	%f609, %f547;
	mov.f32 	%f610, %f547;
$L__BB0_1:
	.loc	1 0 21
	cvt.u32.u64 	%r362, %rd155;
	.loc	1 60 21
	setp.ne.s32 	%p28, %r362, 192;
	.loc	1 62 22
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r162, %r163, %r164, %r165 }, [ %r106 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r258, %r259, %r260, %r261 }, [ %r111 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r210, %r211, %r212, %r213 }, [ %r116 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r306, %r307, %r308, %r309 }, [ %r121 + 0 ];
	// end inline asm
	.loc	1 63 36
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r166, %r167, %r172, %r173 }, [ %r126 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r262, %r263, %r268, %r269 }, [ %r131 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r178, %r179, %r184, %r185 }, [ %r136 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r274, %r275, %r280, %r281 }, [ %r141 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r190, %r191, %r196, %r197 }, [ %r146 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r286, %r287, %r292, %r293 }, [ %r151 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r202, %r203, %r208, %r209 }, [ %r156 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r298, %r299, %r304, %r305 }, [ %r161 + 0 ];
	// end inline asm
	.loc	1 63 27
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f547, %f548, %f549, %f550 }, { %r162, %r163, %r164, %r165 }, { %r166, %r167 }, { %f547, %f548, %f549, %f550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f551, %f552, %f553, %f554 }, { %r162, %r163, %r164, %r165 }, { %r172, %r173 }, { %f551, %f552, %f553, %f554 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f555, %f556, %f557, %f558 }, { %r162, %r163, %r164, %r165 }, { %r178, %r179 }, { %f555, %f556, %f557, %f558 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f559, %f560, %f561, %f562 }, { %r162, %r163, %r164, %r165 }, { %r184, %r185 }, { %f559, %f560, %f561, %f562 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f563, %f564, %f565, %f566 }, { %r162, %r163, %r164, %r165 }, { %r190, %r191 }, { %f563, %f564, %f565, %f566 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f567, %f568, %f569, %f570 }, { %r162, %r163, %r164, %r165 }, { %r196, %r197 }, { %f567, %f568, %f569, %f570 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f571, %f572, %f573, %f574 }, { %r162, %r163, %r164, %r165 }, { %r202, %r203 }, { %f571, %f572, %f573, %f574 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f575, %f576, %f577, %f578 }, { %r162, %r163, %r164, %r165 }, { %r208, %r209 }, { %f575, %f576, %f577, %f578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f579, %f580, %f581, %f582 }, { %r210, %r211, %r212, %r213 }, { %r166, %r167 }, { %f579, %f580, %f581, %f582 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f583, %f584, %f585, %f586 }, { %r210, %r211, %r212, %r213 }, { %r172, %r173 }, { %f583, %f584, %f585, %f586 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f587, %f588, %f589, %f590 }, { %r210, %r211, %r212, %r213 }, { %r178, %r179 }, { %f587, %f588, %f589, %f590 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f591, %f592, %f593, %f594 }, { %r210, %r211, %r212, %r213 }, { %r184, %r185 }, { %f591, %f592, %f593, %f594 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f595, %f596, %f597, %f598 }, { %r210, %r211, %r212, %r213 }, { %r190, %r191 }, { %f595, %f596, %f597, %f598 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f599, %f600, %f601, %f602 }, { %r210, %r211, %r212, %r213 }, { %r196, %r197 }, { %f599, %f600, %f601, %f602 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f603, %f604, %f605, %f606 }, { %r210, %r211, %r212, %r213 }, { %r202, %r203 }, { %f603, %f604, %f605, %f606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f607, %f608, %f609, %f610 }, { %r210, %r211, %r212, %r213 }, { %r208, %r209 }, { %f607, %f608, %f609, %f610 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f547, %f548, %f549, %f550 }, { %r258, %r259, %r260, %r261 }, { %r262, %r263 }, { %f547, %f548, %f549, %f550 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f551, %f552, %f553, %f554 }, { %r258, %r259, %r260, %r261 }, { %r268, %r269 }, { %f551, %f552, %f553, %f554 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f555, %f556, %f557, %f558 }, { %r258, %r259, %r260, %r261 }, { %r274, %r275 }, { %f555, %f556, %f557, %f558 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f559, %f560, %f561, %f562 }, { %r258, %r259, %r260, %r261 }, { %r280, %r281 }, { %f559, %f560, %f561, %f562 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f563, %f564, %f565, %f566 }, { %r258, %r259, %r260, %r261 }, { %r286, %r287 }, { %f563, %f564, %f565, %f566 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f567, %f568, %f569, %f570 }, { %r258, %r259, %r260, %r261 }, { %r292, %r293 }, { %f567, %f568, %f569, %f570 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f571, %f572, %f573, %f574 }, { %r258, %r259, %r260, %r261 }, { %r298, %r299 }, { %f571, %f572, %f573, %f574 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f575, %f576, %f577, %f578 }, { %r258, %r259, %r260, %r261 }, { %r304, %r305 }, { %f575, %f576, %f577, %f578 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f579, %f580, %f581, %f582 }, { %r306, %r307, %r308, %r309 }, { %r262, %r263 }, { %f579, %f580, %f581, %f582 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f583, %f584, %f585, %f586 }, { %r306, %r307, %r308, %r309 }, { %r268, %r269 }, { %f583, %f584, %f585, %f586 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f587, %f588, %f589, %f590 }, { %r306, %r307, %r308, %r309 }, { %r274, %r275 }, { %f587, %f588, %f589, %f590 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f591, %f592, %f593, %f594 }, { %r306, %r307, %r308, %r309 }, { %r280, %r281 }, { %f591, %f592, %f593, %f594 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f595, %f596, %f597, %f598 }, { %r306, %r307, %r308, %r309 }, { %r286, %r287 }, { %f595, %f596, %f597, %f598 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f599, %f600, %f601, %f602 }, { %r306, %r307, %r308, %r309 }, { %r292, %r293 }, { %f599, %f600, %f601, %f602 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f603, %f604, %f605, %f606 }, { %r306, %r307, %r308, %r309 }, { %r298, %r299 }, { %f603, %f604, %f605, %f606 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f607, %f608, %f609, %f610 }, { %r306, %r307, %r308, %r309 }, { %r304, %r305 }, { %f607, %f608, %f609, %f610 };
	// end inline asm
	.loc	1 62 22
	add.s64 	%rd68, %rd6, %rd155;
	add.s64 	%rd69, %rd5, %rd155;
	add.s64 	%rd70, %rd4, %rd155;
	add.s64 	%rd71, %rd3, %rd155;
	setp.lt.u32 	%p29, %r512, 128;
	bar.sync 	0;
	selp.b32 	%r363, 16, 0, %p29;
	selp.b32 	%r364, %r363, 0, %p1;
	selp.b32 	%r355, %r364, 0, %p28;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r354 + 0 ], [ %rd68 + 0 ], 0x10, %r355;
	// end inline asm
	selp.b32 	%r365, %r363, 0, %p2;
	selp.b32 	%r357, %r365, 0, %p28;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r356 + 0 ], [ %rd69 + 0 ], 0x10, %r357;
	// end inline asm
	selp.b32 	%r366, %r363, 0, %p3;
	selp.b32 	%r359, %r366, 0, %p28;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r358 + 0 ], [ %rd70 + 0 ], 0x10, %r359;
	// end inline asm
	selp.b32 	%r367, %r363, 0, %p4;
	selp.b32 	%r361, %r367, 0, %p28;
	// begin inline asm
	@%p5 cp.async.cg.shared.global [ %r360 + 0 ], [ %rd71 + 0 ], 0x10, %r361;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 60 21
	add.s32 	%r513, %r513, 1;
	add.s32 	%r512, %r512, 32;
	add.s64 	%rd155, %rd155, 64;
	setp.lt.u32 	%p30, %r513, 3;
	@%p30 bra 	$L__BB0_1;
	.loc	1 0 21
	cvt.u32.u64 	%r432, %rd2;
	cvt.u32.u64 	%r433, %rd1;
	.loc	1 53 34
	shl.b32 	%r434, %r1, 2;
	and.b32  	%r435, %r434, 60;
	shl.b32 	%r436, %r1, 1;
	shr.u32 	%r437, %r5, 1;
	and.b32  	%r438, %r436, 6;
	or.b32  	%r439, %r438, 57;
	.loc	1 53 21
	or.b32  	%r440, %r432, %r439;
	.loc	1 54 16
	setp.lt.s32 	%p47, %r440, %r433;
	.loc	1 53 34
	or.b32  	%r441, %r438, 56;
	.loc	1 53 21
	or.b32  	%r442, %r432, %r441;
	.loc	1 54 16
	setp.lt.s32 	%p48, %r442, %r433;
	.loc	1 53 34
	or.b32  	%r443, %r438, 49;
	.loc	1 53 21
	or.b32  	%r444, %r432, %r443;
	.loc	1 54 16
	setp.lt.s32 	%p49, %r444, %r433;
	.loc	1 53 34
	or.b32  	%r445, %r438, 48;
	.loc	1 53 21
	or.b32  	%r446, %r432, %r445;
	.loc	1 54 16
	setp.lt.s32 	%p50, %r446, %r433;
	.loc	1 53 34
	or.b32  	%r447, %r438, 41;
	or.b32  	%r448, %r438, 40;
	or.b32  	%r449, %r438, 33;
	or.b32  	%r450, %r438, 32;
	or.b32  	%r451, %r438, 25;
	or.b32  	%r452, %r438, 24;
	or.b32  	%r453, %r438, 17;
	or.b32  	%r454, %r438, 16;
	or.b32  	%r455, %r438, 9;
	or.b32  	%r456, %r438, 8;
	or.b32  	%r457, %r438, 1;
	or.b32  	%r458, %r4, %r437;
	or.b32  	%r459, %r458, 40;
	or.b32  	%r460, %r6, %r437;
	or.b32  	%r461, %r458, 8;
	.loc	1 53 21
	or.b32  	%r462, %r432, %r438;
	or.b32  	%r463, %r432, %r458;
	or.b32  	%r464, %r432, %r457;
	or.b32  	%r465, %r432, %r461;
	or.b32  	%r466, %r432, %r456;
	or.b32  	%r467, %r432, %r455;
	or.b32  	%r468, %r432, %r454;
	or.b32  	%r469, %r432, %r453;
	or.b32  	%r470, %r432, %r452;
	or.b32  	%r471, %r432, %r451;
	or.b32  	%r472, %r432, %r460;
	or.b32  	%r473, %r432, %r459;
	or.b32  	%r474, %r432, %r450;
	or.b32  	%r475, %r432, %r449;
	or.b32  	%r476, %r432, %r448;
	or.b32  	%r477, %r432, %r447;
	.loc	1 54 16
	setp.lt.s32 	%p51, %r477, %r433;
	setp.lt.s32 	%p52, %r476, %r433;
	setp.lt.s32 	%p53, %r475, %r433;
	setp.lt.s32 	%p54, %r474, %r433;
	setp.lt.s32 	%p55, %r473, %r433;
	setp.lt.s32 	%p56, %r472, %r433;
	setp.lt.s32 	%p57, %r471, %r433;
	setp.lt.s32 	%p58, %r470, %r433;
	setp.lt.s32 	%p59, %r469, %r433;
	setp.lt.s32 	%p60, %r468, %r433;
	setp.lt.s32 	%p61, %r467, %r433;
	setp.lt.s32 	%p62, %r466, %r433;
	setp.lt.s32 	%p63, %r465, %r433;
	setp.lt.s32 	%p64, %r464, %r433;
	setp.lt.s32 	%p65, %r463, %r433;
	setp.lt.s32 	%p66, %r462, %r433;
	.loc	1 60 21
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 70 15
	and.b32  	%r478, %r3, 1;
	shl.b32 	%r479, %r7, 1;
	add.s32 	%r481, %r68, %r479;
	st.shared.u16 	[%r481], %rs1;
	bar.sync 	0;
	shr.u32 	%r482, %r2, 2;
	shl.b32 	%r483, %r478, 4;
	or.b32  	%r484, %r483, %r482;
	shl.b32 	%r485, %r484, 1;
	add.s32 	%r486, %r68, %r485;
	ld.shared.b16 	%rs3, [%r486];
	ld.shared.b16 	%rs4, [%r486+16];
	ld.shared.b16 	%rs5, [%r486+64];
	ld.shared.b16 	%rs6, [%r486+80];
	.loc	1 70 11
	cvt.f32.f16 	%f386, %rs3;
	cvt.f32.f16 	%f387, %rs4;
	cvt.f32.f16 	%f388, %rs5;
	cvt.f32.f16 	%f389, %rs6;
	mul.f32 	%f390, %f547, %f386;
	mul.f32 	%f391, %f548, %f386;
	mul.f32 	%f392, %f549, %f387;
	mul.f32 	%f393, %f550, %f387;
	mul.f32 	%f394, %f551, %f386;
	mul.f32 	%f395, %f552, %f386;
	mul.f32 	%f396, %f553, %f387;
	mul.f32 	%f397, %f554, %f387;
	mul.f32 	%f398, %f555, %f386;
	mul.f32 	%f399, %f556, %f386;
	mul.f32 	%f400, %f557, %f387;
	mul.f32 	%f401, %f558, %f387;
	mul.f32 	%f402, %f561, %f387;
	mul.f32 	%f403, %f562, %f387;
	mul.f32 	%f404, %f579, %f388;
	mul.f32 	%f405, %f580, %f388;
	mul.f32 	%f406, %f581, %f389;
	mul.f32 	%f407, %f582, %f389;
	mul.f32 	%f408, %f583, %f388;
	mul.f32 	%f409, %f584, %f388;
	mul.f32 	%f410, %f585, %f389;
	mul.f32 	%f411, %f586, %f389;
	mul.f32 	%f412, %f587, %f388;
	mul.f32 	%f413, %f588, %f388;
	mul.f32 	%f414, %f589, %f389;
	mul.f32 	%f415, %f590, %f389;
	mul.f32 	%f416, %f591, %f388;
	mul.f32 	%f417, %f592, %f388;
	mul.f32 	%f418, %f593, %f389;
	mul.f32 	%f419, %f594, %f389;
	mul.f32 	%f420, %f595, %f388;
	mul.f32 	%f421, %f596, %f388;
	mul.f32 	%f422, %f597, %f389;
	mul.f32 	%f423, %f598, %f389;
	mul.f32 	%f424, %f599, %f388;
	mul.f32 	%f425, %f600, %f388;
	mul.f32 	%f426, %f601, %f389;
	mul.f32 	%f427, %f602, %f389;
	mul.f32 	%f428, %f603, %f388;
	mul.f32 	%f429, %f604, %f388;
	mul.f32 	%f430, %f605, %f389;
	mul.f32 	%f431, %f606, %f389;
	mul.f32 	%f432, %f609, %f389;
	mul.f32 	%f433, %f610, %f389;
	.loc	1 72 26
	setp.gt.u32 	%p67, %r458, %r438;
	setp.gt.u32 	%p68, %r458, %r457;
	setp.gt.u32 	%p69, %r458, %r456;
	setp.gt.u32 	%p70, %r458, %r455;
	setp.gt.u32 	%p71, %r461, %r455;
	setp.gt.u32 	%p72, %r458, %r454;
	setp.gt.u32 	%p73, %r458, %r453;
	setp.gt.u32 	%p74, %r461, %r454;
	setp.gt.u32 	%p75, %r461, %r453;
	setp.gt.u32 	%p76, %r461, %r452;
	setp.gt.u32 	%p77, %r461, %r451;
	setp.gt.u32 	%p78, %r460, %r450;
	setp.gt.u32 	%p79, %r460, %r449;
	setp.gt.u32 	%p80, %r460, %r448;
	setp.gt.u32 	%p81, %r460, %r447;
	setp.gt.u32 	%p82, %r459, %r447;
	setp.gt.u32 	%p83, %r460, %r445;
	setp.gt.u32 	%p84, %r460, %r443;
	setp.gt.u32 	%p85, %r459, %r445;
	setp.gt.u32 	%p86, %r459, %r443;
	setp.gt.u32 	%p87, %r459, %r441;
	setp.gt.u32 	%p88, %r459, %r439;
	.loc	1 73 29
	selp.f32 	%f434, %f390, 0f00000000, %p66;
	selp.f32 	%f435, %f434, 0f00000000, %p67;
	selp.f32 	%f436, %f435, 0f00000000, %p65;
	selp.f32 	%f437, %f391, 0f00000000, %p64;
	selp.f32 	%f438, %f437, 0f00000000, %p68;
	selp.f32 	%f439, %f438, 0f00000000, %p65;
	selp.f32 	%f440, %f392, 0f00000000, %p66;
	selp.f32 	%f441, %f440, 0f00000000, %p63;
	selp.f32 	%f442, %f393, 0f00000000, %p64;
	selp.f32 	%f443, %f442, 0f00000000, %p63;
	selp.f32 	%f444, %f394, 0f00000000, %p62;
	selp.f32 	%f445, %f444, 0f00000000, %p69;
	selp.f32 	%f446, %f445, 0f00000000, %p65;
	selp.f32 	%f447, %f395, 0f00000000, %p61;
	selp.f32 	%f448, %f447, 0f00000000, %p70;
	selp.f32 	%f449, %f448, 0f00000000, %p65;
	selp.f32 	%f450, %f396, 0f00000000, %p62;
	selp.f32 	%f451, %f450, 0f00000000, %p67;
	selp.f32 	%f452, %f451, 0f00000000, %p63;
	selp.f32 	%f453, %f397, 0f00000000, %p61;
	selp.f32 	%f454, %f453, 0f00000000, %p71;
	selp.f32 	%f455, %f454, 0f00000000, %p63;
	selp.f32 	%f456, %f398, 0f00000000, %p60;
	selp.f32 	%f457, %f456, 0f00000000, %p72;
	selp.f32 	%f458, %f457, 0f00000000, %p65;
	selp.f32 	%f459, %f399, 0f00000000, %p59;
	selp.f32 	%f460, %f459, 0f00000000, %p73;
	selp.f32 	%f461, %f460, 0f00000000, %p65;
	selp.f32 	%f462, %f400, 0f00000000, %p60;
	selp.f32 	%f463, %f462, 0f00000000, %p74;
	selp.f32 	%f464, %f463, 0f00000000, %p63;
	selp.f32 	%f465, %f401, 0f00000000, %p59;
	selp.f32 	%f466, %f465, 0f00000000, %p75;
	selp.f32 	%f467, %f466, 0f00000000, %p63;
	selp.f32 	%f468, %f402, 0f00000000, %p58;
	selp.f32 	%f469, %f468, 0f00000000, %p76;
	selp.f32 	%f470, %f469, 0f00000000, %p63;
	selp.f32 	%f471, %f403, 0f00000000, %p57;
	selp.f32 	%f472, %f471, 0f00000000, %p77;
	selp.f32 	%f473, %f472, 0f00000000, %p63;
	selp.f32 	%f474, %f404, 0f00000000, %p66;
	selp.f32 	%f475, %f474, 0f00000000, %p56;
	selp.f32 	%f476, %f405, 0f00000000, %p64;
	selp.f32 	%f477, %f476, 0f00000000, %p56;
	selp.f32 	%f478, %f406, 0f00000000, %p66;
	selp.f32 	%f479, %f478, 0f00000000, %p55;
	selp.f32 	%f480, %f407, 0f00000000, %p64;
	selp.f32 	%f481, %f480, 0f00000000, %p55;
	selp.f32 	%f482, %f408, 0f00000000, %p62;
	selp.f32 	%f483, %f482, 0f00000000, %p56;
	selp.f32 	%f484, %f409, 0f00000000, %p61;
	selp.f32 	%f485, %f484, 0f00000000, %p56;
	selp.f32 	%f486, %f410, 0f00000000, %p62;
	selp.f32 	%f487, %f486, 0f00000000, %p55;
	selp.f32 	%f488, %f411, 0f00000000, %p61;
	selp.f32 	%f489, %f488, 0f00000000, %p55;
	selp.f32 	%f490, %f412, 0f00000000, %p60;
	selp.f32 	%f491, %f490, 0f00000000, %p56;
	selp.f32 	%f492, %f413, 0f00000000, %p59;
	selp.f32 	%f493, %f492, 0f00000000, %p56;
	selp.f32 	%f494, %f414, 0f00000000, %p60;
	selp.f32 	%f495, %f494, 0f00000000, %p55;
	selp.f32 	%f496, %f415, 0f00000000, %p59;
	selp.f32 	%f497, %f496, 0f00000000, %p55;
	selp.f32 	%f498, %f416, 0f00000000, %p58;
	selp.f32 	%f499, %f498, 0f00000000, %p56;
	selp.f32 	%f500, %f417, 0f00000000, %p57;
	selp.f32 	%f501, %f500, 0f00000000, %p56;
	selp.f32 	%f502, %f418, 0f00000000, %p58;
	selp.f32 	%f503, %f502, 0f00000000, %p55;
	selp.f32 	%f504, %f419, 0f00000000, %p57;
	selp.f32 	%f505, %f504, 0f00000000, %p55;
	selp.f32 	%f506, %f420, 0f00000000, %p54;
	selp.f32 	%f507, %f506, 0f00000000, %p78;
	selp.f32 	%f508, %f507, 0f00000000, %p56;
	selp.f32 	%f509, %f421, 0f00000000, %p53;
	selp.f32 	%f510, %f509, 0f00000000, %p79;
	selp.f32 	%f511, %f510, 0f00000000, %p56;
	selp.f32 	%f512, %f422, 0f00000000, %p54;
	selp.f32 	%f513, %f512, 0f00000000, %p55;
	selp.f32 	%f514, %f423, 0f00000000, %p53;
	selp.f32 	%f515, %f514, 0f00000000, %p55;
	selp.f32 	%f516, %f424, 0f00000000, %p52;
	selp.f32 	%f517, %f516, 0f00000000, %p80;
	selp.f32 	%f518, %f517, 0f00000000, %p56;
	selp.f32 	%f519, %f425, 0f00000000, %p51;
	selp.f32 	%f520, %f519, 0f00000000, %p81;
	selp.f32 	%f521, %f520, 0f00000000, %p56;
	selp.f32 	%f522, %f426, 0f00000000, %p52;
	selp.f32 	%f523, %f522, 0f00000000, %p67;
	selp.f32 	%f524, %f523, 0f00000000, %p55;
	selp.f32 	%f525, %f427, 0f00000000, %p51;
	selp.f32 	%f526, %f525, 0f00000000, %p82;
	selp.f32 	%f527, %f526, 0f00000000, %p55;
	selp.f32 	%f528, %f428, 0f00000000, %p50;
	selp.f32 	%f529, %f528, 0f00000000, %p83;
	selp.f32 	%f530, %f529, 0f00000000, %p56;
	selp.f32 	%f531, %f429, 0f00000000, %p49;
	selp.f32 	%f532, %f531, 0f00000000, %p84;
	selp.f32 	%f533, %f532, 0f00000000, %p56;
	selp.f32 	%f534, %f430, 0f00000000, %p50;
	selp.f32 	%f535, %f534, 0f00000000, %p85;
	selp.f32 	%f536, %f535, 0f00000000, %p55;
	selp.f32 	%f537, %f431, 0f00000000, %p49;
	selp.f32 	%f538, %f537, 0f00000000, %p86;
	selp.f32 	%f539, %f538, 0f00000000, %p55;
	selp.f32 	%f540, %f432, 0f00000000, %p48;
	selp.f32 	%f541, %f540, 0f00000000, %p87;
	selp.f32 	%f542, %f541, 0f00000000, %p55;
	selp.f32 	%f543, %f433, 0f00000000, %p47;
	selp.f32 	%f544, %f543, 0f00000000, %p88;
	selp.f32 	%f545, %f544, 0f00000000, %p55;
	.loc	1 74 48
	shl.b32 	%r487, %r8, 6;
	.loc	1 74 32
	mul.wide.s32 	%rd88, %r487, 4;
	add.s64 	%rd89, %rd9, %rd88;
	.loc	1 53 34
	bfe.u32 	%r488, %r1, 4, 2;
	or.b32  	%r489, %r488, 60;
	or.b32  	%r490, %r488, 56;
	or.b32  	%r491, %r488, 52;
	or.b32  	%r492, %r488, 48;
	or.b32  	%r493, %r488, 44;
	or.b32  	%r494, %r488, 40;
	or.b32  	%r495, %r488, 36;
	or.b32  	%r496, %r488, 32;
	or.b32  	%r497, %r488, 28;
	or.b32  	%r498, %r488, 24;
	or.b32  	%r499, %r488, 20;
	or.b32  	%r500, %r488, 16;
	or.b32  	%r501, %r488, 12;
	or.b32  	%r502, %r488, 8;
	or.b32  	%r503, %r488, 4;
	cvt.u64.u32 	%rd90, %r488;
	cvt.u64.u32 	%rd91, %r503;
	cvt.u64.u32 	%rd92, %r502;
	cvt.u64.u32 	%rd93, %r501;
	cvt.u64.u32 	%rd94, %r500;
	cvt.u64.u32 	%rd95, %r499;
	cvt.u64.u32 	%rd96, %r498;
	cvt.u64.u32 	%rd97, %r497;
	cvt.u64.u32 	%rd98, %r496;
	cvt.u64.u32 	%rd99, %r495;
	cvt.u64.u32 	%rd100, %r494;
	cvt.u64.u32 	%rd101, %r493;
	cvt.u64.u32 	%rd102, %r492;
	cvt.u64.u32 	%rd103, %r491;
	cvt.u64.u32 	%rd104, %r490;
	cvt.u64.u32 	%rd105, %r489;
	.loc	1 57 18
	or.b64  	%rd106, %rd2, %rd105;
	or.b64  	%rd107, %rd2, %rd104;
	or.b64  	%rd108, %rd2, %rd103;
	or.b64  	%rd109, %rd2, %rd102;
	or.b64  	%rd110, %rd2, %rd101;
	or.b64  	%rd111, %rd2, %rd100;
	or.b64  	%rd112, %rd2, %rd99;
	or.b64  	%rd113, %rd2, %rd98;
	or.b64  	%rd114, %rd2, %rd97;
	or.b64  	%rd115, %rd2, %rd96;
	or.b64  	%rd116, %rd2, %rd95;
	or.b64  	%rd117, %rd2, %rd94;
	or.b64  	%rd118, %rd2, %rd93;
	or.b64  	%rd119, %rd2, %rd92;
	or.b64  	%rd120, %rd2, %rd91;
	or.b64  	%rd121, %rd2, %rd90;
	.loc	1 75 18
	shl.b64 	%rd122, %rd121, 12;
	mul.wide.u32 	%rd123, %r435, 4;
	or.b64  	%rd124, %rd122, %rd123;
	add.s64 	%rd72, %rd89, %rd124;
	shl.b64 	%rd125, %rd120, 12;
	or.b64  	%rd126, %rd125, %rd123;
	add.s64 	%rd73, %rd89, %rd126;
	shl.b64 	%rd127, %rd119, 12;
	or.b64  	%rd128, %rd127, %rd123;
	add.s64 	%rd74, %rd89, %rd128;
	shl.b64 	%rd129, %rd118, 12;
	or.b64  	%rd130, %rd129, %rd123;
	add.s64 	%rd75, %rd89, %rd130;
	shl.b64 	%rd131, %rd117, 12;
	or.b64  	%rd132, %rd131, %rd123;
	add.s64 	%rd76, %rd89, %rd132;
	shl.b64 	%rd133, %rd116, 12;
	or.b64  	%rd134, %rd133, %rd123;
	add.s64 	%rd77, %rd89, %rd134;
	shl.b64 	%rd135, %rd115, 12;
	or.b64  	%rd136, %rd135, %rd123;
	add.s64 	%rd78, %rd89, %rd136;
	shl.b64 	%rd137, %rd114, 12;
	or.b64  	%rd138, %rd137, %rd123;
	add.s64 	%rd79, %rd89, %rd138;
	shl.b64 	%rd139, %rd113, 12;
	or.b64  	%rd140, %rd139, %rd123;
	add.s64 	%rd80, %rd89, %rd140;
	shl.b64 	%rd141, %rd112, 12;
	or.b64  	%rd142, %rd141, %rd123;
	add.s64 	%rd81, %rd89, %rd142;
	shl.b64 	%rd143, %rd111, 12;
	or.b64  	%rd144, %rd143, %rd123;
	add.s64 	%rd82, %rd89, %rd144;
	shl.b64 	%rd145, %rd110, 12;
	or.b64  	%rd146, %rd145, %rd123;
	add.s64 	%rd83, %rd89, %rd146;
	shl.b64 	%rd147, %rd109, 12;
	or.b64  	%rd148, %rd147, %rd123;
	add.s64 	%rd84, %rd89, %rd148;
	shl.b64 	%rd149, %rd108, 12;
	or.b64  	%rd150, %rd149, %rd123;
	add.s64 	%rd85, %rd89, %rd150;
	shl.b64 	%rd151, %rd107, 12;
	or.b64  	%rd152, %rd151, %rd123;
	add.s64 	%rd86, %rd89, %rd152;
	shl.b64 	%rd153, %rd106, 12;
	or.b64  	%rd154, %rd153, %rd123;
	add.s64 	%rd87, %rd89, %rd154;
	setp.gt.s64 	%p89, %rd106, -1;
	setp.gt.s64 	%p90, %rd107, -1;
	setp.gt.s64 	%p91, %rd108, -1;
	setp.gt.s64 	%p92, %rd109, -1;
	setp.gt.s64 	%p93, %rd110, -1;
	setp.gt.s64 	%p94, %rd111, -1;
	setp.gt.s64 	%p95, %rd112, -1;
	setp.gt.s64 	%p96, %rd113, -1;
	setp.gt.s64 	%p97, %rd114, -1;
	setp.gt.s64 	%p98, %rd115, -1;
	setp.gt.s64 	%p99, %rd116, -1;
	setp.gt.s64 	%p100, %rd117, -1;
	setp.gt.s64 	%p101, %rd118, -1;
	setp.gt.s64 	%p102, %rd119, -1;
	setp.gt.s64 	%p103, %rd120, -1;
	setp.gt.s64 	%p104, %rd121, -1;
	setp.lt.s64 	%p105, %rd121, %rd1;
	setp.lt.s64 	%p106, %rd120, %rd1;
	setp.lt.s64 	%p107, %rd119, %rd1;
	setp.lt.s64 	%p108, %rd118, %rd1;
	setp.lt.s64 	%p109, %rd117, %rd1;
	setp.lt.s64 	%p110, %rd116, %rd1;
	setp.lt.s64 	%p111, %rd115, %rd1;
	setp.lt.s64 	%p112, %rd114, %rd1;
	setp.lt.s64 	%p113, %rd113, %rd1;
	setp.lt.s64 	%p114, %rd112, %rd1;
	setp.lt.s64 	%p115, %rd111, %rd1;
	setp.lt.s64 	%p116, %rd110, %rd1;
	setp.lt.s64 	%p117, %rd109, %rd1;
	setp.lt.s64 	%p118, %rd108, %rd1;
	setp.lt.s64 	%p119, %rd107, %rd1;
	setp.lt.s64 	%p120, %rd106, %rd1;
	and.pred  	%p31, %p104, %p105;
	and.pred  	%p32, %p103, %p106;
	and.pred  	%p33, %p102, %p107;
	and.pred  	%p34, %p101, %p108;
	and.pred  	%p35, %p100, %p109;
	and.pred  	%p36, %p99, %p110;
	and.pred  	%p37, %p98, %p111;
	and.pred  	%p38, %p97, %p112;
	and.pred  	%p39, %p96, %p113;
	and.pred  	%p40, %p95, %p114;
	and.pred  	%p41, %p94, %p115;
	and.pred  	%p42, %p93, %p116;
	and.pred  	%p43, %p92, %p117;
	and.pred  	%p44, %p91, %p118;
	and.pred  	%p45, %p90, %p119;
	and.pred  	%p46, %p89, %p120;
	bar.sync 	0;
	mad.lo.s32 	%r504, %r484, 68, %r438;
	shl.b32 	%r505, %r504, 2;
	add.s32 	%r506, %r68, %r505;
	st.shared.v2.f32 	[%r506], {%f436, %f439};
	st.shared.v2.f32 	[%r506+2176], {%f441, %f443};
	st.shared.v2.f32 	[%r506+32], {%f446, %f449};
	st.shared.v2.f32 	[%r506+2208], {%f452, %f455};
	st.shared.v2.f32 	[%r506+64], {%f458, %f461};
	st.shared.v2.f32 	[%r506+2240], {%f464, %f467};
	mov.f32 	%f546, 0f00000000;
	st.shared.v2.f32 	[%r506+96], {%f546, %f546};
	st.shared.v2.f32 	[%r506+2272], {%f470, %f473};
	st.shared.v2.f32 	[%r506+128], {%f546, %f546};
	st.shared.v2.f32 	[%r506+2304], {%f546, %f546};
	st.shared.v2.f32 	[%r506+160], {%f546, %f546};
	st.shared.v2.f32 	[%r506+2336], {%f546, %f546};
	st.shared.v2.f32 	[%r506+192], {%f546, %f546};
	st.shared.v2.f32 	[%r506+2368], {%f546, %f546};
	st.shared.v2.f32 	[%r506+224], {%f546, %f546};
	st.shared.v2.f32 	[%r506+2400], {%f546, %f546};
	bar.sync 	0;
	shl.b32 	%r507, %r478, 1;
	or.b32  	%r508, %r507, %r13;
	mad.lo.s32 	%r509, %r508, 68, %r435;
	shl.b32 	%r510, %r509, 2;
	add.s32 	%r511, %r68, %r510;
	ld.shared.v4.u32 	{%r368, %r369, %r370, %r371}, [%r511];
	ld.shared.v4.u32 	{%r372, %r373, %r374, %r375}, [%r511+1088];
	ld.shared.v4.u32 	{%r376, %r377, %r378, %r379}, [%r511+2176];
	ld.shared.v4.u32 	{%r380, %r381, %r382, %r383}, [%r511+3264];
	ld.shared.v4.u32 	{%r384, %r385, %r386, %r387}, [%r511+4352];
	ld.shared.v4.u32 	{%r388, %r389, %r390, %r391}, [%r511+5440];
	ld.shared.v4.u32 	{%r392, %r393, %r394, %r395}, [%r511+6528];
	ld.shared.v4.u32 	{%r396, %r397, %r398, %r399}, [%r511+7616];
	bar.sync 	0;
	st.shared.v2.f32 	[%r506], {%f475, %f477};
	st.shared.v2.f32 	[%r506+2176], {%f479, %f481};
	st.shared.v2.f32 	[%r506+32], {%f483, %f485};
	st.shared.v2.f32 	[%r506+2208], {%f487, %f489};
	st.shared.v2.f32 	[%r506+64], {%f491, %f493};
	st.shared.v2.f32 	[%r506+2240], {%f495, %f497};
	st.shared.v2.f32 	[%r506+96], {%f499, %f501};
	st.shared.v2.f32 	[%r506+2272], {%f503, %f505};
	st.shared.v2.f32 	[%r506+128], {%f508, %f511};
	st.shared.v2.f32 	[%r506+2304], {%f513, %f515};
	st.shared.v2.f32 	[%r506+160], {%f518, %f521};
	st.shared.v2.f32 	[%r506+2336], {%f524, %f527};
	st.shared.v2.f32 	[%r506+192], {%f530, %f533};
	st.shared.v2.f32 	[%r506+2368], {%f536, %f539};
	st.shared.v2.f32 	[%r506+224], {%f546, %f546};
	st.shared.v2.f32 	[%r506+2400], {%f542, %f545};
	bar.sync 	0;
	ld.shared.v4.u32 	{%r400, %r401, %r402, %r403}, [%r511];
	ld.shared.v4.u32 	{%r404, %r405, %r406, %r407}, [%r511+1088];
	ld.shared.v4.u32 	{%r408, %r409, %r410, %r411}, [%r511+2176];
	ld.shared.v4.u32 	{%r412, %r413, %r414, %r415}, [%r511+3264];
	ld.shared.v4.u32 	{%r416, %r417, %r418, %r419}, [%r511+4352];
	ld.shared.v4.u32 	{%r420, %r421, %r422, %r423}, [%r511+5440];
	ld.shared.v4.u32 	{%r424, %r425, %r426, %r427}, [%r511+6528];
	ld.shared.v4.u32 	{%r428, %r429, %r430, %r431}, [%r511+7616];
	// begin inline asm
	@%p31 st.global.v4.b32 [ %rd72 + 0 ], { %r368, %r369, %r370, %r371 };
	// end inline asm
	// begin inline asm
	@%p32 st.global.v4.b32 [ %rd73 + 0 ], { %r372, %r373, %r374, %r375 };
	// end inline asm
	// begin inline asm
	@%p33 st.global.v4.b32 [ %rd74 + 0 ], { %r376, %r377, %r378, %r379 };
	// end inline asm
	// begin inline asm
	@%p34 st.global.v4.b32 [ %rd75 + 0 ], { %r380, %r381, %r382, %r383 };
	// end inline asm
	// begin inline asm
	@%p35 st.global.v4.b32 [ %rd76 + 0 ], { %r384, %r385, %r386, %r387 };
	// end inline asm
	// begin inline asm
	@%p36 st.global.v4.b32 [ %rd77 + 0 ], { %r388, %r389, %r390, %r391 };
	// end inline asm
	// begin inline asm
	@%p37 st.global.v4.b32 [ %rd78 + 0 ], { %r392, %r393, %r394, %r395 };
	// end inline asm
	// begin inline asm
	@%p38 st.global.v4.b32 [ %rd79 + 0 ], { %r396, %r397, %r398, %r399 };
	// end inline asm
	// begin inline asm
	@%p39 st.global.v4.b32 [ %rd80 + 0 ], { %r400, %r401, %r402, %r403 };
	// end inline asm
	// begin inline asm
	@%p40 st.global.v4.b32 [ %rd81 + 0 ], { %r404, %r405, %r406, %r407 };
	// end inline asm
	// begin inline asm
	@%p41 st.global.v4.b32 [ %rd82 + 0 ], { %r408, %r409, %r410, %r411 };
	// end inline asm
	// begin inline asm
	@%p42 st.global.v4.b32 [ %rd83 + 0 ], { %r412, %r413, %r414, %r415 };
	// end inline asm
	// begin inline asm
	@%p43 st.global.v4.b32 [ %rd84 + 0 ], { %r416, %r417, %r418, %r419 };
	// end inline asm
	// begin inline asm
	@%p44 st.global.v4.b32 [ %rd85 + 0 ], { %r420, %r421, %r422, %r423 };
	// end inline asm
	// begin inline asm
	@%p45 st.global.v4.b32 [ %rd86 + 0 ], { %r424, %r425, %r426, %r427 };
	// end inline asm
	// begin inline asm
	@%p46 st.global.v4.b32 [ %rd87 + 0 ], { %r428, %r429, %r430, %r431 };
	// end inline asm
	.loc	1 75 4
	ret;
$L__tmp1:
$L__func_end0:

}
	.file	1 "D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\fla\\ops\\common\\chunk_scaled_dot_kkt.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 0
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 164
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 104
.b8 117
.b8 110
.b8 107
.b8 95
.b8 115
.b8 99
.b8 97
.b8 108
.b8 101
.b8 100
.b8 95
.b8 100
.b8 111
.b8 116
.b8 95
.b8 107
.b8 107
.b8 116
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 68
.b8 58
.b8 92
.b8 85
.b8 115
.b8 101
.b8 114
.b8 115
.b8 92
.b8 76
.b8 111
.b8 117
.b8 105
.b8 115
.b8 92
.b8 80
.b8 121
.b8 99
.b8 104
.b8 97
.b8 114
.b8 109
.b8 80
.b8 114
.b8 111
.b8 106
.b8 101
.b8 99
.b8 116
.b8 115
.b8 92
.b8 77
.b8 97
.b8 115
.b8 116
.b8 101
.b8 114
.b8 95
.b8 116
.b8 104
.b8 101
.b8 115
.b8 105
.b8 115
.b8 92
.b8 66
.b8 97
.b8 98
.b8 105
.b8 108
.b8 111
.b8 110
.b8 103
.b8 95
.b8 66
.b8 101
.b8 110
.b8 99
.b8 104
.b8 109
.b8 97
.b8 114
.b8 107
.b8 92
.b8 46
.b8 118
.b8 101
.b8 110
.b8 118
.b8 92
.b8 76
.b8 105
.b8 98
.b8 92
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 92
.b8 102
.b8 108
.b8 97
.b8 92
.b8 111
.b8 112
.b8 115
.b8 92
.b8 99
.b8 111
.b8 109
.b8 109
.b8 111
.b8 110
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
	}
	.section	.debug_loc	{	}
