//
// Generated by LLVM NVPTX Back-End
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	chunk_scaled_dot_kkt_fwd_kernel
.extern .shared .align 16 .b8 global_smem[];

.visible .entry chunk_scaled_dot_kkt_fwd_kernel(
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_0,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_1,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_2,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_3,
	.param .u64 chunk_scaled_dot_kkt_fwd_kernel_param_4,
	.param .u32 chunk_scaled_dot_kkt_fwd_kernel_param_5
)
.maxntid 256, 1, 1
{
	.reg .pred 	%p<56>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<219>;
	.reg .f32 	%f<180>;
	.reg .b64 	%rd<66>;
	.loc	1 30 0
$L__func_begin0:
	.loc	1 30 0

	ld.param.u64 	%rd6, [chunk_scaled_dot_kkt_fwd_kernel_param_2];
	ld.param.u64 	%rd14, [chunk_scaled_dot_kkt_fwd_kernel_param_0];
	ld.param.u64 	%rd15, [chunk_scaled_dot_kkt_fwd_kernel_param_1];
$L__tmp0:
	.loc	1 45 30
	// begin inline asm
	mov.u32 %r22, %ctaid.x;
	// end inline asm
	.loc	1 45 48
	// begin inline asm
	mov.u32 %r23, %ctaid.y;
	// end inline asm
	.loc	1 46 33
	shr.s32 	%r31, %r23, 31;
	shr.u32 	%r32, %r31, 28;
	add.s32 	%r33, %r23, %r32;
	and.b32  	%r34, %r33, -16;
	sub.s32 	%r35, %r23, %r34;
	ld.param.u64 	%rd16, [chunk_scaled_dot_kkt_fwd_kernel_param_3];
	.loc	1 48 49
	shl.b32 	%r36, %r22, 1;
	ld.param.u64 	%rd17, [chunk_scaled_dot_kkt_fwd_kernel_param_4];
	.loc	1 48 43
	mul.wide.s32 	%rd18, %r36, 4;
	add.s64 	%rd7, %rd17, %rd18;
	mov.pred 	%p2, -1;
	.loc	1 48 27
	// begin inline asm
	mov.u32 %r24, 0x0;
	@%p2 ld.global.b32 { %r24 }, [ %rd7 + 0 ];
	// end inline asm
	.loc	1 48 100
	add.s64 	%rd8, %rd7, 4;
	.loc	1 48 74
	// begin inline asm
	mov.u32 %r25, 0x0;
	@%p2 ld.global.b32 { %r25 }, [ %rd8 + 0 ];
	// end inline asm
	.loc	1 49 40
	mul.wide.s32 	%rd19, %r24, 4;
	add.s64 	%rd9, %rd16, %rd19;
	.loc	1 49 27
	// begin inline asm
	mov.u32 %r26, 0x0;
	@%p2 ld.global.b32 { %r26 }, [ %rd9 + 0 ];
	// end inline asm
	.loc	1 49 86
	add.s64 	%rd10, %rd9, 4;
	.loc	1 49 67
	// begin inline asm
	mov.u32 %r27, 0x0;
	@%p2 ld.global.b32 { %r27 }, [ %rd10 + 0 ];
	// end inline asm
	.loc	1 50 18
	sub.s32 	%r37, %r27, %r26;
	.loc	1 53 16
	shl.b32 	%r38, %r25, 6;
	.loc	1 53 34
	mov.u32 	%r1, %tid.x;
	and.b32  	%r2, %r1, 31;
	shr.u32 	%r3, %r1, 5;
	shr.u32 	%r4, %r1, 2;
	bfe.u32 	%r39, %r1, 2, 6;
	and.b32  	%r5, %r4, 55;
	or.b32  	%r6, %r5, 8;
	.loc	1 56 39
	shl.b32 	%r40, %r26, 4;
	.loc	1 56 35
	mul.wide.s32 	%rd20, %r40, 2;
	add.s64 	%rd21, %rd15, %rd20;
	.loc	1 56 43
	mul.wide.s32 	%rd22, %r35, 2;
	add.s64 	%rd23, %rd21, %rd22;
	.loc	1 56 80
	cvt.s64.s32 	%rd1, %r37;
	cvt.s64.s32 	%rd2, %r38;
	cvt.u64.u32 	%rd24, %r39;
	cvt.u64.u32 	%rd25, %r5;
	cvt.u64.u32 	%rd26, %r6;
	.loc	1 57 18
	or.b64  	%rd27, %rd2, %rd24;
	or.b64  	%rd28, %rd2, %rd25;
	or.b64  	%rd29, %rd2, %rd26;
	shl.b64 	%rd30, %rd28, 5;
	add.s64 	%rd11, %rd23, %rd30;
	shl.b64 	%rd31, %rd29, 5;
	add.s64 	%rd12, %rd23, %rd31;
	setp.gt.s64 	%p9, %rd28, -1;
	setp.gt.s64 	%p10, %rd29, -1;
	setp.lt.s64 	%p11, %rd28, %rd1;
	setp.lt.s64 	%p12, %rd29, %rd1;
	and.pred  	%p6, %p9, %p11;
	and.pred  	%p7, %p10, %p12;
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p6 ld.global.b16 { %rs1 }, [ %rd11 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u16 %rs2, 0x0;
	@%p7 ld.global.b16 { %rs2 }, [ %rd12 + 0 ];
	// end inline asm
	.loc	1 61 45
	add.s32 	%r7, %r40, %r35;
	.loc	1 61 52
	shl.b32 	%r41, %r7, 7;
	.loc	1 61 36
	mul.wide.s32 	%rd32, %r41, 2;
	add.s64 	%rd33, %rd14, %rd32;
	.loc	1 62 22
	shl.b32 	%r42, %r1, 3;
	and.b32  	%r43, %r42, 24;
	setp.gt.s64 	%p13, %rd27, -1;
	setp.lt.s64 	%p14, %rd27, %rd1;
	and.pred  	%p1, %p13, %p14;
	mul.wide.u32 	%rd34, %r43, 2;
	shl.b64 	%rd35, %rd27, 12;
	or.b64  	%rd36, %rd35, %rd34;
	add.s64 	%rd13, %rd33, %rd36;
	xor.b32  	%r44, %r1, %r42;
	and.b32  	%r45, %r44, 24;
	shl.b32 	%r46, %r45, 1;
	shl.b32 	%r47, %r39, 6;
	or.b32  	%r48, %r47, %r46;
	mov.u32 	%r49, global_smem;
	add.s32 	%r154, %r49, %r48;
	selp.b32 	%r29, 16, 0, %p1;
	// begin inline asm
	@%p2 cp.async.cg.shared.global [ %r154 + 0 ], [ %rd13 + 0 ], 0x10, %r29;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	and.b32  	%r50, %r1, 7;
	bfe.u32 	%r51, %r1, 3, 1;
	bfe.u32 	%r9, %r1, 4, 1;
	and.b32  	%r52, %r3, 6;
	or.b32  	%r53, %r52, %r51;
	bfe.u32 	%r54, %r1, 1, 2;
	xor.b32  	%r55, %r9, %r54;
	shl.b32 	%r56, %r55, 4;
	shl.b32 	%r57, %r53, 9;
	shl.b32 	%r58, %r50, 6;
	or.b32  	%r59, %r57, %r58;
	or.b32  	%r60, %r56, %r59;
	add.s32 	%r80, %r49, %r60;
	or.b32  	%r61, %r9, 2;
	xor.b32  	%r62, %r61, %r54;
	shl.b32 	%r63, %r62, 4;
	or.b32  	%r64, %r63, %r59;
	add.s32 	%r85, %r49, %r64;
	and.b32  	%r12, %r4, 8;
	and.b32  	%r65, %r1, 23;
	or.b32  	%r66, %r65, %r12;
	xor.b32  	%r67, %r51, %r54;
	shl.b32 	%r68, %r67, 4;
	shl.b32 	%r69, %r66, 6;
	or.b32  	%r70, %r69, %r68;
	add.s32 	%r90, %r49, %r70;
	or.b32  	%r71, %r51, 2;
	xor.b32  	%r72, %r71, %r54;
	shl.b32 	%r73, %r72, 4;
	or.b32  	%r74, %r73, %r69;
	add.s32 	%r95, %r49, %r74;
	add.s32 	%r100, %r90, 2048;
	add.s32 	%r105, %r95, 2048;
	.loc	1 60 21
	or.b32  	%r217, %r43, 32;
	and.b32  	%r75, %r1, 3;
	mul.wide.u32 	%rd37, %r75, 16;
	or.b64  	%rd38, %rd35, %rd37;
	add.s64 	%rd39, %rd38, %rd32;
	add.s64 	%rd40, %rd39, %rd14;
	add.s64 	%rd65, %rd40, 64;
	mov.f32 	%f164, 0f00000000;
	mov.b32 	%r218, -1;
	mov.f32 	%f165, %f164;
	mov.f32 	%f166, %f164;
	mov.f32 	%f167, %f164;
	mov.f32 	%f168, %f164;
	mov.f32 	%f169, %f164;
	mov.f32 	%f170, %f164;
	mov.f32 	%f171, %f164;
	mov.f32 	%f172, %f164;
	mov.f32 	%f173, %f164;
	mov.f32 	%f174, %f164;
	mov.f32 	%f175, %f164;
	mov.f32 	%f176, %f164;
	mov.f32 	%f177, %f164;
	mov.f32 	%f178, %f164;
	mov.f32 	%f179, %f164;
$L__BB0_1:
	.loc	1 62 22
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r106, %r107, %r108, %r109 }, [ %r80 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r130, %r131, %r132, %r133 }, [ %r85 + 0 ];
	// end inline asm
	.loc	1 63 36
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r86, %r87, %r88, %r89 }, [ %r90 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r91, %r92, %r93, %r94 }, [ %r95 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r96, %r97, %r98, %r99 }, [ %r100 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r101, %r102, %r103, %r104 }, [ %r105 + 0 ];
	// end inline asm
	.loc	1 63 27
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f164, %f165, %f166, %f167 }, { %r106, %r107, %r108, %r109 }, { %r86, %r87 }, { %f164, %f165, %f166, %f167 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f168, %f169, %f170, %f171 }, { %r106, %r107, %r108, %r109 }, { %r88, %r89 }, { %f168, %f169, %f170, %f171 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f172, %f173, %f174, %f175 }, { %r106, %r107, %r108, %r109 }, { %r96, %r97 }, { %f172, %f173, %f174, %f175 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f176, %f177, %f178, %f179 }, { %r106, %r107, %r108, %r109 }, { %r98, %r99 }, { %f176, %f177, %f178, %f179 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f164, %f165, %f166, %f167 }, { %r130, %r131, %r132, %r133 }, { %r91, %r92 }, { %f164, %f165, %f166, %f167 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f168, %f169, %f170, %f171 }, { %r130, %r131, %r132, %r133 }, { %r93, %r94 }, { %f168, %f169, %f170, %f171 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f172, %f173, %f174, %f175 }, { %r130, %r131, %r132, %r133 }, { %r101, %r102 }, { %f172, %f173, %f174, %f175 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32 { %f176, %f177, %f178, %f179 }, { %r130, %r131, %r132, %r133 }, { %r103, %r104 }, { %f176, %f177, %f178, %f179 };
	// end inline asm
	.loc	1 62 22
	setp.lt.u32 	%p16, %r217, 128;
	bar.sync 	0;
	selp.b32 	%r156, 16, 0, %p16;
	selp.b32 	%r155, %r156, 0, %p1;
	// begin inline asm
	@%p2 cp.async.cg.shared.global [ %r154 + 0 ], [ %rd65 + 0 ], 0x10, %r155;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 60 21
	add.s32 	%r218, %r218, 1;
	add.s32 	%r217, %r217, 32;
	add.s64 	%rd65, %rd65, 64;
	setp.lt.u32 	%p17, %r218, 3;
	@%p17 bra 	$L__BB0_1;
	.loc	1 0 21
	cvt.u32.u64 	%r173, %rd2;
	cvt.u32.u64 	%r174, %rd1;
	.loc	1 53 34
	bfe.u32 	%r176, %r1, 4, 4;
	or.b32  	%r177, %r176, 48;
	cvt.u64.u32 	%rd46, %r177;
	.loc	1 57 18
	or.b64  	%rd47, %rd2, %rd46;
	.loc	1 53 34
	or.b32  	%r178, %r176, 32;
	cvt.u64.u32 	%rd48, %r178;
	.loc	1 57 18
	or.b64  	%rd49, %rd2, %rd48;
	.loc	1 53 34
	or.b32  	%r179, %r176, 16;
	cvt.u64.u32 	%rd50, %r179;
	.loc	1 57 18
	or.b64  	%rd51, %rd2, %rd50;
	cvt.u64.u32 	%rd52, %r176;
	or.b64  	%rd53, %rd2, %rd52;
	.loc	1 53 34
	shl.b32 	%r180, %r1, 2;
	and.b32  	%r181, %r180, 60;
	shl.b32 	%r182, %r1, 1;
	and.b32  	%r183, %r182, 6;
	or.b32  	%r184, %r183, %r12;
	or.b32  	%r185, %r184, 49;
	.loc	1 53 21
	or.b32  	%r186, %r173, %r185;
	.loc	1 54 16
	setp.lt.s32 	%p22, %r186, %r174;
	.loc	1 53 34
	or.b32  	%r187, %r184, 48;
	.loc	1 53 21
	or.b32  	%r188, %r173, %r187;
	.loc	1 54 16
	setp.lt.s32 	%p23, %r188, %r174;
	.loc	1 53 34
	or.b32  	%r189, %r184, 33;
	or.b32  	%r190, %r184, 32;
	or.b32  	%r191, %r184, 17;
	or.b32  	%r192, %r184, 16;
	or.b32  	%r193, %r184, 1;
	.loc	1 53 21
	or.b32  	%r194, %r173, %r184;
	or.b32  	%r195, %r173, %r5;
	or.b32  	%r196, %r173, %r193;
	or.b32  	%r197, %r173, %r6;
	or.b32  	%r198, %r173, %r192;
	or.b32  	%r199, %r173, %r191;
	or.b32  	%r200, %r173, %r190;
	or.b32  	%r201, %r173, %r189;
	.loc	1 54 16
	setp.lt.s32 	%p24, %r201, %r174;
	setp.lt.s32 	%p25, %r200, %r174;
	setp.lt.s32 	%p26, %r199, %r174;
	setp.lt.s32 	%p27, %r198, %r174;
	setp.lt.s32 	%p28, %r197, %r174;
	setp.lt.s32 	%p29, %r196, %r174;
	setp.lt.s32 	%p30, %r195, %r174;
	setp.lt.s32 	%p31, %r194, %r174;
	.loc	1 60 21
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 70 11
	cvt.f32.f16 	%f98, %rs1;
	cvt.f32.f16 	%f99, %rs2;
	mul.f32 	%f100, %f164, %f98;
	mul.f32 	%f101, %f165, %f98;
	mul.f32 	%f102, %f166, %f99;
	mul.f32 	%f103, %f167, %f99;
	mul.f32 	%f104, %f168, %f98;
	mul.f32 	%f105, %f169, %f98;
	mul.f32 	%f106, %f170, %f99;
	mul.f32 	%f107, %f171, %f99;
	mul.f32 	%f108, %f172, %f98;
	mul.f32 	%f109, %f173, %f98;
	mul.f32 	%f110, %f174, %f99;
	mul.f32 	%f111, %f175, %f99;
	mul.f32 	%f112, %f176, %f98;
	mul.f32 	%f113, %f177, %f98;
	mul.f32 	%f114, %f178, %f99;
	mul.f32 	%f115, %f179, %f99;
	.loc	1 72 26
	setp.gt.u32 	%p32, %r5, %r184;
	setp.gt.u32 	%p33, %r5, %r193;
	setp.gt.u32 	%p34, %r6, %r184;
	setp.gt.u32 	%p35, %r6, %r193;
	setp.gt.u32 	%p36, %r5, %r192;
	setp.gt.u32 	%p37, %r5, %r191;
	setp.gt.u32 	%p38, %r6, %r192;
	setp.gt.u32 	%p39, %r6, %r191;
	setp.gt.u32 	%p40, %r5, %r190;
	setp.gt.u32 	%p41, %r5, %r189;
	setp.gt.u32 	%p42, %r6, %r190;
	setp.gt.u32 	%p43, %r6, %r189;
	setp.gt.u32 	%p44, %r5, %r187;
	setp.gt.u32 	%p45, %r5, %r185;
	setp.gt.u32 	%p46, %r6, %r187;
	setp.gt.u32 	%p47, %r6, %r185;
	.loc	1 73 29
	selp.f32 	%f116, %f100, 0f00000000, %p31;
	selp.f32 	%f117, %f116, 0f00000000, %p32;
	selp.f32 	%f118, %f117, 0f00000000, %p30;
	selp.f32 	%f119, %f101, 0f00000000, %p29;
	selp.f32 	%f120, %f119, 0f00000000, %p33;
	selp.f32 	%f121, %f120, 0f00000000, %p30;
	selp.f32 	%f122, %f102, 0f00000000, %p31;
	selp.f32 	%f123, %f122, 0f00000000, %p34;
	selp.f32 	%f124, %f123, 0f00000000, %p28;
	selp.f32 	%f125, %f103, 0f00000000, %p29;
	selp.f32 	%f126, %f125, 0f00000000, %p35;
	selp.f32 	%f127, %f126, 0f00000000, %p28;
	selp.f32 	%f128, %f104, 0f00000000, %p27;
	selp.f32 	%f129, %f128, 0f00000000, %p36;
	selp.f32 	%f130, %f129, 0f00000000, %p30;
	selp.f32 	%f131, %f105, 0f00000000, %p26;
	selp.f32 	%f132, %f131, 0f00000000, %p37;
	selp.f32 	%f133, %f132, 0f00000000, %p30;
	selp.f32 	%f134, %f106, 0f00000000, %p27;
	selp.f32 	%f135, %f134, 0f00000000, %p38;
	selp.f32 	%f136, %f135, 0f00000000, %p28;
	selp.f32 	%f137, %f107, 0f00000000, %p26;
	selp.f32 	%f138, %f137, 0f00000000, %p39;
	selp.f32 	%f139, %f138, 0f00000000, %p28;
	selp.f32 	%f140, %f108, 0f00000000, %p25;
	selp.f32 	%f141, %f140, 0f00000000, %p40;
	selp.f32 	%f142, %f141, 0f00000000, %p30;
	selp.f32 	%f143, %f109, 0f00000000, %p24;
	selp.f32 	%f144, %f143, 0f00000000, %p41;
	selp.f32 	%f145, %f144, 0f00000000, %p30;
	selp.f32 	%f146, %f110, 0f00000000, %p25;
	selp.f32 	%f147, %f146, 0f00000000, %p42;
	selp.f32 	%f148, %f147, 0f00000000, %p28;
	selp.f32 	%f149, %f111, 0f00000000, %p24;
	selp.f32 	%f150, %f149, 0f00000000, %p43;
	selp.f32 	%f151, %f150, 0f00000000, %p28;
	selp.f32 	%f152, %f112, 0f00000000, %p23;
	selp.f32 	%f153, %f152, 0f00000000, %p44;
	selp.f32 	%f154, %f153, 0f00000000, %p30;
	selp.f32 	%f155, %f113, 0f00000000, %p22;
	selp.f32 	%f156, %f155, 0f00000000, %p45;
	selp.f32 	%f157, %f156, 0f00000000, %p30;
	selp.f32 	%f158, %f114, 0f00000000, %p23;
	selp.f32 	%f159, %f158, 0f00000000, %p46;
	selp.f32 	%f160, %f159, 0f00000000, %p28;
	selp.f32 	%f161, %f115, 0f00000000, %p22;
	selp.f32 	%f162, %f161, 0f00000000, %p47;
	selp.f32 	%f163, %f162, 0f00000000, %p28;
	.loc	1 74 48
	shl.b32 	%r202, %r7, 6;
	.loc	1 74 32
	mul.wide.s32 	%rd54, %r202, 4;
	add.s64 	%rd55, %rd6, %rd54;
	.loc	1 75 18
	shl.b64 	%rd56, %rd53, 12;
	mul.wide.u32 	%rd57, %r181, 4;
	or.b64  	%rd58, %rd56, %rd57;
	add.s64 	%rd42, %rd55, %rd58;
	shl.b64 	%rd59, %rd51, 12;
	or.b64  	%rd60, %rd59, %rd57;
	add.s64 	%rd43, %rd55, %rd60;
	shl.b64 	%rd61, %rd49, 12;
	or.b64  	%rd62, %rd61, %rd57;
	add.s64 	%rd44, %rd55, %rd62;
	shl.b64 	%rd63, %rd47, 12;
	or.b64  	%rd64, %rd63, %rd57;
	add.s64 	%rd45, %rd55, %rd64;
	setp.gt.s64 	%p48, %rd53, -1;
	setp.gt.s64 	%p49, %rd51, -1;
	setp.gt.s64 	%p50, %rd49, -1;
	setp.gt.s64 	%p51, %rd47, -1;
	setp.lt.s64 	%p52, %rd53, %rd1;
	setp.lt.s64 	%p53, %rd51, %rd1;
	setp.lt.s64 	%p54, %rd49, %rd1;
	setp.lt.s64 	%p55, %rd47, %rd1;
	and.pred  	%p18, %p48, %p52;
	and.pred  	%p19, %p49, %p53;
	and.pred  	%p20, %p50, %p54;
	and.pred  	%p21, %p51, %p55;
	shr.u32 	%r203, %r2, 2;
	and.b32  	%r204, %r4, 48;
	or.b32  	%r205, %r203, %r204;
	or.b32  	%r206, %r12, %r183;
	mad.lo.s32 	%r207, %r205, 68, %r206;
	shl.b32 	%r208, %r207, 2;
	add.s32 	%r210, %r49, %r208;
	st.shared.v2.f32 	[%r210], {%f118, %f121};
	st.shared.v2.f32 	[%r210+2176], {%f124, %f127};
	st.shared.v2.f32 	[%r210+64], {%f130, %f133};
	st.shared.v2.f32 	[%r210+2240], {%f136, %f139};
	st.shared.v2.f32 	[%r210+128], {%f142, %f145};
	st.shared.v2.f32 	[%r210+2304], {%f148, %f151};
	st.shared.v2.f32 	[%r210+192], {%f154, %f157};
	st.shared.v2.f32 	[%r210+2368], {%f160, %f163};
	bar.sync 	0;
	shl.b32 	%r211, %r3, 1;
	and.b32  	%r212, %r211, 14;
	or.b32  	%r213, %r212, %r9;
	mad.lo.s32 	%r214, %r213, 68, %r181;
	shl.b32 	%r215, %r214, 2;
	add.s32 	%r216, %r49, %r215;
	ld.shared.v4.u32 	{%r161, %r162, %r163, %r164}, [%r216+4352];
	ld.shared.v4.u32 	{%r165, %r166, %r167, %r168}, [%r216+8704];
	ld.shared.v4.u32 	{%r169, %r170, %r171, %r172}, [%r216+13056];
	ld.shared.v4.u32 	{%r157, %r158, %r159, %r160}, [%r216];
	// begin inline asm
	@%p18 st.global.v4.b32 [ %rd42 + 0 ], { %r157, %r158, %r159, %r160 };
	// end inline asm
	// begin inline asm
	@%p19 st.global.v4.b32 [ %rd43 + 0 ], { %r161, %r162, %r163, %r164 };
	// end inline asm
	// begin inline asm
	@%p20 st.global.v4.b32 [ %rd44 + 0 ], { %r165, %r166, %r167, %r168 };
	// end inline asm
	// begin inline asm
	@%p21 st.global.v4.b32 [ %rd45 + 0 ], { %r169, %r170, %r171, %r172 };
	// end inline asm
	.loc	1 75 4
	ret;
$L__tmp1:
$L__func_end0:

}
	.file	1 "D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\fla\\ops\\common\\chunk_scaled_dot_kkt.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 0
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 164
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 104
.b8 117
.b8 110
.b8 107
.b8 95
.b8 115
.b8 99
.b8 97
.b8 108
.b8 101
.b8 100
.b8 95
.b8 100
.b8 111
.b8 116
.b8 95
.b8 107
.b8 107
.b8 116
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 68
.b8 58
.b8 92
.b8 85
.b8 115
.b8 101
.b8 114
.b8 115
.b8 92
.b8 76
.b8 111
.b8 117
.b8 105
.b8 115
.b8 92
.b8 80
.b8 121
.b8 99
.b8 104
.b8 97
.b8 114
.b8 109
.b8 80
.b8 114
.b8 111
.b8 106
.b8 101
.b8 99
.b8 116
.b8 115
.b8 92
.b8 77
.b8 97
.b8 115
.b8 116
.b8 101
.b8 114
.b8 95
.b8 116
.b8 104
.b8 101
.b8 115
.b8 105
.b8 115
.b8 92
.b8 66
.b8 97
.b8 98
.b8 105
.b8 108
.b8 111
.b8 110
.b8 103
.b8 95
.b8 66
.b8 101
.b8 110
.b8 99
.b8 104
.b8 109
.b8 97
.b8 114
.b8 107
.b8 92
.b8 46
.b8 118
.b8 101
.b8 110
.b8 118
.b8 92
.b8 76
.b8 105
.b8 98
.b8 92
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 92
.b8 102
.b8 108
.b8 97
.b8 92
.b8 111
.b8 112
.b8 115
.b8 92
.b8 99
.b8 111
.b8 109
.b8 109
.b8 111
.b8 110
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
	}
	.section	.debug_loc	{	}
