//
// Generated by LLVM NVPTX Back-End
//

.version 8.3
.target sm_86
.address_size 64

	// .globl	layer_norm_fwd_kernel1
.extern .shared .align 16 .b8 global_smem[];
.global .align 1 .b8 _$_str[11] = {95, 95, 67, 85, 68, 65, 95, 70, 84, 90};
.global .align 1 .b8 _$_str_$_2[17] = {95, 95, 67, 85, 68, 65, 95, 80, 82, 69, 67, 95, 83, 81, 82, 84};

.visible .entry layer_norm_fwd_kernel1(
	.param .u64 layer_norm_fwd_kernel1_param_0,
	.param .u64 layer_norm_fwd_kernel1_param_1,
	.param .u64 layer_norm_fwd_kernel1_param_2,
	.param .u64 layer_norm_fwd_kernel1_param_3,
	.param .u64 layer_norm_fwd_kernel1_param_4,
	.param .u64 layer_norm_fwd_kernel1_param_5,
	.param .f32 layer_norm_fwd_kernel1_param_6
)
.maxntid 256, 1, 1
{
	.reg .pred 	%p<19>;
	.reg .b16 	%rs<41>;
	.reg .b32 	%r<88>;
	.reg .f32 	%f<79>;
	.reg .b64 	%rd<20>;
	.loc	1 264 0
$L__func_begin0:
	.loc	1 264 0

	ld.param.u64 	%rd7, [layer_norm_fwd_kernel1_param_0];
	ld.param.u64 	%rd8, [layer_norm_fwd_kernel1_param_1];
$L__tmp0:
	.loc	1 283 24
	// begin inline asm
	mov.u32 %r1, %ctaid.x;
	// end inline asm
	.loc	1 286 15
	shl.b32 	%r43, %r1, 11;
	ld.param.u64 	%rd9, [layer_norm_fwd_kernel1_param_2];
	ld.param.u64 	%rd10, [layer_norm_fwd_kernel1_param_3];
	.loc	1 286 9
	mul.wide.s32 	%rd11, %r43, 2;
	add.s64 	%rd12, %rd7, %rd11;
	ld.param.u64 	%rd13, [layer_norm_fwd_kernel1_param_4];
	.loc	1 289 15
	add.s64 	%rd14, %rd10, %rd11;
	ld.param.u64 	%rd15, [layer_norm_fwd_kernel1_param_5];
	.loc	1 291 19
	add.s64 	%rd16, %rd13, %rd11;
	ld.param.f32 	%f1, [layer_norm_fwd_kernel1_param_6];
	.loc	1 293 23
	mov.u32 	%r44, %tid.x;
	and.b32  	%r45, %r44, 31;
	shl.b32 	%r46, %r44, 3;
	and.b32  	%r47, %r46, 2040;
	.loc	1 295 22
	mul.wide.u32 	%rd17, %r47, 2;
	add.s64 	%rd1, %rd12, %rd17;
	mov.b32 	%r6, 0;
	mov.pred 	%p1, -1;
	.loc	1 295 18
	// begin inline asm
	mov.u32 %r2, 0x0;
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	mov.u32 %r5, 0x0;
	@%p1 ld.global.v4.b32 { %r2, %r3, %r4, %r5 }, [ %rd1 + 0 ];
	@!%p1 mov.u32 %r2, %r6;
	@!%p1 mov.u32 %r3, %r6;
	@!%p1 mov.u32 %r4, %r6;
	@!%p1 mov.u32 %r5, %r6;
	// end inline asm
	.loc	1 297 29
	add.s64 	%rd2, %rd14, %rd17;
	.loc	1 297 23
	// begin inline asm
	mov.u32 %r10, 0x0;
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	mov.u32 %r13, 0x0;
	@%p1 ld.global.v4.b32 { %r10, %r11, %r12, %r13 }, [ %rd2 + 0 ];
	@!%p1 mov.u32 %r10, %r6;
	@!%p1 mov.u32 %r11, %r6;
	@!%p1 mov.u32 %r12, %r6;
	@!%p1 mov.u32 %r13, %r6;
	// end inline asm
	.loc	1 295 51
	mov.b32 	{%rs1, %rs2}, %r2;
	cvt.f32.f16 	%f2, %rs2;
	cvt.f32.f16 	%f3, %rs1;
	.loc	1 297 58
	mov.b32 	{%rs3, %rs4}, %r10;
	cvt.f32.f16 	%f4, %rs4;
	cvt.f32.f16 	%f5, %rs3;
	.loc	1 297 15
	add.f32 	%f6, %f3, %f5;
	add.f32 	%f7, %f2, %f4;
	.loc	1 295 51
	mov.b32 	{%rs5, %rs6}, %r3;
	cvt.f32.f16 	%f8, %rs6;
	cvt.f32.f16 	%f9, %rs5;
	.loc	1 297 58
	mov.b32 	{%rs7, %rs8}, %r11;
	cvt.f32.f16 	%f10, %rs8;
	cvt.f32.f16 	%f11, %rs7;
	.loc	1 297 15
	add.f32 	%f12, %f9, %f11;
	add.f32 	%f13, %f8, %f10;
	.loc	1 295 51
	mov.b32 	{%rs9, %rs10}, %r4;
	cvt.f32.f16 	%f14, %rs10;
	cvt.f32.f16 	%f15, %rs9;
	.loc	1 297 58
	mov.b32 	{%rs11, %rs12}, %r12;
	cvt.f32.f16 	%f16, %rs12;
	cvt.f32.f16 	%f17, %rs11;
	.loc	1 297 15
	add.f32 	%f18, %f15, %f17;
	add.f32 	%f19, %f14, %f16;
	.loc	1 295 51
	mov.b32 	{%rs13, %rs14}, %r5;
	cvt.f32.f16 	%f20, %rs14;
	cvt.f32.f16 	%f21, %rs13;
	.loc	1 297 58
	mov.b32 	{%rs15, %rs16}, %r13;
	cvt.f32.f16 	%f22, %rs16;
	cvt.f32.f16 	%f23, %rs15;
	.loc	1 297 15
	add.f32 	%f24, %f21, %f23;
	add.f32 	%f25, %f20, %f22;
	.loc	1 299 27
	add.s64 	%rd3, %rd16, %rd17;
	.loc	1 299 32
	cvt.rn.f16.f32 	%rs17, %f7;
	cvt.rn.f16.f32 	%rs18, %f6;
	mov.b32 	%r56, {%rs18, %rs17};
	cvt.rn.f16.f32 	%rs19, %f13;
	cvt.rn.f16.f32 	%rs20, %f12;
	mov.b32 	%r57, {%rs20, %rs19};
	cvt.rn.f16.f32 	%rs21, %f19;
	cvt.rn.f16.f32 	%rs22, %f18;
	mov.b32 	%r58, {%rs22, %rs21};
	cvt.rn.f16.f32 	%rs23, %f25;
	cvt.rn.f16.f32 	%rs24, %f24;
	mov.b32 	%r59, {%rs24, %rs23};
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd3 + 0 ], { %r56, %r57, %r58, %r59 };
	// end inline asm
	.loc	1 307 32
	mul.f32 	%f26, %f7, %f7;
$L__tmp1:
	.loc	2 256 15
	fma.rn.f32 	%f27, %f6, %f6, %f26;
	fma.rn.f32 	%f28, %f12, %f12, %f27;
	fma.rn.f32 	%f29, %f13, %f13, %f28;
	fma.rn.f32 	%f30, %f18, %f18, %f29;
	fma.rn.f32 	%f31, %f19, %f19, %f30;
	fma.rn.f32 	%f32, %f24, %f24, %f31;
	fma.rn.f32 	%f33, %f25, %f25, %f32;
	.loc	2 267 36
	mov.b32 	%r60, %f33;
	shfl.sync.bfly.b32	%r61, %r60, 16, 31, -1;
	mov.b32 	%f34, %r61;
	.loc	2 256 15
	add.f32 	%f35, %f33, %f34;
	.loc	2 267 36
	mov.b32 	%r62, %f35;
	shfl.sync.bfly.b32	%r63, %r62, 8, 31, -1;
	mov.b32 	%f36, %r63;
	.loc	2 256 15
	add.f32 	%f37, %f35, %f36;
	.loc	2 267 36
	mov.b32 	%r64, %f37;
	shfl.sync.bfly.b32	%r65, %r64, 4, 31, -1;
	mov.b32 	%f38, %r65;
	.loc	2 256 15
	add.f32 	%f39, %f37, %f38;
	.loc	2 267 36
	mov.b32 	%r66, %f39;
	shfl.sync.bfly.b32	%r67, %r66, 2, 31, -1;
	mov.b32 	%f40, %r67;
	.loc	2 256 15
	add.f32 	%f41, %f39, %f40;
	.loc	2 267 36
	mov.b32 	%r68, %f41;
	shfl.sync.bfly.b32	%r69, %r68, 1, 31, -1;
	mov.b32 	%f42, %r69;
	.loc	2 256 15
	add.f32 	%f43, %f41, %f42;
	.loc	2 267 36
	setp.eq.s32 	%p12, %r45, 0;
	shr.u32 	%r70, %r44, 3;
	and.b32  	%r71, %r70, 28;
	mov.u32 	%r72, global_smem;
	add.s32 	%r22, %r72, %r71;
	mov.b32 	%r23, %f43;
	// begin inline asm
	@%p12 st.shared.b32 [ %r22 + 0 ], %r23;
	// end inline asm
	bar.sync 	0;
	setp.lt.s32 	%p13, %r44, 8;
	shl.b32 	%r73, %r44, 2;
	add.s32 	%r25, %r72, %r73;
	// begin inline asm
	@%p13 ld.shared.b32 %r24, [ %r25 + 0 ];
	// end inline asm
	mov.b32 	%f44, %r24;
	shfl.sync.bfly.b32	%r74, %r24, 4, 31, -1;
	mov.b32 	%f45, %r74;
	.loc	2 256 15
	add.f32 	%f46, %f44, %f45;
	.loc	2 267 36
	mov.b32 	%r75, %f46;
	shfl.sync.bfly.b32	%r76, %r75, 2, 31, -1;
	mov.b32 	%f47, %r76;
	.loc	2 256 15
	add.f32 	%f48, %f46, %f47;
	.loc	2 267 36
	mov.b32 	%r77, %f48;
	shfl.sync.bfly.b32	%r78, %r77, 1, 31, -1;
	mov.b32 	%f49, %r78;
	.loc	2 256 15
	add.f32 	%f50, %f48, %f49;
	.loc	2 267 36
	and.b32  	%r79, %r44, 7;
	setp.eq.s32 	%p18, %r79, 0;
	and.pred  	%p14, %p13, %p18;
	mov.b32 	%r27, %f50;
	// begin inline asm
	@%p14 st.shared.b32 [ %r25 + 0 ], %r27;
	// end inline asm
	bar.sync 	0;
$L__tmp2:
	.loc	1 307 50
	ld.shared.u32 	%r29, [global_smem];
	mov.b32 	%r30, 1157627904;
	// begin inline asm
	div.full.f32 %r28, %r29, %r30;
	// end inline asm
	mov.b32 	%f51, %r28;
	.loc	1 308 33
	add.f32 	%f52, %f51, %f1;
	.loc	1 308 25
	sqrt.approx.ftz.f32 	%f53, %f52;
	.loc	1 287 9
	add.s64 	%rd18, %rd8, %rd11;
	.loc	1 308 17
	mov.b32 	%r33, %f53;
	mov.b32 	%r32, 1065353216;
	// begin inline asm
	div.full.f32 %r34, %r32, %r33;
	// end inline asm
	mov.b32 	%f54, %r34;
	.loc	1 309 20
	mul.wide.s32 	%rd19, %r1, 4;
	add.s64 	%rd4, %rd15, %rd19;
	.loc	1 309 25
	setp.eq.s32 	%p15, %r44, 0;
	// begin inline asm
	@%p15 st.global.b32 [ %rd4 + 0 ], { %r34 };
	// end inline asm
	.loc	1 312 36
	add.s64 	%rd5, %rd9, %rd17;
	.loc	1 312 22
	// begin inline asm
	mov.u32 %r35, 0x0;
	mov.u32 %r36, 0x0;
	mov.u32 %r37, 0x0;
	mov.u32 %r38, 0x0;
	@%p1 ld.global.v4.b32 { %r35, %r36, %r37, %r38 }, [ %rd5 + 0 ];
	// end inline asm
	.loc	1 321 17
	add.s64 	%rd6, %rd18, %rd17;
	.loc	1 312 54
	mov.b32 	{%rs25, %rs26}, %r35;
	cvt.f32.f16 	%f55, %rs26;
	cvt.f32.f16 	%f56, %rs25;
	.loc	1 315 68
	mul.f32 	%f57, %f7, %f54;
	mul.f32 	%f58, %f6, %f54;
	.loc	1 316 20
	mul.f32 	%f59, %f58, %f56;
	mul.f32 	%f60, %f57, %f55;
	.loc	1 321 22
	cvt.rn.f16.f32 	%rs27, %f60;
	cvt.rn.f16.f32 	%rs28, %f59;
	mov.b32 	%r84, {%rs28, %rs27};
	.loc	1 312 54
	mov.b32 	{%rs29, %rs30}, %r36;
	cvt.f32.f16 	%f61, %rs30;
	cvt.f32.f16 	%f62, %rs29;
	.loc	1 315 68
	mul.f32 	%f63, %f13, %f54;
	mul.f32 	%f64, %f12, %f54;
	.loc	1 316 20
	mul.f32 	%f65, %f64, %f62;
	mul.f32 	%f66, %f63, %f61;
	.loc	1 321 22
	cvt.rn.f16.f32 	%rs31, %f66;
	cvt.rn.f16.f32 	%rs32, %f65;
	mov.b32 	%r85, {%rs32, %rs31};
	.loc	1 312 54
	mov.b32 	{%rs33, %rs34}, %r37;
	cvt.f32.f16 	%f67, %rs34;
	cvt.f32.f16 	%f68, %rs33;
	.loc	1 315 68
	mul.f32 	%f69, %f19, %f54;
	mul.f32 	%f70, %f18, %f54;
	.loc	1 316 20
	mul.f32 	%f71, %f70, %f68;
	mul.f32 	%f72, %f69, %f67;
	.loc	1 321 22
	cvt.rn.f16.f32 	%rs35, %f72;
	cvt.rn.f16.f32 	%rs36, %f71;
	mov.b32 	%r86, {%rs36, %rs35};
	.loc	1 312 54
	mov.b32 	{%rs37, %rs38}, %r38;
	cvt.f32.f16 	%f73, %rs38;
	cvt.f32.f16 	%f74, %rs37;
	.loc	1 315 68
	mul.f32 	%f75, %f25, %f54;
	mul.f32 	%f76, %f24, %f54;
	.loc	1 316 20
	mul.f32 	%f77, %f76, %f74;
	mul.f32 	%f78, %f75, %f73;
	.loc	1 321 22
	cvt.rn.f16.f32 	%rs39, %f78;
	cvt.rn.f16.f32 	%rs40, %f77;
	mov.b32 	%r87, {%rs40, %rs39};
	// begin inline asm
	@%p1 st.global.v4.b32 [ %rd6 + 0 ], { %r84, %r85, %r86, %r87 };
	// end inline asm
	.loc	1 321 4
	ret;
$L__tmp3:
$L__func_end0:

}
	.file	1 "D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\fla\\modules\\layernorm.py"
	.file	2 "D:\\Users\\Louis\\PycharmProjects\\Master_thesis\\Babilong_Benchmark\\.venv\\Lib\\site-packages\\triton\\language\\standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 5
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 223
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 108
.b8 97
.b8 121
.b8 101
.b8 114
.b8 110
.b8 111
.b8 114
.b8 109
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 68
.b8 58
.b8 92
.b8 85
.b8 115
.b8 101
.b8 114
.b8 115
.b8 92
.b8 76
.b8 111
.b8 117
.b8 105
.b8 115
.b8 92
.b8 80
.b8 121
.b8 99
.b8 104
.b8 97
.b8 114
.b8 109
.b8 80
.b8 114
.b8 111
.b8 106
.b8 101
.b8 99
.b8 116
.b8 115
.b8 92
.b8 77
.b8 97
.b8 115
.b8 116
.b8 101
.b8 114
.b8 95
.b8 116
.b8 104
.b8 101
.b8 115
.b8 105
.b8 115
.b8 92
.b8 66
.b8 97
.b8 98
.b8 105
.b8 108
.b8 111
.b8 110
.b8 103
.b8 95
.b8 66
.b8 101
.b8 110
.b8 99
.b8 104
.b8 109
.b8 97
.b8 114
.b8 107
.b8 92
.b8 46
.b8 118
.b8 101
.b8 110
.b8 118
.b8 92
.b8 76
.b8 105
.b8 98
.b8 92
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 92
.b8 102
.b8 108
.b8 97
.b8 92
.b8 109
.b8 111
.b8 100
.b8 117
.b8 108
.b8 101
.b8 115
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 108
.b8 97
.b8 121
.b8 101
.b8 114
.b8 95
.b8 110
.b8 111
.b8 114
.b8 109
.b8 95
.b8 102
.b8 119
.b8 100
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 49
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 154
.b8 4
.b32 154
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 51
.b8 1
.b8 23
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
